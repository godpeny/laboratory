{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-15T10:50:17.576690Z",
     "start_time": "2023-10-15T10:50:17.569549Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, TimeDistributed\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d51a322e5f61513e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# data\n",
    "raw_text = '''\n",
    "I get on with life as a programmer,\n",
    "I like to contemplate beer.\n",
    "But when I start to daydream,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "Do I love wine more than beer?\n",
    "\n",
    "I like to use words about beer.\n",
    "But when I stop my talking,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "I hate bugs and errors.\n",
    "But I just think back to wine,\n",
    "And I'm happy once again.\n",
    "\n",
    "I like to hang out with programming and deep learning.\n",
    "But when left alone,\n",
    "My mind turns straight to wine.\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T10:32:08.072082Z",
     "start_time": "2023-10-15T10:32:08.068706Z"
    }
   },
   "id": "476b1ab4fd7c9997"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "tokens = raw_text.split()\n",
    "text = \" \".join(tokens)\n",
    "\n",
    "char_vocab = sorted(list(set(text)))\n",
    "vocab_size = len(char_vocab)\n",
    "\n",
    "char_to_index_pair = dict((char, index) for index, char in enumerate(char_vocab))\n",
    "print(char_to_index_pair)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T10:34:16.656250Z",
     "start_time": "2023-10-15T10:34:16.650377Z"
    }
   },
   "id": "94240739be7247d5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n",
      "['I get on wi', ' get on wit', 'get on with', 'et on with ', 't on with l', ' on with li', 'on with lif', 'n with life', ' with life ', 'with life a']\n"
     ]
    }
   ],
   "source": [
    "length = 11\n",
    "sequences = []\n",
    "\n",
    "for i in range(length, len(text)):\n",
    "    seq = text[i-length:i] # cut the text into sequences of length 11\n",
    "    sequences.append(seq)\n",
    "    \n",
    "print(len(sequences))\n",
    "print(sequences[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T10:42:07.893160Z",
     "start_time": "2023-10-15T10:42:07.886641Z"
    }
   },
   "id": "7cbf7caa650cd0b2"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18], [0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28], [16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17], [14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0], [28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21], [0, 24, 23, 0, 31, 18, 28, 17, 0, 21, 18], [24, 23, 0, 31, 18, 28, 17, 0, 21, 18, 15], [23, 0, 31, 18, 28, 17, 0, 21, 18, 15, 14], [0, 31, 18, 28, 17, 0, 21, 18, 15, 14, 0], [31, 18, 28, 17, 0, 21, 18, 15, 14, 0, 10]]\n"
     ]
    }
   ],
   "source": [
    "encoded_sequences = []\n",
    "\n",
    "for seq in sequences:\n",
    "    encoded_char = [char_to_index_pair[char] for char in seq]\n",
    "    encoded_sequences.append(encoded_char)\n",
    "\n",
    "print(encoded_sequences[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T10:43:29.804542Z",
     "start_time": "2023-10-15T10:43:29.791122Z"
    }
   },
   "id": "92aa444901e68c0e"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 10, 33)\n",
      "(426, 33)\n"
     ]
    }
   ],
   "source": [
    "encoded_sequences = np.array(encoded_sequences)\n",
    "\n",
    "X = encoded_sequences[:,:-1]\n",
    "y = encoded_sequences[:,-1]\n",
    "\n",
    "X_one_hot = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X_one_hot = np.array(X_one_hot)\n",
    "y_one_hot = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "print(X_one_hot.shape)\n",
    "print(y_one_hot.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T11:21:00.497974Z",
     "start_time": "2023-10-15T11:21:00.488173Z"
    }
   },
   "id": "b6122907e54616cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2dacde37cb1d174"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 64)                25088     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 33)                2145      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27233 (106.38 KB)\n",
      "Trainable params: 27233 (106.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "14/14 - 1s - loss: 3.4718 - accuracy: 0.1268 - 631ms/epoch - 45ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 3.3526 - accuracy: 0.1972 - 34ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 3.1425 - accuracy: 0.1972 - 35ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 3.0254 - accuracy: 0.1972 - 35ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 2.9782 - accuracy: 0.1972 - 35ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 2.9447 - accuracy: 0.1972 - 35ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 2.9276 - accuracy: 0.1972 - 34ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 2.9136 - accuracy: 0.1972 - 33ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 2.8941 - accuracy: 0.1972 - 34ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 2.8734 - accuracy: 0.1972 - 34ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 2.8507 - accuracy: 0.1972 - 34ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 2.8220 - accuracy: 0.1972 - 33ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 2.7952 - accuracy: 0.1995 - 33ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 2.7531 - accuracy: 0.2042 - 34ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 2.7115 - accuracy: 0.2324 - 33ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 2.6683 - accuracy: 0.2183 - 33ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 2.6345 - accuracy: 0.2582 - 33ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 2.6117 - accuracy: 0.2418 - 33ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 2.5577 - accuracy: 0.2958 - 33ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 2.5137 - accuracy: 0.2582 - 33ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 2.4733 - accuracy: 0.3099 - 34ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 2.4410 - accuracy: 0.2958 - 35ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 2.3918 - accuracy: 0.3099 - 34ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 2.3374 - accuracy: 0.3451 - 34ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 2.3064 - accuracy: 0.3498 - 33ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 2.2654 - accuracy: 0.3545 - 34ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 2.2238 - accuracy: 0.4155 - 34ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 2.2004 - accuracy: 0.3850 - 33ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 2.1571 - accuracy: 0.3779 - 34ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 2.0971 - accuracy: 0.4366 - 33ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 2.0548 - accuracy: 0.4390 - 33ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 2.0076 - accuracy: 0.4390 - 34ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.9615 - accuracy: 0.4437 - 34ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.9354 - accuracy: 0.4718 - 34ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.8768 - accuracy: 0.4577 - 33ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.8364 - accuracy: 0.4906 - 34ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.7838 - accuracy: 0.5000 - 33ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.7621 - accuracy: 0.5000 - 34ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.7065 - accuracy: 0.5211 - 33ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6699 - accuracy: 0.5587 - 33ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6190 - accuracy: 0.5563 - 34ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.5930 - accuracy: 0.5610 - 34ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.5504 - accuracy: 0.5751 - 33ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.5122 - accuracy: 0.5939 - 34ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.4656 - accuracy: 0.6150 - 33ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.4341 - accuracy: 0.6174 - 34ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.4006 - accuracy: 0.6385 - 34ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.3691 - accuracy: 0.6808 - 33ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.3310 - accuracy: 0.6620 - 33ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.2913 - accuracy: 0.6761 - 34ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.2523 - accuracy: 0.6737 - 34ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.2476 - accuracy: 0.6737 - 33ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.2027 - accuracy: 0.6972 - 32ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.1591 - accuracy: 0.7136 - 33ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.1302 - accuracy: 0.7089 - 34ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.0955 - accuracy: 0.7160 - 34ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.0809 - accuracy: 0.7371 - 32ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.0434 - accuracy: 0.7535 - 33ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.0177 - accuracy: 0.7512 - 34ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 0.9745 - accuracy: 0.7676 - 33ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 0.9461 - accuracy: 0.7864 - 34ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 0.9105 - accuracy: 0.8052 - 34ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 0.8903 - accuracy: 0.8028 - 34ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 0.8652 - accuracy: 0.8122 - 34ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 0.8399 - accuracy: 0.8169 - 33ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 0.8345 - accuracy: 0.8239 - 33ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 0.8136 - accuracy: 0.8333 - 33ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 0.7693 - accuracy: 0.8474 - 34ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 0.7741 - accuracy: 0.8404 - 34ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 0.7548 - accuracy: 0.8545 - 34ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 0.7102 - accuracy: 0.8615 - 34ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 0.6718 - accuracy: 0.8803 - 33ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 0.6559 - accuracy: 0.8920 - 33ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 0.6325 - accuracy: 0.8920 - 34ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 0.6131 - accuracy: 0.8920 - 34ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 0.6031 - accuracy: 0.9061 - 34ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 0.5741 - accuracy: 0.9085 - 34ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 0.5611 - accuracy: 0.9131 - 33ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 0.5493 - accuracy: 0.9178 - 32ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 0.5258 - accuracy: 0.9131 - 34ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 0.5062 - accuracy: 0.9225 - 33ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 0.4894 - accuracy: 0.9249 - 34ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 0.4718 - accuracy: 0.9225 - 34ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 0.4576 - accuracy: 0.9343 - 34ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 0.4459 - accuracy: 0.9366 - 34ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 0.4296 - accuracy: 0.9507 - 33ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 0.4181 - accuracy: 0.9460 - 34ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 0.4103 - accuracy: 0.9413 - 33ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 0.3963 - accuracy: 0.9624 - 33ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 0.3782 - accuracy: 0.9577 - 34ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 0.3622 - accuracy: 0.9624 - 34ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 0.3524 - accuracy: 0.9695 - 33ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 0.3386 - accuracy: 0.9765 - 33ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 0.3323 - accuracy: 0.9765 - 34ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 0.3296 - accuracy: 0.9671 - 33ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 0.3278 - accuracy: 0.9718 - 33ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 0.3168 - accuracy: 0.9765 - 33ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 0.3129 - accuracy: 0.9695 - 33ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 0.2859 - accuracy: 0.9765 - 33ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 0.2768 - accuracy: 0.9742 - 34ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x2cea46350>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_units = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=hidden_units, input_shape=(X_one_hot.shape[1], X_one_hot.shape[2]))) # 10 words with 33 chars\n",
    "model.add(Dense(units=vocab_size, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_one_hot, y_one_hot, epochs=100, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T11:21:06.527607Z",
     "start_time": "2023-10-15T11:21:02.384196Z"
    }
   },
   "id": "2c27c04fe7480e9a"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def generate(model, char_to_index_pair, text, n, seq_length=10):\n",
    "    sentence = text\n",
    "    \n",
    "    for _ in range(n):\n",
    "        encoded = [char_to_index_pair[char] for char in sentence]\n",
    "        encoded_padded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        encoded_padded_one_hot = to_categorical(encoded_padded, num_classes=vocab_size)\n",
    "        \n",
    "        result = model.predict(encoded_padded_one_hot, verbose=0)\n",
    "        result = np.argmax(result, axis=1) # get the index of the most probable char from each row\n",
    "        \n",
    "        for char, idx in char_to_index_pair.items():\n",
    "            if idx == result:\n",
    "                break\n",
    "        \n",
    "        sentence += char\n",
    "\n",
    "    return sentence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T11:26:01.902577Z",
     "start_time": "2023-10-15T11:26:01.897004Z"
    }
   },
   "id": "ff10da5d781fbec2"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I get on w,tht oop tyy aikkg  m ik  hut utsnssrraaiggt I wiin  oee laaa e, lM.  nen Iualtpp\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, char_to_index_pair, 'I get on w,', 80))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T11:26:09.841571Z",
     "start_time": "2023-10-15T11:26:08.366322Z"
    }
   },
   "id": "85c95d13b667efc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5ad58f17c3f4493b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
