{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-29T04:26:05.907436Z",
     "start_time": "2023-12-29T04:26:05.161449Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082168\n",
      "   publish_date                                      headline_text\n",
      "0      20030219  aba decides against community broadcasting lic...\n",
      "1      20030219     act fire witnesses must be aware of defamation\n",
      "2      20030219     a g calls for infrastructure protection summit\n",
      "3      20030219           air nz staff in aust strike for pay rise\n",
      "4      20030219      air nz strike to affect australian travellers\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/\"\n",
    "df = pd.read_csv(data_path + \"abcnews-date-text.csv\")\n",
    "\n",
    "print(len(df))\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T04:44:03.176875Z",
     "start_time": "2023-12-29T04:44:02.628800Z"
    }
   },
   "id": "6082bbd7448a3ac6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing & Tokenizing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ac72c33d5650c49"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/godpeny/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T04:44:07.197204Z",
     "start_time": "2023-12-29T04:44:07.159390Z"
    }
   },
   "id": "c637bdbdcbb74627"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "   publish_date                                      headline_text\n0      20030219  [aba, decides, against, community, broadcastin...\n1      20030219  [act, fire, witnesses, must, be, aware, of, de...\n2      20030219  [a, g, calls, for, infrastructure, protection,...\n3      20030219  [air, nz, staff, in, aust, strike, for, pay, r...\n4      20030219  [air, nz, strike, to, affect, australian, trav...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>publish_date</th>\n      <th>headline_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20030219</td>\n      <td>[aba, decides, against, community, broadcastin...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20030219</td>\n      <td>[act, fire, witnesses, must, be, aware, of, de...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20030219</td>\n      <td>[a, g, calls, for, infrastructure, protection,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20030219</td>\n      <td>[air, nz, staff, in, aust, strike, for, pay, r...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20030219</td>\n      <td>[air, nz, strike, to, affect, australian, trav...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline_text'] = df['headline_text'].apply(lambda row: nltk.word_tokenize(row))\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T04:44:39.514550Z",
     "start_time": "2023-12-29T04:44:08.114865Z"
    }
   },
   "id": "28f454e7b72913c0"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0       [decide, community, broadcast, licence]\n1      [fire, witness, must, aware, defamation]\n2    [call, infrastructure, protection, summit]\n3                   [staff, aust, strike, rise]\n4      [strike, affect, australian, travellers]\nName: headline_text, dtype: object"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnecessary columns\n",
    "df = df.drop(columns=['publish_date'])\n",
    "\n",
    "# remove stop words\n",
    "stops = stopwords.words('english')\n",
    "df['headline_text'] = df['headline_text'].apply(lambda row: [word for word in row if word not in stops])\n",
    "\n",
    "# lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['headline_text'] = df['headline_text'].apply(lambda row: [lemmatizer.lemmatize(word, pos='v') for word in row]) # pos='v' means parts of speech is verb.\n",
    "\n",
    "# remove words with length <= 3\n",
    "tokenized_doc = df['headline_text'].apply(lambda row: [word for word in row if len(word) > 3])\n",
    "tokenized_doc.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T04:45:49.746238Z",
     "start_time": "2023-12-29T04:45:28.614635Z"
    }
   },
   "id": "42914092f54a70a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TF-IDF Processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fdc7c5e0ce0a24b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                           headline_text\n0     decide community broadcast licence\n1     fire witness must aware defamation\n2  call infrastructure protection summit\n3                 staff aust strike rise\n4    strike affect australian travellers",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>decide community broadcast licence</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fire witness must aware defamation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>call infrastructure protection summit</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>staff aust strike rise</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>strike affect australian travellers</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detokenized_doc = []\n",
    "for i in range(len(df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "    \n",
    "df['headline_text'] = detokenized_doc\n",
    "\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T04:52:04.565886Z",
     "start_time": "2023-12-29T04:52:03.489035Z"
    }
   },
   "id": "826737f61b16486d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features= 1000) # keep top 1000 terms\n",
    "X = vectorizer.fit_transform(df['headline_text'])\n",
    "\n",
    "n_topics = 10 # hyperparameter\n",
    "model = LatentDirichletAllocation(n_components=n_topics, learning_method='online', random_state=777, max_iter=1)\n",
    "history = model.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T05:03:52.192101Z",
     "start_time": "2023-12-29T05:03:04.177685Z"
    }
   },
   "id": "80271e7b5b406a74"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LatentDirichletAllocation.learning_method\n",
    " - 'batch': Batch variational Bayes method. Use all training data in each EM update. Old `components_` will be overwritten in each iteration.\n",
    " - 'online': Online variational Bayes method. In each EM update, use mini-batch of training data to update the ``components_`` variable incrementally. \n",
    "    The learning rate is controlled by the ``learning_decay`` and the ``learning_offset`` parameters.\n",
    "### EM(Expectation and Maximization) algorithm\n",
    " - In statistics, an expectationâ€“maximization (EM) algorithm is an iterative method to find (local) maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "484db8939866f037"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1000)\n",
      "[[1.00001533e-01 1.00001269e-01 1.00004179e-01 ... 1.00006124e-01\n",
      "  1.00003111e-01 1.00003064e-01]\n",
      " [1.00001199e-01 1.13513398e+03 3.50170830e+03 ... 1.00009349e-01\n",
      "  1.00001896e-01 1.00002937e-01]\n",
      " [1.00001811e-01 1.00001151e-01 1.00003566e-01 ... 1.00002693e-01\n",
      "  1.00002061e-01 7.53381835e+02]\n",
      " ...\n",
      " [1.00001065e-01 1.00001689e-01 1.00003278e-01 ... 1.00006721e-01\n",
      "  1.00004902e-01 1.00004759e-01]\n",
      " [1.00002401e-01 1.00000732e-01 1.00002989e-01 ... 1.00003517e-01\n",
      "  1.00001428e-01 1.00005266e-01]\n",
      " [1.00003427e-01 1.00002313e-01 1.00007340e-01 ... 1.00003732e-01\n",
      "  1.00001207e-01 1.00005153e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(model.components_.shape)\n",
    "print(model.components_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T05:06:54.629035Z",
     "start_time": "2023-12-29T05:06:54.619320Z"
    }
   },
   "id": "ea7e0b8b546fd969"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names_out() # 1000 words\n",
    "\n",
    "def get_topics(components, terms, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(terms[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T05:07:37.565637Z",
     "start_time": "2023-12-29T05:07:37.563283Z"
    }
   },
   "id": "bfeb660c697621ed"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('government', 8725.19), ('sydney', 8393.29), ('queensland', 7720.12), ('change', 5874.27), ('home', 5674.38)]\n",
      "Topic 2: [('australia', 13691.08), ('australian', 11088.95), ('melbourne', 7528.43), ('world', 6707.7), ('south', 6677.03)]\n",
      "Topic 3: [('death', 5935.06), ('interview', 5924.98), ('kill', 5851.6), ('jail', 4632.85), ('life', 4275.27)]\n",
      "Topic 4: [('house', 6113.49), ('2016', 5488.19), ('state', 4923.41), ('brisbane', 4857.21), ('tasmania', 4610.97)]\n",
      "Topic 5: [('court', 7542.74), ('attack', 6959.64), ('open', 5663.0), ('face', 5193.63), ('warn', 5115.01)]\n",
      "Topic 6: [('market', 5545.86), ('rural', 5502.89), ('plan', 4828.71), ('indigenous', 4223.4), ('power', 3968.26)]\n",
      "Topic 7: [('charge', 8428.8), ('election', 7561.63), ('adelaide', 6758.36), ('make', 5658.99), ('test', 5062.69)]\n",
      "Topic 8: [('police', 12092.44), ('crash', 5281.14), ('drug', 4290.87), ('beat', 3257.58), ('rise', 2934.92)]\n",
      "Topic 9: [('fund', 4693.03), ('labor', 4047.69), ('national', 4038.68), ('council', 4006.62), ('claim', 3604.75)]\n",
      "Topic 10: [('trump', 11966.41), ('perth', 6456.53), ('report', 5611.33), ('school', 5465.06), ('woman', 5456.76)]\n"
     ]
    }
   ],
   "source": [
    "get_topics(model.components_, terms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T05:08:04.697020Z",
     "start_time": "2023-12-29T05:08:04.692902Z"
    }
   },
   "id": "9e0d7ac467b6ec10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bc469eb4e675a412"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
