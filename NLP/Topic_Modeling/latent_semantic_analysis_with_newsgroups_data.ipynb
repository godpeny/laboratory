{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-29T01:27:46.373936Z",
     "start_time": "2023-12-29T01:27:45.666056Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "항목 :  dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n",
      "샘플의 수 :  11314\n",
      "카테고리 :  ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "\n",
    "print('항목 : ', dataset.keys())\n",
    "print('샘플의 수 : ',len(documents))\n",
    "print('카테고리 : ', dataset.target_names) # 20 categories"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T01:36:18.492098Z",
     "start_time": "2023-12-29T01:36:17.862030Z"
    }
   },
   "id": "56aede7115b2e31a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing & Tokenizing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "928545279bd477d1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            document\n",
      "0  Well i'm not sure about the story nad it did s...\n",
      "1  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
      "2  Although I realize that principle is not one o...\n",
      "0    Well i m not sure about the story nad it did s...\n",
      "1           Yeah  do you expect people to read the ...\n",
      "2    Although I realize that principle is not one o...\n",
      "Name: clean_doc, dtype: object\n",
      "0    Well sure about story seem biased What disagre...\n",
      "1    Yeah expect people read actually accept hard a...\n",
      "2    Although realize that principle your strongest...\n",
      "Name: clean_doc, dtype: object\n",
      "0    well sure about story seem biased what disagre...\n",
      "1    yeah expect people read actually accept hard a...\n",
      "2    although realize that principle your strongest...\n",
      "Name: clean_doc, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'document':documents})\n",
    "print(df.head(3))\n",
    "\n",
    "df['clean_doc'] = df['document'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
    "print(df.clean_doc[:3])\n",
    "\n",
    "df['clean_doc'] = df['clean_doc'].apply(lambda x: ' '.join([word for word in x.split() if len(word) > 3]))\n",
    "print(df.clean_doc[:3])\n",
    "\n",
    "df['clean_doc'] = df['clean_doc'].apply(lambda x: x.lower())\n",
    "print(df.clean_doc[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T01:27:47.552928Z",
     "start_time": "2023-12-29T01:27:46.986753Z"
    }
   },
   "id": "1535599f18e901d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### join\n",
    " - Concatenate any number of strings.\n",
    " ```python\n",
    "    '.'.join(['ab', 'pq', 'rs']) # 'ab.pq.rs'\n",
    " ```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdd8c90da64865a9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons\n"
     ]
    }
   ],
   "source": [
    "print(df['clean_doc'][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T01:27:47.553520Z",
     "start_time": "2023-12-29T01:27:47.552200Z"
    }
   },
   "id": "4fd48be67e2d4eb"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "tokenized_doc = df['clean_doc'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [word for word in x if word not in stop])\n",
    "\n",
    "print(tokenized_doc[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T01:28:32.185541Z",
     "start_time": "2023-12-29T01:28:30.925687Z"
    }
   },
   "id": "2396da24d72d6693"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TF-IDF Processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3628221e85febf"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah expect people read actually accept hard atheism need little leap faith jimmy logic runs steam sorry pity sorry feelings denial faith need well pretend happily ever anyway maybe start newsgroup atheist hard bummin much forget flintstone chewables bake timmons\n"
     ]
    }
   ],
   "source": [
    "detokenized_doc = []\n",
    "\n",
    "for i in range(len(tokenized_doc)):\n",
    "    sentence_from_tokens= ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(sentence_from_tokens)\n",
    "    \n",
    "df['clean_doc'] = detokenized_doc\n",
    "\n",
    "print(df['clean_doc'][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T01:31:27.926792Z",
     "start_time": "2023-12-29T01:31:27.885081Z"
    }
   },
   "id": "af9f4ce8e9a1946a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 1000)\n"
     ]
    }
   ],
   "source": [
    "# max_df : ignore terms that have a document frequency(df) strictly higher than the given threshold. In this case, 0.5 means \"ignore terms that appear in more than 50% of the documents\".\n",
    "# max_features : build a vocabulary that only consider the top max_features ordered by term frequency across the corpus. In this case, pick top 1000 words ordered by term frequency.\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000, max_df=0.5, smooth_idf=True)\n",
    "X = vectorizer.fit_transform(df['clean_doc'])\n",
    "\n",
    "print(X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T01:33:56.352438Z",
     "start_time": "2023-12-29T01:33:55.861555Z"
    }
   },
   "id": "cc2d8eae6de676f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Topic Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "822f8d97be6a82e3"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "TruncatedSVD(n_components=20, n_iter=100, random_state=122)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TruncatedSVD(n_components=20, n_iter=100, random_state=122)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TruncatedSVD</label><div class=\"sk-toggleable__content\"><pre>TruncatedSVD(n_components=20, n_iter=100, random_state=122)</pre></div></div></div></div></div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_components : number of topics = 20 categories of news datas\n",
    "svd_model = TruncatedSVD(n_components=len(dataset.target_names), algorithm='randomized', n_iter=100, random_state=122)\n",
    "svd_model.fit(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T01:41:44.389619Z",
     "start_time": "2023-12-29T01:41:43.109404Z"
    }
   },
   "id": "48ffc153a67dee53"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1000)\n",
      "['ability' 'able' 'accept' 'access' 'according' 'account' 'action'\n",
      " 'actions' 'actual' 'actually']\n"
     ]
    }
   ],
   "source": [
    "# check VT and words\n",
    "print(svd_model.components_.shape) # VT = (20, 1000) = (n_components, n_words)\n",
    "\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "print(terms[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T01:45:06.453248Z",
     "start_time": "2023-12-29T01:45:06.445536Z"
    }
   },
   "id": "73b6034ca155a847"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def get_topics(components, feature_names, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n-1:-1]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T02:04:08.962191Z",
     "start_time": "2023-12-29T02:04:08.950071Z"
    }
   },
   "id": "1a319f4fbf6790ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [a:b:c] : a부터 b까지 c의 간격으로\n",
    "```python\n",
    "lst = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "n = 3\n",
    "print(lst[:-n-1:-1]) # [9, 8, 7]\n",
    "print(lst[0:5:2]) # [0, 2, 4]\n",
    "print(lst[:-3]) # [0, 1, 2, 3, 4, 5, 6]\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f7324a11ee671cd"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('like', 0.21386), ('know', 0.20046), ('people', 0.19293), ('think', 0.17805), ('good', 0.15128)]\n",
      "Topic 2: [('thanks', 0.32888), ('windows', 0.29088), ('card', 0.18069), ('drive', 0.17455), ('mail', 0.15111)]\n",
      "Topic 3: [('game', 0.37064), ('team', 0.32443), ('year', 0.28154), ('games', 0.2537), ('season', 0.18419)]\n",
      "Topic 4: [('drive', 0.53324), ('scsi', 0.20165), ('hard', 0.15628), ('disk', 0.15578), ('card', 0.13994)]\n",
      "Topic 5: [('windows', 0.40399), ('file', 0.25436), ('window', 0.18044), ('files', 0.16078), ('program', 0.13894)]\n",
      "Topic 6: [('chip', 0.16114), ('government', 0.16009), ('mail', 0.15625), ('space', 0.1507), ('information', 0.13562)]\n",
      "Topic 7: [('like', 0.67086), ('bike', 0.14236), ('chip', 0.11169), ('know', 0.11139), ('sounds', 0.10371)]\n",
      "Topic 8: [('card', 0.46633), ('video', 0.22137), ('sale', 0.21266), ('monitor', 0.15463), ('offer', 0.14643)]\n",
      "Topic 9: [('know', 0.46047), ('card', 0.33605), ('chip', 0.17558), ('government', 0.1522), ('video', 0.14356)]\n",
      "Topic 10: [('good', 0.42756), ('know', 0.23039), ('time', 0.1882), ('bike', 0.11406), ('jesus', 0.09027)]\n",
      "Topic 11: [('think', 0.78469), ('chip', 0.10899), ('good', 0.10635), ('thanks', 0.09123), ('clipper', 0.07946)]\n",
      "Topic 12: [('thanks', 0.36824), ('good', 0.22729), ('right', 0.21559), ('bike', 0.21037), ('problem', 0.20894)]\n",
      "Topic 13: [('good', 0.36212), ('people', 0.33985), ('windows', 0.28385), ('know', 0.26232), ('file', 0.18422)]\n",
      "Topic 14: [('space', 0.39946), ('think', 0.23258), ('know', 0.18074), ('nasa', 0.15174), ('problem', 0.12957)]\n",
      "Topic 15: [('space', 0.31613), ('good', 0.3094), ('card', 0.22603), ('people', 0.17476), ('time', 0.14496)]\n",
      "Topic 16: [('people', 0.48156), ('problem', 0.19961), ('window', 0.15281), ('time', 0.14664), ('game', 0.12871)]\n",
      "Topic 17: [('time', 0.34465), ('bike', 0.27303), ('right', 0.25557), ('windows', 0.1997), ('file', 0.19118)]\n",
      "Topic 18: [('time', 0.5973), ('problem', 0.15504), ('file', 0.14956), ('think', 0.12847), ('israel', 0.10903)]\n",
      "Topic 19: [('file', 0.44163), ('need', 0.26633), ('card', 0.18388), ('files', 0.17453), ('right', 0.15448)]\n",
      "Topic 20: [('problem', 0.33006), ('file', 0.27651), ('thanks', 0.23578), ('used', 0.19206), ('space', 0.13185)]\n"
     ]
    }
   ],
   "source": [
    "get_topics(svd_model.components_, terms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T02:04:22.605925Z",
     "start_time": "2023-12-29T02:04:22.588015Z"
    }
   },
   "id": "d4e9f0ae9e09fca2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b1777bbfa923b148"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
