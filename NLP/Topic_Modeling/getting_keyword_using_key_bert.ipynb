{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-31T05:24:43.592987Z",
     "start_time": "2023-12-31T05:24:43.589118Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "         Supervised learning is the machine learning task of \n",
    "         learning a function that maps an input to an output based \n",
    "         on example input-output pairs.[1] It infers a function \n",
    "         from labeled training data consisting of a set of \n",
    "         training examples.[2] In supervised learning, each \n",
    "         example is a pair consisting of an input object \n",
    "         (typically a vector) and a desired output value (also \n",
    "         called the supervisory signal). A supervised learning \n",
    "         algorithm analyzes the training data and produces an \n",
    "         inferred function, which can be used for mapping new \n",
    "         examples. An optimal scenario will allow for the algorithm \n",
    "         to correctly determine the class labels for unseen \n",
    "         instances. This requires the learning algorithm to  \n",
    "         generalize from the training data to unseen situations \n",
    "         in a 'reasonable' way (see inductive bias).\n",
    "      \"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T05:24:43.601367Z",
     "start_time": "2023-12-31T05:24:43.594730Z"
    }
   },
   "id": "dd8a6a8408046364"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algorithm analyzes training' 'algorithm correctly determine'\n",
      " 'algorithm generalize training' 'allow algorithm correctly'\n",
      " 'analyzes training data' 'based example input'\n",
      " 'called supervisory signal' 'class labels unseen'\n",
      " 'consisting input object' 'consisting set training'\n",
      " 'correctly determine class' 'data consisting set'\n",
      " 'data produces inferred' 'data unseen situations' 'desired output value'\n",
      " 'determine class labels' 'example input output' 'example pair consisting'\n",
      " 'examples optimal scenario' 'examples supervised learning'\n",
      " 'function labeled training' 'function maps input' 'function used mapping'\n",
      " 'generalize training data' 'inferred function used'\n",
      " 'infers function labeled' 'input object typically' 'input output based'\n",
      " 'input output pairs' 'instances requires learning'\n",
      " 'labeled training data' 'labels unseen instances'\n",
      " 'learning algorithm analyzes' 'learning algorithm generalize'\n",
      " 'learning example pair' 'learning function maps'\n",
      " 'learning machine learning' 'learning task learning'\n",
      " 'machine learning task' 'mapping new examples' 'maps input output'\n",
      " 'new examples optimal' 'object typically vector' 'optimal scenario allow'\n",
      " 'output based example' 'output pairs infers' 'output value called'\n",
      " 'pair consisting input' 'pairs infers function'\n",
      " 'produces inferred function' 'reasonable way inductive'\n",
      " 'requires learning algorithm' 'scenario allow algorithm'\n",
      " 'set training examples' 'signal supervised learning'\n",
      " 'situations reasonable way' 'supervised learning algorithm'\n",
      " 'supervised learning example' 'supervised learning machine'\n",
      " 'supervisory signal supervised' 'task learning function'\n",
      " 'training data consisting' 'training data produces'\n",
      " 'training data unseen' 'training examples supervised'\n",
      " 'typically vector desired' 'unseen instances requires'\n",
      " 'unseen situations reasonable' 'used mapping new'\n",
      " 'value called supervisory' 'vector desired output' 'way inductive bias']\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "n_gram_range = (3,3) # trigrams\n",
    "stop_words = \"english\"\n",
    "\n",
    "# Extract candidate words/phrases\n",
    "cv = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([doc])\n",
    "candidates = cv.get_feature_names_out()\n",
    "\n",
    "print(candidates)\n",
    "print(len(candidates))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T05:29:14.279712Z",
     "start_time": "2023-12-31T05:29:14.275513Z"
    }
   },
   "id": "1e6c20f5f7bd46de"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_embedding: (1, 768)\n",
      "candidate_embeddings: (72, 768)\n",
      "distances: (1, 72)\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "doc_embedding = model.encode([doc])\n",
    "candidate_embeddings = model.encode(candidates)\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "\n",
    "print('document_embedding:', doc_embedding.shape)\n",
    "print('candidate_embeddings:', candidate_embeddings.shape)\n",
    "print('distances:', distances.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T05:29:17.271892Z",
     "start_time": "2023-12-31T05:29:16.995985Z"
    }
   },
   "id": "871fba68fa1867f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Basic Key BERT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10c656b02436e31e"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algorithm analyzes training', 'learning algorithm generalize', 'learning machine learning', 'learning algorithm analyzes', 'algorithm generalize training']\n"
     ]
    }
   ],
   "source": [
    "# pick top_n words closest to the doc.\n",
    "top_n = 5\n",
    "\n",
    "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]  # return top n keywords\n",
    "print(keywords)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T05:29:18.730262Z",
     "start_time": "2023-12-31T05:29:18.724984Z"
    }
   },
   "id": "bf29ee94a9154d92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Max Sum Similarity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc179aba7d0e5c1b"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['requires learning algorithm', 'signal supervised learning', 'learning function maps', 'algorithm analyzes training', 'learning machine learning']\n"
     ]
    }
   ],
   "source": [
    "candidates_num = 10\n",
    "\n",
    "dist_doc_word = cosine_similarity(doc_embedding, candidate_embeddings) # (1, 72)\n",
    "dist_word_word = cosine_similarity(candidate_embeddings, candidate_embeddings) # (72, 72)\n",
    "\n",
    "words_idx = list(np.argsort(dist_doc_word)[0][-candidates_num:])\n",
    "words = [candidates[idx] for idx in words_idx]\n",
    "\n",
    "dist_word_word = dist_word_word[np.ix_(words_idx, words_idx)]\n",
    "\n",
    "min_sim = np.inf\n",
    "candidate = None\n",
    "\n",
    "# find the least similar words\n",
    "for combination in itertools.combinations(range(len(words_idx)), top_n):\n",
    "    sim = sum([dist_word_word[i][j] for i in combination for j in combination if i != j])\n",
    "    if sim < min_sim:\n",
    "        candidate = combination\n",
    "        min_sim = sim\n",
    "        \n",
    "result = [words[idx] for idx in candidate]\n",
    "\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T05:24:44.283181Z",
     "start_time": "2023-12-31T05:24:44.263700Z"
    }
   },
   "id": "e1ab14cbf9fc84ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### np.ix_\n",
    " - construct an open mesh from multiple sequences.\n",
    "```python\n",
    "a = np.array([[1,2,3,4,5,6,7,8,9,10],[11,12,13,14,15,16,17,18,19,20],[21,22,23,24,25,26,27,28,29,30]])\n",
    "_a = a[np.ix_([0,2,1],[0,1,2])]\n",
    "print(_a) \n",
    "\"\"\"\n",
    "[[ 1  2  3]\n",
    " [21 22 23]\n",
    " [11 12 13]]\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### itertools.combinations\n",
    " - return r length subsequences of elements from the input iterable.\n",
    " - combinations('ABCD', 2) --> AB AC AD BC BD CD\n",
    " - combinations(range(4), 3) --> 012 013 023 123\n",
    "```python\n",
    "for combination in itertools.combinations(range(5), 3):\n",
    "  print(combination)\n",
    "\"\"\"\n",
    "(0, 1, 2)\n",
    "(0, 1, 3)\n",
    "(0, 1, 4)\n",
    "(0, 2, 3)\n",
    "(0, 2, 4)\n",
    "(0, 3, 4)\n",
    "(1, 2, 3)\n",
    "(1, 2, 4)\n",
    "(1, 3, 4)\n",
    "(2, 3, 4)\n",
    "\"\"\"\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ac7d70332ea057a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Maximal Marginal Relevance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b81abfc4057b4812"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algorithm generalize training', 'supervised learning algorithm', 'learning machine learning', 'learning algorithm analyzes', 'learning algorithm generalize']\n"
     ]
    }
   ],
   "source": [
    "diversity = 0.2\n",
    "\n",
    "dist_word_doc = cosine_similarity(candidate_embeddings, doc_embedding) # (72, 1)\n",
    "dist_word_word_2 = cosine_similarity(candidate_embeddings) # (72, 72)\n",
    "\n",
    "most_similar_keyword = [np.argmax(dist_word_doc)] # [2]\n",
    "\n",
    "# cand_indexes of words except most_similar_keyword\n",
    "cand_indexes = [i for i in range(len(candidates)) if i not in most_similar_keyword] \n",
    "\n",
    "for _ in range(top_n-1):\n",
    "    candidate_similarities = dist_word_doc[cand_indexes]\n",
    "    target_similarities = np.max(dist_word_word_2[cand_indexes][:, most_similar_keyword], axis=1)\n",
    "    # print(candidate_similarities.shape)\n",
    "    # print(target_similarities.reshape(-1,1).shape)\n",
    "    \n",
    "    mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1,1)\n",
    "    mmr_idx = cand_indexes[np.argmax(mmr)]\n",
    "    \n",
    "    most_similar_keyword.append(mmr_idx)\n",
    "    cand_indexes.remove(mmr_idx)\n",
    "    \n",
    "result = [candidates[idx] for idx in most_similar_keyword]\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T06:00:11.410443Z",
     "start_time": "2023-12-31T06:00:11.364858Z"
    }
   },
   "id": "692fa1e6b56a3e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### np.array\n",
    "```python\n",
    "a = np.array([1,2,3,4,5,6,7,8,9])\n",
    "a = a.reshape(3,3)\n",
    "print(a)\n",
    "\"\"\"\n",
    "[[1 2 3]\n",
    " [4 5 6]\n",
    " [7 8 9]]\n",
    "\"\"\"\n",
    "print(a[[0,1,2]][:,[2]])\n",
    "\"\"\"\n",
    "[[3]\n",
    " [6]\n",
    " [9]]\n",
    "\"\"\"\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f19f3d65f6e3a1a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "99678cb863c76f11"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
