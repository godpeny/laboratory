{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-29T03:42:52.515480Z",
     "start_time": "2023-12-29T03:42:51.839695Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "항목 :  dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n",
      "샘플의 수 :  11314\n",
      "카테고리 :  ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "\n",
    "print('항목 : ', dataset.keys())\n",
    "print('샘플의 수 : ',len(documents))\n",
    "print('카테고리 : ', dataset.target_names) # 20 categories"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T03:42:53.295704Z",
     "start_time": "2023-12-29T03:42:52.516873Z"
    }
   },
   "id": "56aede7115b2e31a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "928545279bd477d1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            document\n",
      "0  Well i'm not sure about the story nad it did s...\n",
      "1  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
      "2  Although I realize that principle is not one o...\n",
      "0    Well i m not sure about the story nad it did s...\n",
      "1           Yeah  do you expect people to read the ...\n",
      "2    Although I realize that principle is not one o...\n",
      "Name: clean_doc, dtype: object\n",
      "0    Well sure about story seem biased What disagre...\n",
      "1    Yeah expect people read actually accept hard a...\n",
      "2    Although realize that principle your strongest...\n",
      "Name: clean_doc, dtype: object\n",
      "0    well sure about story seem biased what disagre...\n",
      "1    yeah expect people read actually accept hard a...\n",
      "2    although realize that principle your strongest...\n",
      "Name: clean_doc, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'document':documents})\n",
    "print(df.head(3))\n",
    "\n",
    "df['clean_doc'] = df['document'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
    "print(df.clean_doc[:3])\n",
    "\n",
    "df['clean_doc'] = df['clean_doc'].apply(lambda x: ' '.join([word for word in x.split() if len(word) > 3]))\n",
    "print(df.clean_doc[:3])\n",
    "\n",
    "df['clean_doc'] = df['clean_doc'].apply(lambda x: x.lower())\n",
    "print(df.clean_doc[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T03:42:53.710923Z",
     "start_time": "2023-12-29T03:42:53.123238Z"
    }
   },
   "id": "1535599f18e901d7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons\n"
     ]
    }
   ],
   "source": [
    "print(df['clean_doc'][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T03:42:53.711164Z",
     "start_time": "2023-12-29T03:42:53.695739Z"
    }
   },
   "id": "4fd48be67e2d4eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed16fc3ab0007fe8"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T04:06:08.694560Z",
     "start_time": "2023-12-29T04:06:08.685385Z"
    }
   },
   "id": "6669254255b45433"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "tokenized_doc = df['clean_doc'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [word for word in x if word not in stop])\n",
    "\n",
    "print(tokenized_doc[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T03:42:55.073863Z",
     "start_time": "2023-12-29T03:42:53.892704Z"
    }
   },
   "id": "2396da24d72d6693"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64281 11314\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 4), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1)]\n",
      "israels\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_doc)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
    "\n",
    "# check corpus and dictionary\n",
    "print(len(dictionary), len(corpus))\n",
    "print(corpus[0])\n",
    "print(dictionary[22])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T03:56:21.377413Z",
     "start_time": "2023-12-29T03:56:20.554439Z"
    }
   },
   "id": "279f5318b65f8107"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling LDA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3628221e85febf"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "num_topics = 20\n",
    "model = gensim.models.ldamodel.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15) # passes : the number of iterations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T04:07:36.487076Z",
     "start_time": "2023-12-29T04:06:53.960653Z"
    }
   },
   "id": "41811e1360811c95"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.013*\"would\" + 0.011*\"like\" + 0.008*\"think\" + 0.008*\"good\"')\n",
      "(1, '0.012*\"people\" + 0.010*\"would\" + 0.005*\"jesus\" + 0.005*\"many\"')\n",
      "(2, '0.019*\"sale\" + 0.017*\"price\" + 0.015*\"shipping\" + 0.014*\"offer\"')\n",
      "(3, '0.053*\"space\" + 0.017*\"nasa\" + 0.012*\"launch\" + 0.011*\"earth\"')\n",
      "(4, '0.019*\"armenian\" + 0.018*\"turkish\" + 0.014*\"health\" + 0.014*\"armenians\"')\n",
      "(5, '0.033*\"thanks\" + 0.026*\"anyone\" + 0.025*\"know\" + 0.025*\"would\"')\n",
      "(6, '0.014*\"available\" + 0.013*\"information\" + 0.010*\"also\" + 0.010*\"software\"')\n",
      "(7, '0.010*\"research\" + 0.009*\"center\" + 0.009*\"university\" + 0.009*\"data\"')\n",
      "(8, '0.011*\"cubs\" + 0.010*\"kent\" + 0.009*\"compass\" + 0.008*\"scores\"')\n",
      "(9, '0.023*\"ripem\" + 0.018*\"bits\" + 0.014*\"part\" + 0.012*\"random\"')\n",
      "(10, '0.022*\"file\" + 0.014*\"program\" + 0.011*\"output\" + 0.011*\"window\"')\n",
      "(11, '0.015*\"year\" + 0.015*\"chicago\" + 0.014*\"detroit\" + 0.013*\"york\"')\n",
      "(12, '0.019*\"said\" + 0.012*\"people\" + 0.010*\"went\" + 0.008*\"children\"')\n",
      "(13, '0.024*\"sound\" + 0.012*\"sony\" + 0.012*\"monitors\" + 0.009*\"helmet\"')\n",
      "(14, '0.016*\"government\" + 0.014*\"president\" + 0.010*\"state\" + 0.009*\"states\"')\n",
      "(15, '0.015*\"chip\" + 0.014*\"encryption\" + 0.012*\"clipper\" + 0.011*\"keys\"')\n",
      "(16, '0.011*\"cover\" + 0.009*\"copies\" + 0.007*\"mary\" + 0.007*\"appears\"')\n",
      "(17, '0.028*\"game\" + 0.024*\"team\" + 0.019*\"play\" + 0.019*\"games\"')\n",
      "(18, '0.036*\"drive\" + 0.024*\"disk\" + 0.023*\"scsi\" + 0.016*\"system\"')\n",
      "(19, '0.013*\"cross\" + 0.011*\"weaver\" + 0.009*\"outlet\" + 0.008*\"unit\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in model.print_topics(num_words=4):\n",
    "    print(topic)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T04:18:17.390110Z",
     "start_time": "2023-12-29T04:18:17.371059Z"
    }
   },
   "id": "cea8e3e6d78bddce"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 문서의 topic 비율은 [(0, 0.116479814), (1, 0.6111767), (4, 0.12856787), (9, 0.13063347)]\n",
      "1 번째 문서의 topic 비율은 [(0, 0.35182634), (1, 0.45541498), (2, 0.028739547), (7, 0.106837645), (8, 0.03742534)]\n",
      "2 번째 문서의 topic 비율은 [(0, 0.1679781), (1, 0.67871153), (15, 0.13912484)]\n",
      "3 번째 문서의 topic 비율은 [(0, 0.5967653), (1, 0.065252796), (15, 0.32446572)]\n",
      "4 번째 문서의 topic 비율은 [(0, 0.34629565), (12, 0.30610335), (17, 0.3161044)]\n"
     ]
    }
   ],
   "source": [
    "for i, topic_list in enumerate(model[corpus]):\n",
    "    if i==5:\n",
    "        break\n",
    "    print(i,'번째 문서의 topic 비율은',topic_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T04:19:47.352651Z",
     "start_time": "2023-12-29T04:19:47.343774Z"
    }
   },
   "id": "1ab15185722350ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9e0325918d1da685"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
