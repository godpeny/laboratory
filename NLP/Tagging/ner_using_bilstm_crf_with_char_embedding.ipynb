{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:48.836475Z",
     "start_time": "2023-11-25T08:47:46.046692Z"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048575\n",
      "    Sentence #           Word  POS Tag\n",
      "0  Sentence: 1      Thousands  NNS   O\n",
      "1          NaN             of   IN   O\n",
      "2          NaN  demonstrators  NNS   O\n",
      "3          NaN           have  VBP   O\n",
      "4          NaN        marched  VBN   O\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/\"\n",
    "df = pd.read_csv(data_path + \"ner_dataset.csv\", encoding=\"latin1\")\n",
    "\n",
    "print(len(df))\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:48.836806Z",
     "start_time": "2023-11-25T08:47:48.479193Z"
    }
   },
   "id": "95c0fcd84091c464"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7a8a95bf774ef99"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47959 35177 17\n",
      "      Tag  counts\n",
      "0   B-art     402\n",
      "1   B-eve     308\n",
      "2   B-geo   37644\n",
      "3   B-gpe   15870\n",
      "4   B-nat     201\n",
      "5   B-org   20143\n",
      "6   B-per   16990\n",
      "7   B-tim   20333\n",
      "8   I-art     297\n",
      "9   I-eve     253\n",
      "10  I-geo    7414\n",
      "11  I-gpe     198\n",
      "12  I-nat      51\n",
      "13  I-org   16784\n",
      "14  I-per   17251\n",
      "15  I-tim    6528\n",
      "16      O  887908\n"
     ]
    }
   ],
   "source": [
    "# see 'Tag' distribution\n",
    "print(df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique())\n",
    "print(df.groupby('Tag').size().reset_index(name='counts'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:48.836888Z",
     "start_time": "2023-11-25T08:47:48.704620Z"
    }
   },
   "id": "e5d49e154c6e592c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "              Sentence #       Word  POS    Tag\n",
      "1048565  Sentence: 47958     impact   NN      O\n",
      "1048566  Sentence: 47958          .    .      O\n",
      "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
      "1048568  Sentence: 47959     forces  NNS      O\n",
      "1048569  Sentence: 47959       said  VBD      O\n",
      "1048570  Sentence: 47959       they  PRP      O\n",
      "1048571  Sentence: 47959  responded  VBD      O\n",
      "1048572  Sentence: 47959         to   TO      O\n",
      "1048573  Sentence: 47959        the   DT      O\n",
      "1048574  Sentence: 47959     attack   NN      O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/76/r353dd3n1cb9npy26cwjvyz00000gn/T/ipykernel_1879/3415340063.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\") # fill NaN with previous value\n"
     ]
    }
   ],
   "source": [
    "# fill NaN with previous value\n",
    "df = df.fillna(method=\"ffill\") # fill NaN with previous value\n",
    "print(df.isnull().values.any())\n",
    "print(df.tail(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:49.102568Z",
     "start_time": "2023-11-25T08:47:48.969422Z"
    }
   },
   "id": "7650cab060beb129"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47959 31817 17\n"
     ]
    }
   ],
   "source": [
    "df['Word'] = df['Word'].str.lower() # lowercase \n",
    "print(df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:49.290053Z",
     "start_time": "2023-11-25T08:47:49.125845Z"
    }
   },
   "id": "cd78b89150acaafa"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# get word and tag in each sentence\n",
    "func = lambda temp: [(word, tag) for word, tag in zip(temp[\"Word\"].values.tolist(), temp[\"Tag\"].values.tolist())]\n",
    "tagged_sentences=[t for t in df.groupby(\"Sentence #\").apply(func)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:50.548185Z",
     "start_time": "2023-11-25T08:47:49.294113Z"
    }
   },
   "id": "43851432a3defb74"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:50.551977Z",
     "start_time": "2023-11-25T08:47:50.548310Z"
    }
   },
   "id": "d407d1fed4ffc02b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# get sentence and tag\n",
    "sentences, tags = [], []\n",
    "\n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tag = zip(*tagged_sentence)\n",
    "    sentences.append(list(sentence))\n",
    "    tags.append(list(tag))\n",
    "\n",
    "print(sentences[0])\n",
    "print(tags[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:50.725368Z",
     "start_time": "2023-11-25T08:47:50.595317Z"
    }
   },
   "id": "bcca8d13c37512a6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length: 104, average sentence length: 21.863987989741236\n"
     ]
    }
   ],
   "source": [
    "max_sentence_len = max(len(s) for s in sentences)\n",
    "avg_sentence_len = sum(map(len, sentences))/len(sentences)\n",
    "print(\"max sentence length: {}, average sentence length: {}\".format(max_sentence_len, avg_sentence_len))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:50.729129Z",
     "start_time": "2023-11-25T08:47:50.727079Z"
    }
   },
   "id": "71e49c1148e15ce9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "408c21e4868d6ee9"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "sen_tokenizer = Tokenizer(oov_token=\"OOV\")\n",
    "tag_tokenizer = Tokenizer(lower=False) # keep the original case\n",
    "\n",
    "sen_tokenizer.fit_on_texts(sentences)\n",
    "tag_tokenizer.fit_on_texts(tags)\n",
    "\n",
    "X_data = sen_tokenizer.texts_to_sequences(sentences)\n",
    "y_data = tag_tokenizer.texts_to_sequences(tags)\n",
    "\n",
    "vocab_size = len(sen_tokenizer.word_index) + 1\n",
    "tag_size = len(tag_tokenizer.word_index) + 1\n",
    "\n",
    "word_index= sen_tokenizer.word_index\n",
    "index_word = sen_tokenizer.index_word"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:51.313971Z",
     "start_time": "2023-11-25T08:47:50.753951Z"
    }
   },
   "id": "aba27a9ff7db998c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38367, 70) (38367, 70, 18)\n",
      "(9592, 70) (9592, 70, 18)\n"
     ]
    }
   ],
   "source": [
    "max_len = 70 # hyperparameter\n",
    "\n",
    "X_data_pad = pad_sequences(X_data, padding=\"post\", maxlen=max_len)\n",
    "y_data_pad = pad_sequences(y_data, padding=\"post\", maxlen=max_len)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data_pad, y_data_pad, test_size=0.2, random_state=777)\n",
    "\n",
    "y_train_encod = to_categorical(y_train)\n",
    "y_test_encod = to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape, y_train_encod.shape)\n",
    "print(X_test.shape, y_test_encod.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:51.475051Z",
     "start_time": "2023-11-25T08:47:51.316888Z"
    }
   },
   "id": "717e91491a50890"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing with Character-Embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b50d8398fb80eea"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '~', '\\x85', '\\x91', '\\x92', '\\x93', '\\x94', '\\x96', '\\x97', '\\xa0', '°', 'é', 'ë', 'ö', 'ü']\n"
     ]
    }
   ],
   "source": [
    "max_char_len = 15 # hyperparameter\n",
    "\n",
    "words = list(set(df.Word.values)) # use set to remove duplicate words\n",
    "chars = set([char for word in words for char in word]) # get all characters with no duplicate\n",
    "chars = sorted(list(chars)) # sort characters\n",
    "\n",
    "print(chars)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:51.528173Z",
     "start_time": "2023-11-25T08:47:51.523593Z"
    }
   },
   "id": "3f7fa42a0c1815b0"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "char_index = {c:i+2 for i,c in enumerate(chars)} # index start from 2\n",
    "char_index[\"OOV\"] = 1 # OOV: Out of Vocabulary\n",
    "char_index[\"PAD\"] = 0 # PAD: Padding\n",
    "\n",
    "index_char = {i:c for c,i in char_index.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:51.528347Z",
     "start_time": "2023-11-25T08:47:51.526422Z"
    }
   },
   "id": "12ac40b887e9ea2e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "X_char = []\n",
    "# padding for each word\n",
    "for sentence in sentences:\n",
    "    char_indices = [[char_index[char] for char in word] for word in sentence]\n",
    "    char_indices_padded = pad_sequences(char_indices, maxlen=max_char_len, truncating=\"post\", padding=\"post\", value=0)\n",
    "    X_char.append(char_indices_padded)\n",
    "    \n",
    "# padding for each sentence\n",
    "X_char = pad_sequences(X_char, maxlen=max_len, padding=\"post\", value=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:52.771850Z",
     "start_time": "2023-11-25T08:47:51.531039Z"
    }
   },
   "id": "c4aee0524cdd2818"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 150  928  361   17 2624    9 4130 3566    9    8 2893 1250  880  107\n",
      "    3    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "soldiers\n",
      "s o l d i e r s PAD PAD PAD PAD PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "# check the first word in the first sentence\n",
    "# random state should be same with the previous one (X_train, X_test, y_train, y_test)\n",
    "X_char_train, X_char_test, _, _ = train_test_split(X_char, y_data_pad, test_size=0.2, random_state=777) \n",
    "\n",
    "print(X_train[0])\n",
    "print(index_word[X_train[0][0]])\n",
    "print(' '.join([index_char[index] for index in X_char_train[0][0]]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:47:52.818112Z",
     "start_time": "2023-11-25T08:47:52.773809Z"
    }
   },
   "id": "e693e02e09c05b52"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38367, 70) (9592, 70)\n",
      "(38367, 70, 15) (9592, 70, 15)\n",
      "(38367, 70) (9592, 70)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(X_char_train.shape, X_char_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T08:48:37.079444Z",
     "start_time": "2023-11-25T08:48:37.074418Z"
    }
   },
   "id": "b87e8ce44fada807"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. BiLSTM + CNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "995096358a8bb66e"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Embedding, Input, TimeDistributed, Dropout, concatenate, Bidirectional, LSTM, Conv1D, Dense, MaxPooling1D, Flatten\n",
    "from keras import Model\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "from keras_crf import CRFModel"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T09:34:00.255049Z",
     "start_time": "2023-11-25T09:34:00.241240Z"
    }
   },
   "id": "67c21a18361ebe78"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model_path = \"../model/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T09:17:13.126955Z",
     "start_time": "2023-11-25T09:17:13.118205Z"
    }
   },
   "id": "ab916c3580924c56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7b4ec5fe81e26ba"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " char_input (InputLayer)     [(None, None, 15)]           0         []                            \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, None, 15, 64)         4736      ['char_input[0][0]']          \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, None, 15, 64)         0         ['time_distributed[0][0]']    \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, None, 15, 30)         5790      ['dropout[0][0]']             \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDi  (None, None, 1, 30)          0         ['time_distributed_1[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " word_input (InputLayer)     [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDi  (None, None, 30)             0         ['time_distributed_2[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " word_embedding (Embedding)  (None, None, 128)            4072832   ['word_input[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, None, 30)             0         ['time_distributed_3[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, None, 158)            0         ['word_embedding[0][0]',      \n",
      "                                                                     'dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, None, 512)            849920    ['concatenate[0][0]']         \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, None, 512)            0         ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDi  (None, None, 18)             9234      ['dropout_2[0][0]']           \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4942512 (18.85 MB)\n",
      "Trainable params: 4942512 (18.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter\n",
    "embedding_dim = 128\n",
    "char_embedding_dim = 64\n",
    "dropout_rate = 0.5\n",
    "hidden_units = 256\n",
    "num_filters = 30 # num of kernels\n",
    "kernel_size = 3 \n",
    "\n",
    "# word embedding\n",
    "word_input = Input(shape=(None,), dtype=\"int32\", name=\"word_input\")\n",
    "word_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, name=\"word_embedding\")(word_input)\n",
    "\n",
    "# char embedding\n",
    "char_input = Input(shape=(None, max_char_len,), dtype=\"int32\", name=\"char_input\")\n",
    "char_embedding = TimeDistributed(Embedding(input_dim=len(char_index), output_dim=char_embedding_dim, name=\"char_embedding\",embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)))(char_input) # init: RandomUniform(minval=-0.5, maxval=0.5)\n",
    "char_dropout = Dropout(rate=dropout_rate)(char_embedding)\n",
    "\n",
    "# CNN\n",
    "char_cnn_embedding = TimeDistributed(Conv1D(filters=num_filters, kernel_size=kernel_size, padding=\"same\", activation=\"tanh\", strides=1))(char_dropout)\n",
    "char_cnn_embedding = TimeDistributed(MaxPooling1D(max_char_len))(char_cnn_embedding)\n",
    "char_cnn_embedding = TimeDistributed(Flatten())(char_cnn_embedding)\n",
    "char_cnn_embedding = Dropout(rate=dropout_rate)(char_cnn_embedding)\n",
    "\n",
    "# concat word and char embedding\n",
    "output = concatenate([word_embedding, char_cnn_embedding])\n",
    "output = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(output)\n",
    "output = Dropout(rate=dropout_rate)(output)\n",
    "output = TimeDistributed(Dense(tag_size, activation=\"softmax\"))(output)\n",
    "\n",
    "model = Model(inputs=[word_input, char_input], outputs=[output])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T09:14:42.788041Z",
     "start_time": "2023-11-25T09:14:42.381865Z"
    }
   },
   "id": "5d639ff475424da6"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# callbacks\n",
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=3)\n",
    "mc = ModelCheckpoint(model_path + \"ner_char_embedding_bilstm_cnn.h5\", monitor=\"val_accuracy\", mode=\"max\", verbose=1, save_best_only=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T09:17:51.957170Z",
     "start_time": "2023-11-25T09:17:51.938311Z"
    }
   },
   "id": "e3d0b11409d432c6"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.9478\n",
      "Epoch 1: val_accuracy improved from -inf to 0.97804, saving model to ../model/ner_char_embedding_bilstm_cnn.h5\n",
      "270/270 [==============================] - 76s 276ms/step - loss: 0.2093 - accuracy: 0.9478 - val_loss: 0.0805 - val_accuracy: 0.9780\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/godpeny/Code/venv/laboratory/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9829\n",
      "Epoch 2: val_accuracy improved from 0.97804 to 0.98545, saving model to ../model/ner_char_embedding_bilstm_cnn.h5\n",
      "270/270 [==============================] - 77s 286ms/step - loss: 0.0598 - accuracy: 0.9829 - val_loss: 0.0494 - val_accuracy: 0.9854\n",
      "Epoch 3/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9877\n",
      "Epoch 3: val_accuracy improved from 0.98545 to 0.98692, saving model to ../model/ner_char_embedding_bilstm_cnn.h5\n",
      "270/270 [==============================] - 78s 288ms/step - loss: 0.0423 - accuracy: 0.9877 - val_loss: 0.0436 - val_accuracy: 0.9869\n",
      "Epoch 4/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9894\n",
      "Epoch 4: val_accuracy improved from 0.98692 to 0.98732, saving model to ../model/ner_char_embedding_bilstm_cnn.h5\n",
      "270/270 [==============================] - 78s 290ms/step - loss: 0.0355 - accuracy: 0.9894 - val_loss: 0.0422 - val_accuracy: 0.9873\n",
      "Epoch 5/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9906\n",
      "Epoch 5: val_accuracy did not improve from 0.98732\n",
      "270/270 [==============================] - 78s 289ms/step - loss: 0.0311 - accuracy: 0.9906 - val_loss: 0.0430 - val_accuracy: 0.9871\n",
      "Epoch 6/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9914\n",
      "Epoch 6: val_accuracy did not improve from 0.98732\n",
      "270/270 [==============================] - 79s 294ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.0437 - val_accuracy: 0.9867\n",
      "Epoch 7/15\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9921\n",
      "Epoch 7: val_accuracy improved from 0.98732 to 0.98736, saving model to ../model/ner_char_embedding_bilstm_cnn.h5\n",
      "270/270 [==============================] - 78s 290ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.0428 - val_accuracy: 0.9874\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train, X_char_train], y_train_encod, batch_size=128, epochs=15, validation_split=0.1, callbacks=[es, mc])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T09:27:15.936472Z",
     "start_time": "2023-11-25T09:18:10.991824Z"
    }
   },
   "id": "84dafb53f1bdfa32"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating with F1-score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f617983d7e08269"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 291ms/step\n",
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "the              : O       O\n",
      "statement        : O       O\n",
      "came             : O       O\n",
      "as               : O       O\n",
      "u.n.             : B-org   B-org\n",
      "secretary-general: I-org   I-org\n",
      "kofi             : B-per   B-per\n",
      "annan            : I-per   I-per\n",
      "met              : O       O\n",
      "with             : O       O\n",
      "officials        : O       O\n",
      "in               : O       O\n",
      "amman            : B-geo   B-geo\n",
      "to               : O       O\n",
      "discuss          : O       O\n",
      "wednesday        : B-tim   B-tim\n",
      "'s               : O       O\n",
      "attacks          : O       O\n",
      ".                : O       O\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(model_path + \"ner_char_embedding_bilstm_cnn.h5\")\n",
    "\n",
    "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "# 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])\n",
    "\n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # 확률 벡터를 정수 인코딩으로 변경.\n",
    "labels = np.argmax(y_test_encod[i], -1) # 원-핫 인코딩을 정수 인코딩으로 변경.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
    "    if word != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(sen_tokenizer.index_word[word], tag_tokenizer.index_word[tag], tag_tokenizer.index_word[pred]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T09:28:58.465287Z",
     "start_time": "2023-11-25T09:28:57.853685Z"
    }
   },
   "id": "eacddad6b96a0e04"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def sequences_to_tag(sequences):\n",
    "    result = []\n",
    "    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
    "    for sequence in sequences:\n",
    "        word_sequence = []\n",
    "        # 시퀀스로부터 확률 벡터 또는 원-핫 벡터를 하나씩 꺼낸다.\n",
    "        for pred in sequence:\n",
    "            # 정수로 변환. 예를 들어 pred가 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
    "            pred_index = np.argmax(pred)\n",
    "            # index_word 사용하여 정수를 태깅 정보로 변환. 'PAD'는 'O'로 변경.\n",
    "            if pred_index == 0: # PAD\n",
    "                word_sequence.append(\"O\")\n",
    "            else:\n",
    "                word_sequence.append(tag_tokenizer.index_word[pred_index].replace(\"PAD\", \"O\"))\n",
    "        result.append(word_sequence)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T09:29:53.607753Z",
     "start_time": "2023-11-25T09:29:53.588410Z"
    }
   },
   "id": "30d05983cf139094"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 19s 64ms/step\n",
      "F1-score: 78.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/godpeny/Code/venv/laboratory/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.00      0.00      0.00        63\n",
      "         eve       0.64      0.27      0.38        52\n",
      "         geo       0.82      0.85      0.84      7620\n",
      "         gpe       0.94      0.94      0.94      3145\n",
      "         nat       0.58      0.19      0.29        37\n",
      "         org       0.59      0.57      0.58      4033\n",
      "         per       0.72      0.71      0.72      3545\n",
      "         tim       0.86      0.84      0.85      4067\n",
      "\n",
      "   micro avg       0.79      0.78      0.79     22562\n",
      "   macro avg       0.64      0.55      0.57     22562\n",
      "weighted avg       0.79      0.78      0.78     22562\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict([X_test, X_char_test])\n",
    "pred_tags = sequences_to_tag(y_predicted)\n",
    "test_tags = sequences_to_tag(y_test_encod)\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
    "print(classification_report(test_tags, pred_tags))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T09:30:44.679118Z",
     "start_time": "2023-11-25T09:30:21.369060Z"
    }
   },
   "id": "a6c41994af762ac9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. BiLSTM + CNN + CRF"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6aa251032e6adf2d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6afa578bfaa31f37"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"crf_model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " char_input (InputLayer)     [(None, None, 15)]           0         []                            \n",
      "                                                                                                  \n",
      " time_distributed_10 (TimeD  (None, None, 15, 64)         4736      ['char_input[0][0]']          \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, None, 15, 64)         0         ['time_distributed_10[0][0]'] \n",
      "                                                                                                  \n",
      " time_distributed_11 (TimeD  (None, None, 15, 30)         5790      ['dropout_6[0][0]']           \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_12 (TimeD  (None, None, 1, 30)          0         ['time_distributed_11[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " word_input (InputLayer)     [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " time_distributed_13 (TimeD  (None, None, 30)             0         ['time_distributed_12[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " word_embedding (Embedding)  (None, None, 128)            4072832   ['word_input[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, None, 30)             0         ['time_distributed_13[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, None, 158)            0         ['word_embedding[0][0]',      \n",
      " )                                                                   'dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirecti  (None, None, 512)            849920    ['concatenate_2[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, None, 512)            0         ['bidirectional_2[0][0]']     \n",
      "                                                                                                  \n",
      " time_distributed_14 (TimeD  (None, None, 18)             9234      ['dropout_8[0][0]']           \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " crf_1 (CRF)                 [(None, None),               702       ['time_distributed_14[0][0]'] \n",
      "                              (None, None, 18),                                                   \n",
      "                              (None,),                                                            \n",
      "                              (18, 18)]                                                           \n",
      "                                                                                                  \n",
      " decode_sequence (Lambda)    (None, None)                 0         ['crf_1[0][0]']               \n",
      "                                                                                                  \n",
      " potentials (Lambda)         (None, None, 18)             0         ['crf_1[0][1]']               \n",
      "                                                                                                  \n",
      " sequence_length (Lambda)    (None,)                      0         ['crf_1[0][2]']               \n",
      "                                                                                                  \n",
      " kernel (Lambda)             (18, 18)                     0         ['crf_1[0][3]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4943214 (18.86 MB)\n",
      "Trainable params: 4943214 (18.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter\n",
    "embedding_dim = 128\n",
    "char_embedding_dim = 64\n",
    "dropout_rate = 0.5\n",
    "hidden_units = 256\n",
    "num_filters = 30 # num of kernels\n",
    "kernel_size = 3\n",
    "\n",
    "# word embedding\n",
    "word_input = Input(shape=(None,), dtype=\"int32\", name=\"word_input\")\n",
    "word_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, name=\"word_embedding\")(word_input)\n",
    "\n",
    "# char embedding\n",
    "char_input = Input(shape=(None, max_char_len,), dtype=\"int32\", name=\"char_input\")\n",
    "char_embedding = TimeDistributed(Embedding(input_dim=len(char_index), output_dim=char_embedding_dim, name=\"char_embedding\",embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)))(char_input) # init: RandomUniform(minval=-0.5, maxval=0.5)\n",
    "char_dropout = Dropout(rate=dropout_rate)(char_embedding)\n",
    "\n",
    "# CNN\n",
    "char_cnn_embedding = TimeDistributed(Conv1D(filters=num_filters, kernel_size=kernel_size, padding=\"same\", activation=\"tanh\", strides=1))(char_dropout)\n",
    "char_cnn_embedding = TimeDistributed(MaxPooling1D(max_char_len))(char_cnn_embedding)\n",
    "char_cnn_embedding = TimeDistributed(Flatten())(char_cnn_embedding)\n",
    "char_cnn_embedding = Dropout(rate=dropout_rate)(char_cnn_embedding)\n",
    "\n",
    "# concat word and char embedding\n",
    "output = concatenate([word_embedding, char_cnn_embedding])\n",
    "output = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(output)\n",
    "output = Dropout(rate=dropout_rate)(output)\n",
    "output = TimeDistributed(Dense(tag_size, activation=\"relu\"))(output)\n",
    "\n",
    "model = Model(inputs=[word_input, char_input], outputs=[output])\n",
    "model = CRFModel(model, tag_size)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(0.001), metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T10:17:35.006746Z",
     "start_time": "2023-11-25T10:17:34.732839Z"
    }
   },
   "id": "24b09445cb2f44e5"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# callbacks\n",
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=3)\n",
    "mc = ModelCheckpoint(model_path + \"ner_char_embedding_bilstm_cnn_crf.ckpt\", monitor=\"val_decode_sequence_accuracy\", mode=\"max\", verbose=1, save_best_only=True, save_weights_only=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T10:18:35.630065Z",
     "start_time": "2023-11-25T10:18:35.616929Z"
    }
   },
   "id": "c4888fab7313fca7"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9600 - loss: 10.4860\n",
      "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.97300, saving model to ../model/ner_char_embedding_bilstm_cnn_crf.ckpt\n",
      "270/270 [==============================] - 86s 318ms/step - decode_sequence_accuracy: 0.9600 - loss: 10.4672 - val_decode_sequence_accuracy: 0.9730 - val_loss: 6.7449\n",
      "Epoch 2/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9802 - loss: 4.4477\n",
      "Epoch 2: val_decode_sequence_accuracy improved from 0.97300 to 0.98363, saving model to ../model/ner_char_embedding_bilstm_cnn_crf.ckpt\n",
      "270/270 [==============================] - 85s 316ms/step - decode_sequence_accuracy: 0.9802 - loss: 4.4469 - val_decode_sequence_accuracy: 0.9836 - val_loss: 3.4534\n",
      "Epoch 3/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9866 - loss: 2.7226\n",
      "Epoch 3: val_decode_sequence_accuracy improved from 0.98363 to 0.98534, saving model to ../model/ner_char_embedding_bilstm_cnn_crf.ckpt\n",
      "270/270 [==============================] - 85s 314ms/step - decode_sequence_accuracy: 0.9866 - loss: 2.7213 - val_decode_sequence_accuracy: 0.9853 - val_loss: 3.0461\n",
      "Epoch 4/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9887 - loss: 2.1529\n",
      "Epoch 4: val_decode_sequence_accuracy did not improve from 0.98534\n",
      "270/270 [==============================] - 85s 314ms/step - decode_sequence_accuracy: 0.9887 - loss: 2.1546 - val_decode_sequence_accuracy: 0.9850 - val_loss: 2.8198\n",
      "Epoch 5/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9899 - loss: 1.8172\n",
      "Epoch 5: val_decode_sequence_accuracy improved from 0.98534 to 0.98542, saving model to ../model/ner_char_embedding_bilstm_cnn_crf.ckpt\n",
      "270/270 [==============================] - 84s 313ms/step - decode_sequence_accuracy: 0.9899 - loss: 1.8173 - val_decode_sequence_accuracy: 0.9854 - val_loss: 2.8498\n",
      "Epoch 6/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9908 - loss: 1.5933\n",
      "Epoch 6: val_decode_sequence_accuracy did not improve from 0.98542\n",
      "270/270 [==============================] - 85s 316ms/step - decode_sequence_accuracy: 0.9908 - loss: 1.5927 - val_decode_sequence_accuracy: 0.9851 - val_loss: 2.7958\n",
      "Epoch 7/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9915 - loss: 1.4045\n",
      "Epoch 7: val_decode_sequence_accuracy improved from 0.98542 to 0.98560, saving model to ../model/ner_char_embedding_bilstm_cnn_crf.ckpt\n",
      "270/270 [==============================] - 84s 312ms/step - decode_sequence_accuracy: 0.9915 - loss: 1.4024 - val_decode_sequence_accuracy: 0.9856 - val_loss: 2.9671\n",
      "Epoch 8/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9921 - loss: 1.2572\n",
      "Epoch 8: val_decode_sequence_accuracy improved from 0.98560 to 0.98583, saving model to ../model/ner_char_embedding_bilstm_cnn_crf.ckpt\n",
      "270/270 [==============================] - 84s 313ms/step - decode_sequence_accuracy: 0.9921 - loss: 1.2572 - val_decode_sequence_accuracy: 0.9858 - val_loss: 3.0383\n",
      "Epoch 9/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9926 - loss: 1.1340\n",
      "Epoch 9: val_decode_sequence_accuracy did not improve from 0.98583\n",
      "270/270 [==============================] - 85s 315ms/step - decode_sequence_accuracy: 0.9926 - loss: 1.1336 - val_decode_sequence_accuracy: 0.9857 - val_loss: 2.8922\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train, X_char_train], y_train, batch_size=128, epochs=15, validation_split=0.1, callbacks=[es, mc])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T10:31:21.459896Z",
     "start_time": "2023-11-25T10:18:37.405419Z"
    }
   },
   "id": "70edc23effb83c95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating with F1-score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "614bdf48451d0206"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 475ms/step\n",
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "the              : O       O\n",
      "statement        : O       O\n",
      "came             : O       O\n",
      "as               : O       O\n",
      "u.n.             : B-org   B-org\n",
      "secretary-general: I-org   I-org\n",
      "kofi             : B-per   B-per\n",
      "annan            : I-per   I-per\n",
      "met              : O       O\n",
      "with             : O       O\n",
      "officials        : O       O\n",
      "in               : O       O\n",
      "amman            : B-geo   B-geo\n",
      "to               : O       O\n",
      "discuss          : O       O\n",
      "wednesday        : B-tim   B-tim\n",
      "'s               : O       O\n",
      "attacks          : O       O\n",
      ".                : O       O\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(model_path + \"ner_char_embedding_bilstm_cnn_crf.ckpt\")\n",
    "\n",
    "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])[0]\n",
    "labels = np.argmax(y_test_encod[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
    "    if word != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(sen_tokenizer.index_word[word], tag_tokenizer.index_word[tag], tag_tokenizer.index_word[pred]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T10:31:49.575023Z",
     "start_time": "2023-11-25T10:31:49.011634Z"
    }
   },
   "id": "195801f189731be7"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 19s 64ms/step\n",
      "[[ 1  3 10  1  2  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  1  1  1  1  1  3  1  1  1  1  1  1  1  2  9  9  1  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict([X_test, X_char_test])[0]\n",
    "print(y_predicted[:2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T10:32:09.783124Z",
     "start_time": "2023-11-25T10:31:50.571934Z"
    }
   },
   "id": "72421da414627743"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 79.9%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.00      0.00      0.00        63\n",
      "         eve       0.48      0.27      0.35        52\n",
      "         geo       0.83      0.86      0.84      7620\n",
      "         gpe       0.96      0.93      0.94      3145\n",
      "         nat       0.50      0.19      0.27        37\n",
      "         org       0.68      0.55      0.61      4033\n",
      "         per       0.76      0.69      0.72      3545\n",
      "         tim       0.86      0.84      0.85      4067\n",
      "\n",
      "   micro avg       0.82      0.78      0.80     22562\n",
      "   macro avg       0.63      0.54      0.57     22562\n",
      "weighted avg       0.81      0.78      0.79     22562\n"
     ]
    }
   ],
   "source": [
    "def sequences_to_tag_for_crf(sequences):\n",
    "    result = []\n",
    "    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
    "    for sequence in sequences:\n",
    "        word_sequence = []\n",
    "        # 시퀀스로부터 예측 정수 레이블을 하나씩 꺼낸다.\n",
    "        for pred_index in sequence:\n",
    "            # 정수를 태깅 정보로 변환. 'PAD'는 'O'로 변경.\n",
    "            if pred_index == 0: # PAD\n",
    "                word_sequence.append(\"O\")\n",
    "            else:\n",
    "                word_sequence.append(tag_tokenizer.index_word[pred_index].replace(\"PAD\", \"O\"))\n",
    "        result.append(word_sequence)\n",
    "    return result\n",
    "\n",
    "pred_tags = sequences_to_tag_for_crf(y_predicted)\n",
    "test_tags = sequences_to_tag(y_test_encod) # not using 'y_test_encod' because CRF does not need one-hot encoding\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
    "print(classification_report(test_tags, pred_tags))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T10:32:16.283221Z",
     "start_time": "2023-11-25T10:32:12.171236Z"
    }
   },
   "id": "5d133e3a5923d3ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. BiLSTM-BiLSTM + CRF"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2145b9b63308aa9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f096a9b4acca98e"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"crf_model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " char_input (InputLayer)     [(None, None, None)]         0         []                            \n",
      "                                                                                                  \n",
      " word_input (InputLayer)     [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " char_embedding (Embedding)  (None, None, None, 64)       4736      ['char_input[0][0]']          \n",
      "                                                                                                  \n",
      " word_embedding (Embedding)  (None, None, 128)            4072832   ['word_input[0][0]']          \n",
      "                                                                                                  \n",
      " time_distributed_30 (TimeD  (None, None, 512)            657408    ['char_embedding[0][0]']      \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate  (None, None, 640)            0         ['word_embedding[0][0]',      \n",
      " )                                                                   'time_distributed_30[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)        (None, None, 640)            0         ['concatenate_9[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_21 (Bidirect  (None, None, 512)            1837056   ['dropout_19[0][0]']          \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)        (None, None, 512)            0         ['bidirectional_21[0][0]']    \n",
      "                                                                                                  \n",
      " time_distributed_31 (TimeD  (None, None, 18)             9234      ['dropout_20[0][0]']          \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " crf_5 (CRF)                 [(None, None),               702       ['time_distributed_31[0][0]'] \n",
      "                              (None, None, 18),                                                   \n",
      "                              (None,),                                                            \n",
      "                              (18, 18)]                                                           \n",
      "                                                                                                  \n",
      " decode_sequence (Lambda)    (None, None)                 0         ['crf_5[0][0]']               \n",
      "                                                                                                  \n",
      " potentials (Lambda)         (None, None, 18)             0         ['crf_5[0][1]']               \n",
      "                                                                                                  \n",
      " sequence_length (Lambda)    (None,)                      0         ['crf_5[0][2]']               \n",
      "                                                                                                  \n",
      " kernel (Lambda)             (18, 18)                     0         ['crf_5[0][3]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6581968 (25.11 MB)\n",
      "Trainable params: 6581968 (25.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter\n",
    "embedding_dim = 128\n",
    "char_embedding_dim = 64\n",
    "dropout_rate = 0.3\n",
    "hidden_units = 256\n",
    "\n",
    "# word embedding\n",
    "word_input = Input(batch_shape=(None,None), dtype=\"int32\", name=\"word_input\")\n",
    "word_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, name=\"word_embedding\")(word_input)\n",
    "\n",
    "# char embedding\n",
    "char_input = Input(batch_shape=(None, None, None), dtype=\"int32\", name=\"char_input\")\n",
    "char_embedding = Embedding(input_dim=len(char_index), output_dim=char_embedding_dim, name=\"char_embedding\",embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5))(char_input) # init: RandomUniform(minval=-0.5, maxval=0.5\n",
    "# word embedding (# of char(batch_size) * char_embedding) -> word_embedding\n",
    "word_embedding_char = TimeDistributed(Bidirectional(LSTM(units=hidden_units, return_sequences=False)))(char_embedding) # many-to-one\n",
    "\n",
    "# concat word and char embedding\n",
    "output = concatenate([word_embedding, word_embedding_char])\n",
    "output = Dropout(rate=dropout_rate)(output)\n",
    "output = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(output)\n",
    "output = Dropout(rate=dropout_rate)(output)\n",
    "output = TimeDistributed(Dense(tag_size, activation=\"relu\"))(output)\n",
    "\n",
    "model = Model(inputs=[word_input, char_input], outputs=[output])\n",
    "model = CRFModel(model, tag_size)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(0.001), metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T11:29:43.495533Z",
     "start_time": "2023-11-25T11:29:43.065681Z"
    }
   },
   "id": "22ee5f76ac8b62d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### char_embedding = TimeDistributed(Bidirectional(LSTM(units=hidden_units, return_sequences=False)))(char_embedding)\n",
    " - many-to-one because return_sequences=False and TimeDistributed\n",
    " - many-to-one으로 하면 char_embedding의 shape이 (batch_size, max_char_len, hidden_units)가 되어서 word_embedding과 concat할 수 있음\n",
    " - 하나의 단어 벡터를 의미한다. (문자 벡터 * 단어의 문자 갯수(batch) -> 단어 벡터)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2007b1239202751"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=3)\n",
    "mc = ModelCheckpoint(model_path + \"ner_char_embedding_bilstm_crf.ckpt\", monitor=\"val_decode_sequence_accuracy\", mode=\"max\", verbose=1, save_best_only=True, save_weights_only=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T11:00:28.654633Z",
     "start_time": "2023-11-25T11:00:28.618573Z"
    }
   },
   "id": "aca14d341e25975f"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9484 - loss: 14.6737\n",
      "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.97605, saving model to ../model/ner_char_embedding_bilstm_crf.ckpt\n",
      "270/270 [==============================] - 440s 2s/step - decode_sequence_accuracy: 0.9484 - loss: 14.6383 - val_decode_sequence_accuracy: 0.9760 - val_loss: 5.6052\n",
      "Epoch 2/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9817 - loss: 4.0914\n",
      "Epoch 2: val_decode_sequence_accuracy improved from 0.97605 to 0.98460, saving model to ../model/ner_char_embedding_bilstm_crf.ckpt\n",
      "270/270 [==============================] - 433s 2s/step - decode_sequence_accuracy: 0.9817 - loss: 4.0866 - val_decode_sequence_accuracy: 0.9846 - val_loss: 3.1063\n",
      "Epoch 3/15\n",
      "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9867 - loss: 2.7142\n",
      "Epoch 3: val_decode_sequence_accuracy improved from 0.98460 to 0.98662, saving model to ../model/ner_char_embedding_bilstm_crf.ckpt\n",
      "270/270 [==============================] - 447s 2s/step - decode_sequence_accuracy: 0.9867 - loss: 2.7116 - val_decode_sequence_accuracy: 0.9866 - val_loss: 2.6682\n",
      "Epoch 4/15\n",
      "  4/270 [..............................] - ETA: 6:50 - decode_sequence_accuracy: 0.9894 - loss: 2.2092"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[74], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_char_train\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmc\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1266\u001B[0m     args,\n\u001B[1;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1268\u001B[0m     executing_eagerly)\n\u001B[1;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    262\u001B[0m     )\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1494\u001B[0m   )\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[1;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[1;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[1;32m     59\u001B[0m   ]\n\u001B[0;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train, X_char_train], y_train, batch_size=128, epochs=15, validation_split=0.1, callbacks=[es, mc])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T11:22:47.318023Z",
     "start_time": "2023-11-25T11:00:39.912900Z"
    }
   },
   "id": "564a42a59eb92b3b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating with F1-score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb126423e594d2d4"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "the              : O       O\n",
      "statement        : O       O\n",
      "came             : O       O\n",
      "as               : O       O\n",
      "u.n.             : B-org   B-org\n",
      "secretary-general: I-org   I-org\n",
      "kofi             : B-per   B-per\n",
      "annan            : I-per   I-per\n",
      "met              : O       O\n",
      "with             : O       O\n",
      "officials        : O       O\n",
      "in               : O       O\n",
      "amman            : B-geo   B-geo\n",
      "to               : O       O\n",
      "discuss          : O       O\n",
      "wednesday        : B-tim   B-tim\n",
      "'s               : O       O\n",
      "attacks          : O       O\n",
      ".                : O       O\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(model_path + \"ner_char_embedding_bilstm_crf.ckpt\")\n",
    "\n",
    "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "# 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])[0]\n",
    "labels = np.argmax(y_test_encod[i], -1) # 원-핫 벡터를 정수 인코딩으로 변경.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
    "    if word != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(sen_tokenizer.index_word[word], tag_tokenizer.index_word[tag], tag_tokenizer.index_word[pred]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T11:23:40.546559Z",
     "start_time": "2023-11-25T11:23:40.406041Z"
    }
   },
   "id": "7ba654ffdb418519"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 54s 179ms/step\n",
      "F1-score: 80.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/godpeny/Code/venv/laboratory/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.00      0.00      0.00        63\n",
      "         eve       1.00      0.04      0.07        52\n",
      "         geo       0.80      0.89      0.84      7620\n",
      "         gpe       0.94      0.94      0.94      3145\n",
      "         nat       0.00      0.00      0.00        37\n",
      "         org       0.70      0.49      0.58      4033\n",
      "         per       0.76      0.76      0.76      3545\n",
      "         tim       0.85      0.85      0.85      4067\n",
      "\n",
      "   micro avg       0.81      0.79      0.80     22562\n",
      "   macro avg       0.63      0.50      0.51     22562\n",
      "weighted avg       0.80      0.79      0.79     22562\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict([X_test, X_char_test])[0]\n",
    "pred_tags = sequences_to_tag_for_crf(y_predicted)\n",
    "test_tags = sequences_to_tag(y_test_encod) # not using 'y_test_encod' because CRF does not need one-hot encoding\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
    "print(classification_report(test_tags, pred_tags))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T11:27:40.810515Z",
     "start_time": "2023-11-25T11:26:42.785290Z"
    }
   },
   "id": "fc665ad41c970274"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bff4f6746c935284"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
