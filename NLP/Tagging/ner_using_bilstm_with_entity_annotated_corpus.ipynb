{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:43.310994Z",
     "start_time": "2023-11-23T13:11:40.190769Z"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048575\n",
      "    Sentence #           Word  POS Tag\n",
      "0  Sentence: 1      Thousands  NNS   O\n",
      "1          NaN             of   IN   O\n",
      "2          NaN  demonstrators  NNS   O\n",
      "3          NaN           have  VBP   O\n",
      "4          NaN        marched  VBN   O\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/\"\n",
    "df = pd.read_csv(data_path + \"ner_dataset.csv\", encoding=\"latin1\")\n",
    "\n",
    "print(len(df))\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:43.517271Z",
     "start_time": "2023-11-23T13:11:43.273749Z"
    }
   },
   "id": "95c0fcd84091c464"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7a8a95bf774ef99"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47959 35177 17\n",
      "      Tag  counts\n",
      "0   B-art     402\n",
      "1   B-eve     308\n",
      "2   B-geo   37644\n",
      "3   B-gpe   15870\n",
      "4   B-nat     201\n",
      "5   B-org   20143\n",
      "6   B-per   16990\n",
      "7   B-tim   20333\n",
      "8   I-art     297\n",
      "9   I-eve     253\n",
      "10  I-geo    7414\n",
      "11  I-gpe     198\n",
      "12  I-nat      51\n",
      "13  I-org   16784\n",
      "14  I-per   17251\n",
      "15  I-tim    6528\n",
      "16      O  887908\n"
     ]
    }
   ],
   "source": [
    "# see 'Tag' distribution\n",
    "print(df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique())\n",
    "print(df.groupby('Tag').size().reset_index(name='counts'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:43.624310Z",
     "start_time": "2023-11-23T13:11:43.524769Z"
    }
   },
   "id": "e5d49e154c6e592c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/76/r353dd3n1cb9npy26cwjvyz00000gn/T/ipykernel_1093/3415340063.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\") # fill NaN with previous value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "              Sentence #       Word  POS    Tag\n",
      "1048565  Sentence: 47958     impact   NN      O\n",
      "1048566  Sentence: 47958          .    .      O\n",
      "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
      "1048568  Sentence: 47959     forces  NNS      O\n",
      "1048569  Sentence: 47959       said  VBD      O\n",
      "1048570  Sentence: 47959       they  PRP      O\n",
      "1048571  Sentence: 47959  responded  VBD      O\n",
      "1048572  Sentence: 47959         to   TO      O\n",
      "1048573  Sentence: 47959        the   DT      O\n",
      "1048574  Sentence: 47959     attack   NN      O\n"
     ]
    }
   ],
   "source": [
    "# fill NaN with previous value\n",
    "df = df.fillna(method=\"ffill\") # fill NaN with previous value\n",
    "print(df.isnull().values.any())\n",
    "print(df.tail(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:43.928465Z",
     "start_time": "2023-11-23T13:11:43.621570Z"
    }
   },
   "id": "7650cab060beb129"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47959 31817 17\n"
     ]
    }
   ],
   "source": [
    "df['Word'] = df['Word'].str.lower() # lowercase \n",
    "print(df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:44.107580Z",
     "start_time": "2023-11-23T13:11:43.949425Z"
    }
   },
   "id": "cd78b89150acaafa"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# get word and tag in each sentence\n",
    "func = lambda temp: [(word, tag) for word, tag in zip(temp[\"Word\"].values.tolist(), temp[\"Tag\"].values.tolist())]\n",
    "tagged_sentences=[t for t in df.groupby(\"Sentence #\").apply(func)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:45.344689Z",
     "start_time": "2023-11-23T13:11:44.109997Z"
    }
   },
   "id": "43851432a3defb74"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_sentences[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:45.350027Z",
     "start_time": "2023-11-23T13:11:45.344845Z"
    }
   },
   "id": "d407d1fed4ffc02b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'london', 'to', 'protest', 'the', 'war', 'in', 'iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'british', 'troops', 'from', 'that', 'country', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# get sentence and tag\n",
    "sentences, tags = [], []\n",
    "\n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tag = zip(*tagged_sentence)\n",
    "    sentences.append(list(sentence))\n",
    "    tags.append(list(tag))\n",
    "\n",
    "print(sentences[0])\n",
    "print(tags[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:45.523475Z",
     "start_time": "2023-11-23T13:11:45.502934Z"
    }
   },
   "id": "bcca8d13c37512a6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length: 104, average sentence length: 21.863987989741236\n"
     ]
    }
   ],
   "source": [
    "max_sentence_len = max(len(s) for s in sentences)\n",
    "avg_sentence_len = sum(map(len, sentences))/len(sentences)\n",
    "print(\"max sentence length: {}, average sentence length: {}\".format(max_sentence_len, avg_sentence_len))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:45.527876Z",
     "start_time": "2023-11-23T13:11:45.523634Z"
    }
   },
   "id": "71e49c1148e15ce9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b50d8398fb80eea"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "31819\n",
      "18\n",
      "[254, 6, 967, 16, 1795, 238, 468, 7, 523, 2, 129, 5, 61, 9, 571, 2, 833, 6, 186, 90, 22, 15, 56, 3]\n",
      "[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "sen_tokenizer = Tokenizer(oov_token=\"OOV\")\n",
    "tag_tokenizer = Tokenizer(lower=False) # keep the original case\n",
    "\n",
    "sen_tokenizer.fit_on_texts(sentences)\n",
    "tag_tokenizer.fit_on_texts(tags)\n",
    "\n",
    "X_data = sen_tokenizer.texts_to_sequences(sentences)\n",
    "y_data = tag_tokenizer.texts_to_sequences(tags)\n",
    "\n",
    "vocab_size = len(sen_tokenizer.word_index) + 1\n",
    "tag_size = len(tag_tokenizer.word_index) + 1\n",
    "\n",
    "print(sen_tokenizer.word_index[\"OOV\"])\n",
    "print(vocab_size)\n",
    "print(tag_size)\n",
    "\n",
    "print(X_data[0])\n",
    "print(y_data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:46.110233Z",
     "start_time": "2023-11-23T13:11:45.583140Z"
    }
   },
   "id": "113b9a942112ea83"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38367, 70) (38367, 70, 18)\n",
      "(9592, 70) (9592, 70, 18)\n"
     ]
    }
   ],
   "source": [
    "max_len = 70 # hyperparameter\n",
    "\n",
    "X_data_pad = pad_sequences(X_data, padding=\"post\", maxlen=max_len)\n",
    "y_data_pad = pad_sequences(y_data, padding=\"post\", maxlen=max_len)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data_pad, y_data_pad, test_size=0.2, random_state=0)\n",
    "\n",
    "y_train_encod = to_categorical(y_train)\n",
    "y_test_encod = to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape, y_train_encod.shape)\n",
    "print(X_test.shape, y_test_encod.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:46.265039Z",
     "start_time": "2023-11-23T13:11:46.109736Z"
    }
   },
   "id": "74f9bece063cce7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d18174b66673c7c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
    "from keras.optimizers import Adam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:11:46.265271Z",
     "start_time": "2023-11-23T13:11:46.262001Z"
    }
   },
   "id": "afbe7b6f36427769"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 70, 128)           4072832   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 70, 512)           788480    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 70, 18)            9234      \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4870546 (18.58 MB)\n",
      "Trainable params: 4870546 (18.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter\n",
    "embedding_dim = 128\n",
    "hidden_units = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(units=hidden_units, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation=\"softmax\")))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(0.001), metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:21:19.794871Z",
     "start_time": "2023-11-23T13:21:19.052409Z"
    }
   },
   "id": "e132f4f736d0823c"
  },
  {
   "cell_type": "markdown",
   "source": [
    " #### If mask_zero is set to True, as a consequence, index 0 cannot be used in the vocabulary (input_dim should equal size of vocabulary + 1)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0e8fc3261bfe4c5"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "270/270 [==============================] - 70s 250ms/step - loss: 0.5606 - accuracy: 0.8756 - val_loss: 0.2575 - val_accuracy: 0.9281\n",
      "Epoch 2/6\n",
      "270/270 [==============================] - 76s 281ms/step - loss: 0.1791 - accuracy: 0.9485 - val_loss: 0.1566 - val_accuracy: 0.9543\n",
      "Epoch 3/6\n",
      "270/270 [==============================] - 76s 283ms/step - loss: 0.1195 - accuracy: 0.9640 - val_loss: 0.1414 - val_accuracy: 0.9587\n",
      "Epoch 4/6\n",
      "270/270 [==============================] - 78s 289ms/step - loss: 0.0968 - accuracy: 0.9701 - val_loss: 0.1402 - val_accuracy: 0.9581\n",
      "Epoch 5/6\n",
      "270/270 [==============================] - 79s 291ms/step - loss: 0.0824 - accuracy: 0.9738 - val_loss: 0.1411 - val_accuracy: 0.9599\n",
      "Epoch 6/6\n",
      "270/270 [==============================] - 77s 286ms/step - loss: 0.0724 - accuracy: 0.9766 - val_loss: 0.1453 - val_accuracy: 0.9586\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_encod, batch_size=128, epochs=6, validation_split=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:31:17.497659Z",
     "start_time": "2023-11-23T13:23:41.093350Z"
    }
   },
   "id": "c3e9bf460d46e901"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "jordan           : B-org   B-gpe\n",
      "'s               : O       O\n",
      "king             : B-per   B-per\n",
      "abdullah         : I-per   I-per\n",
      "joined           : O       O\n",
      "a                : O       O\n",
      "prayer           : O       O\n",
      "service          : O       O\n",
      "in               : O       O\n",
      "the              : O       O\n",
      "red              : B-geo   B-geo\n",
      "sea              : I-geo   I-geo\n",
      "port             : O       O\n",
      "of               : O       O\n",
      "aqaba            : B-geo   B-geo\n",
      ".                : O       O\n"
     ]
    }
   ],
   "source": [
    "i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # 확률 벡터를 정수 인코딩으로 변경함.\n",
    "labels = np.argmax(y_test_encod[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
    "    if word != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(sen_tokenizer.index_word[word], tag_tokenizer.index_word[tag], tag_tokenizer.index_word[pred]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T13:40:40.121212Z",
     "start_time": "2023-11-23T13:40:40.077225Z"
    }
   },
   "id": "332d3e14660d3ffb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate with F1-score\n",
    "## Precision vs Recall\n",
    " - the precision is the number of true positive results divided by the number of all positive results, including those not identified correctly. (=positive predictive value) (True라고 분류한 것 중에서 실제로 True인 것의 비율)\n",
    " - the recall is the number of true positive results divided by the number of all samples that should have been identified as positive. (=sensitivity) (실제 True인 것 중에서 모델이 True라고 예측한 것의 비율)\n",
    "## F1-score\n",
    "### https://en.wikipedia.org/wiki/F-score\n",
    " - the F1 score is the harmonic mean of precision and recall\n",
    " - the F1 score is the harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n",
    " - the F1 score weights recall more than precision by a factor of beta. beta == 1.0 means recall and precision are equally important.\n",
    " - the support is the number of occurrences of each class in y_true."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "979601292d137d3d"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T14:22:01.627228Z",
     "start_time": "2023-11-23T14:22:01.616157Z"
    }
   },
   "id": "88bc6bf6323b00bb"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def sequences_to_tag(sequences):\n",
    "    result = []\n",
    "    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
    "    for sequence in sequences:\n",
    "        word_sequence = []\n",
    "        # 시퀀스로부터 확률 벡터 또는 원-핫 벡터를 하나씩 꺼낸다.\n",
    "        for pred in sequence:\n",
    "            # 정수로 변환. 예를 들어 pred가 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
    "            pred_index = np.argmax(pred)\n",
    "            # index_word 사용하여 정수를 태깅 정보로 변환. 'PAD'는 'O'로 변경.\n",
    "            if pred_index == 0: # PAD\n",
    "                word_sequence.append(\"O\")\n",
    "            else:\n",
    "                word_sequence.append(tag_tokenizer.index_word[pred_index].replace(\"PAD\", \"O\"))\n",
    "        result.append(word_sequence)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T14:42:38.445444Z",
     "start_time": "2023-11-23T14:42:38.433936Z"
    }
   },
   "id": "9ab5670488412f0d"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 20s 66ms/step\n",
      "F1-score: 78.3%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         art       0.00      0.00      0.00        91\n",
      "         eve       0.68      0.29      0.41        65\n",
      "         geo       0.82      0.85      0.84      7584\n",
      "         gpe       0.96      0.92      0.94      3195\n",
      "         nat       0.55      0.26      0.35        47\n",
      "         org       0.59      0.59      0.59      4036\n",
      "         per       0.72      0.70      0.71      3403\n",
      "         tim       0.83      0.85      0.84      4149\n",
      "\n",
      "   micro avg       0.78      0.79      0.78     22570\n",
      "   macro avg       0.64      0.56      0.58     22570\n",
      "weighted avg       0.78      0.79      0.78     22570\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict([X_test])\n",
    "pred_tags = sequences_to_tag(y_predicted)\n",
    "test_tags = sequences_to_tag(y_test_encod)\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n",
    "print(classification_report(test_tags, pred_tags))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T14:43:06.128933Z",
     "start_time": "2023-11-23T14:42:42.299215Z"
    }
   },
   "id": "83dff278d4e4066e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
