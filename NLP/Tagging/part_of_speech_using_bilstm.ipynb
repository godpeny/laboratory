{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-19T00:58:42.419555Z",
     "start_time": "2023-11-19T00:58:40.078567Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/godpeny/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914\n",
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('treebank')\n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "#  check dataset\n",
    "print(len(tagged_sentences))\n",
    "print(tagged_sentences[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T01:03:50.430126Z",
     "start_time": "2023-11-19T01:03:50.054579Z"
    }
   },
   "id": "86d7da8c111b237e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3855922b178bb16"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'form', 'of', 'asbestos', 'once', 'used', '*', '*', 'to', 'make', 'Kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of', 'workers', 'exposed', '*', 'to', 'it', 'more', 'than', '30', 'years', 'ago', ',', 'researchers', 'reported', '0', '*T*-1', '.']\n",
      "['DT', 'NN', 'IN', 'NN', 'RB', 'VBN', '-NONE-', '-NONE-', 'TO', 'VB', 'NNP', 'NN', 'NNS', 'VBZ', 'VBN', 'DT', 'JJ', 'NN', 'IN', 'NN', 'NNS', 'IN', 'DT', 'NN', 'IN', 'NNS', 'VBN', '-NONE-', 'TO', 'PRP', 'RBR', 'IN', 'CD', 'NNS', 'IN', ',', 'NNS', 'VBD', '-NONE-', '-NONE-', '.']\n"
     ]
    }
   ],
   "source": [
    "# split sentences and tags from dataset\n",
    "sentences, tags =[], []\n",
    "\n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tag = zip(*tagged_sentence)\n",
    "    # save dataset\n",
    "    sentences.append(list(sentence))\n",
    "    tags.append(list(tag))\n",
    "    \n",
    "    \n",
    "print(sentences[3])\n",
    "print(tags[3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T01:08:52.250266Z",
     "start_time": "2023-11-19T01:08:51.864677Z"
    }
   },
   "id": "6c1e9d8c84e1a618"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 25.722023505365357\n"
     ]
    }
   ],
   "source": [
    "max_len_sentence = max(len(sentence) for sentence in sentences)\n",
    "avg_len_sentence = sum(map(len, sentences)) / len(sentences)\n",
    "\n",
    "print(max_len_sentence, avg_len_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T01:12:00.530471Z",
     "start_time": "2023-11-19T01:12:00.525119Z"
    }
   },
   "id": "3f7d7ceac807175"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "615e2a57ff3fb489"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5601, 3746, 1, 2024, 86, 331, 1, 46, 2405, 2, 131, 27, 6, 2025, 332, 459, 2026, 3], [31, 3746, 20, 177, 4, 5602, 2915, 1, 2, 2916, 637, 147, 3], [2917, 5603, 1, 1136, 86, 331, 8, 602, 177, 4, 3747, 1046, 892, 893, 1, 34, 483, 9, 6, 2025, 332, 4, 51, 1047, 435, 2918, 3]]\n",
      "[[3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9], [3, 3, 17, 1, 2, 3, 3, 8, 4, 3, 19, 1, 9], [3, 3, 8, 10, 6, 7, 14, 7, 1, 2, 3, 3, 3, 3, 8, 11, 16, 5, 4, 7, 1, 2, 4, 7, 7, 1, 9]]\n"
     ]
    }
   ],
   "source": [
    "sen_tokenizer = Tokenizer()\n",
    "tag_tokenizer = Tokenizer()\n",
    "\n",
    "sen_tokenizer.fit_on_texts(sentences)\n",
    "tag_tokenizer.fit_on_texts(tags)\n",
    "\n",
    "X_train = sen_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tag_tokenizer.texts_to_sequences(tags)\n",
    "\n",
    "sen_size = len(sen_tokenizer.word_index) + 1\n",
    "tag_size = len(tag_tokenizer.word_index) + 1\n",
    "\n",
    "print(X_train[:3])\n",
    "print(y_train[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T01:32:29.413635Z",
     "start_time": "2023-11-19T01:32:29.349412Z"
    }
   },
   "id": "efc1bb20419b7504"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# check length of sentences\n",
    "def len_sen(num):\n",
    "    cnt = 0\n",
    "    for sentence in X_train:\n",
    "        if len(sentence) > num:\n",
    "           cnt += 1\n",
    "    print((1-(cnt/len(X_train))) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T01:32:30.137494Z",
     "start_time": "2023-11-19T01:32:30.133903Z"
    }
   },
   "id": "b4c996f32c392c72"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.97445068983137\n"
     ]
    }
   ],
   "source": [
    "# padding\n",
    "len_sen(150) # if padding with max 150 length, 99.97% of sentences are included\n",
    "max_len = 150\n",
    "\n",
    "X_train_pad = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "y_train_pad = pad_sequences(y_train, padding='post', maxlen=max_len)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T01:32:30.800818Z",
     "start_time": "2023-11-19T01:32:30.781112Z"
    }
   },
   "id": "a613437d8c883614"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131, 150) (3131, 150)\n",
      "(783, 150) (783, 150)\n"
     ]
    }
   ],
   "source": [
    "# split train and test dataset\n",
    "X_train_pad, X_test_pad, y_train_pad, y_test_pad = train_test_split(X_train_pad, y_train_pad, test_size=0.2, random_state=777)\n",
    "\n",
    "print(X_train_pad.shape, y_train_pad.shape)\n",
    "print(X_test_pad.shape, y_test_pad.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T01:32:31.872487Z",
     "start_time": "2023-11-19T01:32:31.867446Z"
    }
   },
   "id": "1ca683accc9c8846"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bc53b752154189c"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
    "from keras.optimizers import Adam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T01:34:19.139787Z",
     "start_time": "2023-11-19T01:34:19.124749Z"
    }
   },
   "id": "7650cbd6e531c06d"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 128)         1457664   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, None, 256)         263168    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, None, 47)          12079     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1732911 (6.61 MB)\n",
      "Trainable params: 1732911 (6.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "embedding_dims = 128\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=sen_size, output_dim=embedding_dims, mask_zero=True)) # mask_zero=True : padding 0\n",
    "model.add(Bidirectional(LSTM(units=hidden_units, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T01:48:35.422619Z",
     "start_time": "2023-11-19T01:48:34.788148Z"
    }
   },
   "id": "7df23c4d1f823333"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### mask_zero : Boolean, whether or not the input value 0 is a special \"padding\" value that should be masked out. (0를 연산에서 제외)\n",
    "##### TimeDistributed : You can then use TimeDistributed to apply the same Conv2D layer to each of the timesteps, independently.(LSTM을 다 대 다 구조로 사용하여 LSTM의 모든 시점에 대해서 출력층을 사용)\n",
    "##### SparseCategoricalCrossentropy : Use this crossentropy loss function when there are two or more label classes.\n",
    "##### CategoricalCrossentropy : Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided in a one_hot representation. (https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28cba3b566b6e565"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "25/25 [==============================] - 12s 381ms/step - loss: 3.4443 - accuracy: 0.1386 - val_loss: 3.0151 - val_accuracy: 0.1652\n",
      "Epoch 2/7\n",
      "25/25 [==============================] - 10s 408ms/step - loss: 2.9204 - accuracy: 0.1967 - val_loss: 2.7924 - val_accuracy: 0.2696\n",
      "Epoch 3/7\n",
      "25/25 [==============================] - 10s 414ms/step - loss: 2.6005 - accuracy: 0.3895 - val_loss: 2.2999 - val_accuracy: 0.4753\n",
      "Epoch 4/7\n",
      "25/25 [==============================] - 11s 435ms/step - loss: 1.9312 - accuracy: 0.5305 - val_loss: 1.5486 - val_accuracy: 0.5904\n",
      "Epoch 5/7\n",
      "25/25 [==============================] - 11s 449ms/step - loss: 1.2054 - accuracy: 0.7205 - val_loss: 0.9230 - val_accuracy: 0.8067\n",
      "Epoch 6/7\n",
      "25/25 [==============================] - 11s 440ms/step - loss: 0.6583 - accuracy: 0.8767 - val_loss: 0.5528 - val_accuracy: 0.8845\n",
      "Epoch 7/7\n",
      "25/25 [==============================] - 11s 431ms/step - loss: 0.3678 - accuracy: 0.9301 - val_loss: 0.3928 - val_accuracy: 0.9065\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad, y_train_pad, batch_size=128, epochs=7, validation_data=(X_test_pad, y_test_pad))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T01:49:53.292683Z",
     "start_time": "2023-11-19T01:48:36.983029Z"
    }
   },
   "id": "fa08d6c9ff6433ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf8179747e81b776"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "(783, 150) (783, 150) (1, 150)\n",
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "in               : IN      IN\n",
      "addition         : NN      NN\n",
      ",                : ,       ,\n",
      "buick            : NNP     NNP\n",
      "is               : VBZ     VBZ\n",
      "a                : DT      DT\n",
      "relatively       : RB      RB\n",
      "respected        : VBN     VBN\n",
      "nameplate        : NN      NN\n",
      "among            : IN      IN\n",
      "american         : NNP     NNP\n",
      "express          : NNP     NNP\n",
      "card             : NN      NN\n",
      "holders          : NNS     NNS\n",
      ",                : ,       ,\n",
      "says             : VBZ     VBZ\n",
      "0                : -NONE-  -NONE-\n",
      "*t*-1            : -NONE-  -NONE-\n",
      "an               : DT      DT\n",
      "american         : NNP     NNP\n",
      "express          : NNP     NNP\n",
      "spokeswoman      : NN      NN\n",
      ".                : .       .\n"
     ]
    }
   ],
   "source": [
    "index_to_word = sen_tokenizer.index_word\n",
    "index_to_tag = tag_tokenizer.index_word\n",
    "\n",
    "i = 10 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "y_predicted = model.predict(np.array([X_test_pad[i]])) # 입력한 테스트용 샘플에 대해서 예측값 y를 리턴\n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # 확률 벡터를 정수 레이블로 변환.\n",
    "\n",
    "print(X_test_pad.shape, y_test_pad.shape, y_predicted.shape)\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for word, tag, pred in zip(X_test_pad[i], y_test_pad[i], y_predicted[0]):\n",
    "    if word != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_tag[tag].upper(), index_to_tag[pred].upper()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-19T02:03:28.135588Z",
     "start_time": "2023-11-19T02:03:28.094177Z"
    }
   },
   "id": "111c782e33f418b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8364e6c8b6ea0f85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
