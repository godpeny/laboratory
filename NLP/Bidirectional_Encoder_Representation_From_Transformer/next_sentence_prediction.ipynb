{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:05:21.172474Z",
     "start_time": "2023-12-24T01:05:18.645044Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import TFBertForNextSentencePrediction, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForNextSentencePrediction.\n",
      "\n",
      "All the weights of TFBertForNextSentencePrediction were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForNextSentencePrediction for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = TFBertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:05:23.138290Z",
     "start_time": "2023-12-24T01:05:21.173518Z"
    }
   },
   "id": "b976569be12a9b97"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# sentences with connection\n",
    "# prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "# next_sentence = \"pizza is eaten with the use of a knife and fork. In casual settings, however, it is cut into wedges to be eaten while held in the hand.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:05:23.138484Z",
     "start_time": "2023-12-24T01:05:23.136174Z"
    }
   },
   "id": "66c2de5256273fe2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# sentences with no connection\n",
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:05:23.142221Z",
     "start_time": "2023-12-24T01:05:23.138703Z"
    }
   },
   "id": "e06f1c323cf65ef3"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101  1999  3304  1010 10733  2366  1999  5337 10906  1010  2107  2004\n",
      "   2012  1037  4825  1010  2003  3591  4895 14540  6610  2094  1012   102\n",
      "   1996  3712  2003  2630  2349  2000  1996  7820 19934  1997  2630  2422\n",
      "   1012   102]], shape=(1, 38), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1]], shape=(1, 38), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')\n",
    "print(encoding.input_ids)\n",
    "print(encoding.token_type_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:05:23.146478Z",
     "start_time": "2023-12-24T01:05:23.141419Z"
    }
   },
   "id": "601c1e36da9bfcec"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] : 101\n",
      "[SEP] : 102\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.cls_token, ':', tokenizer.cls_token_id)\n",
    "print(tokenizer.sep_token, ':' , tokenizer.sep_token_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:05:23.146662Z",
     "start_time": "2023-12-24T01:05:23.144359Z"
    }
   },
   "id": "65da26eef57c2b35"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] in italy, pizza served in formal settings, such as at a restaurant, is presented unsliced. [SEP] the sky is blue due to the shorter wavelength of blue light. [SEP]\n"
     ]
    }
   ],
   "source": [
    "output = print(tokenizer.decode(encoding.input_ids[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:05:23.150388Z",
     "start_time": "2023-12-24T01:05:23.147064Z"
    }
   },
   "id": "55c35292d592586b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predict The Next Sentence using 'TFBertForNextSentencePrediction'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fed687b0544c9a2"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Softmax"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:05:23.153975Z",
     "start_time": "2023-12-24T01:05:23.150110Z"
    }
   },
   "id": "d25168d3aca9fbf"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1.2606435e-04 9.9987388e-01]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits = model(encoding.input_ids, token_type_ids=encoding.token_type_ids)[0]\n",
    "softmax = Softmax()\n",
    "probabilities = softmax(logits)\n",
    "print(probabilities)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:05:23.266210Z",
     "start_time": "2023-12-24T01:05:23.152675Z"
    }
   },
   "id": "a3b2e3df4a946269"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# 0 means next_sentence is a continuation of prompt and 1 means next_sentence is a random sentence.\n",
    "print(tf.math.argmax(input=probabilities, axis=-1).numpy()) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:05:23.267535Z",
     "start_time": "2023-12-24T01:05:23.264514Z"
    }
   },
   "id": "174d032753f5a420"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Klue/BERT-base for Korean"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f003efb6c8a69e27"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForNextSentencePrediction: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForNextSentencePrediction from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForNextSentencePrediction from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForNextSentencePrediction were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForNextSentencePrediction for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_k = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "model_k = TFBertForNextSentencePrediction.from_pretrained(\"klue/bert-base\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:07:37.245540Z",
     "start_time": "2023-12-24T01:07:35.912543Z"
    }
   },
   "id": "cb354a9a917b389c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# sentences with connection\n",
    "prompt = \"2002년 월드컵 축구대회는 일본과 공동으로 개최되었던 세계적인 큰 잔치입니다.\"\n",
    "next_sentence = \"여행을 가보니 한국의 2002년 월드컵 축구대회의 준비는 완벽했습니다.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:07:48.636386Z",
     "start_time": "2023-12-24T01:07:48.618860Z"
    }
   },
   "id": "af1ac8b3e745b933"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[9.9988782e-01 1.1218969e-04]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoding_k = tokenizer_k(prompt, next_sentence, return_tensors='tf')\n",
    "logits_k = model_k(encoding_k.input_ids, token_type_ids=encoding_k.token_type_ids)[0]\n",
    "\n",
    "softmax = Softmax()\n",
    "probabilities = softmax(logits_k)\n",
    "print(probabilities)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:09:49.096423Z",
     "start_time": "2023-12-24T01:09:48.966069Z"
    }
   },
   "id": "aeef88ad2a9d1079"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.argmax(input=probabilities, axis=-1).numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-24T01:09:54.863392Z",
     "start_time": "2023-12-24T01:09:54.852297Z"
    }
   },
   "id": "28398c56f61892d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ffcc7ed089d21231"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
