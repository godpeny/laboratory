{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:34:58.371643Z",
     "start_time": "2024-01-07T12:34:55.235780Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/\"\n",
    "\n",
    "df = pd.read_csv(data_path + \"reviews.csv\", nrows=100000)\n",
    "print(df.head(3))\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:34:58.807033Z",
     "start_time": "2024-01-07T12:34:58.373078Z"
    }
   },
   "id": "82739f5b7d9d4937"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b05434060ecbe50"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Summary                                               Text\n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...\n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...\n"
     ]
    }
   ],
   "source": [
    "df = df[['Summary', 'Text']] # use only two columns\n",
    "print(df.head(3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:34:58.812278Z",
     "start_time": "2024-01-07T12:34:58.803570Z"
    }
   },
   "id": "edc0ac1765ed37a5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary    2\n",
      "Text       0\n",
      "dtype: int64\n",
      "Summary    72348\n",
      "Text       88426\n",
      "dtype: int64\n",
      "88425\n"
     ]
    }
   ],
   "source": [
    "# check null and duplicate\n",
    "print(df.isnull().sum())\n",
    "print(df.nunique())\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates(subset=['Text']) # drop duplicates in Text column\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:34:58.978658Z",
     "start_time": "2024-01-07T12:34:58.819448Z"
    }
   },
   "id": "ee795ba894db9157"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "contractions = {\"'cause\": 'because',\n",
    "                \"I'd\": 'I would',\n",
    "                \"I'd've\": 'I would have',\n",
    "                \"I'll\": 'I will',\n",
    "                \"I'll've\": 'I will have',\n",
    "                \"I'm\": 'I am',\n",
    "                \"I've\": 'I have',\n",
    "                \"ain't\": 'is not',\n",
    "                \"aren't\": 'are not',\n",
    "                \"can't\": 'cannot',\n",
    "                \"could've\": 'could have',\n",
    "                \"couldn't\": 'could not',\n",
    "                \"didn't\": 'did not',\n",
    "                \"doesn't\": 'does not',\n",
    "                \"don't\": 'do not',\n",
    "                \"hadn't\": 'had not',\n",
    "                \"hasn't\": 'has not',\n",
    "                \"haven't\": 'have not',\n",
    "                \"he'd\": 'he would',\n",
    "                \"he'll\": 'he will',\n",
    "                \"he's\": 'he is',\n",
    "                \"here's\": 'here is',\n",
    "                \"how'd\": 'how did',\n",
    "                \"how'd'y\": 'how do you',\n",
    "                \"how'll\": 'how will',\n",
    "                \"how's\": 'how is',\n",
    "                \"i'd\": 'i would',\n",
    "                \"i'd've\": 'i would have',\n",
    "                \"i'll\": 'i will',\n",
    "                \"i'll've\": 'i will have',\n",
    "                \"i'm\": 'i am',\n",
    "                \"i've\": 'i have',\n",
    "                \"isn't\": 'is not',\n",
    "                \"it'd\": 'it would',\n",
    "                \"it'd've\": 'it would have',\n",
    "                \"it'll\": 'it will',\n",
    "                \"it'll've\": 'it will have',\n",
    "                \"it's\": 'it is',\n",
    "                \"let's\": 'let us',\n",
    "                \"ma'am\": 'madam',\n",
    "                \"mayn't\": 'may not',\n",
    "                \"might've\": 'might have',\n",
    "                \"mightn't\": 'might not',\n",
    "                \"mightn't've\": 'might not have',\n",
    "                \"must've\": 'must have',\n",
    "                \"mustn't\": 'must not',\n",
    "                \"mustn't've\": 'must not have',\n",
    "                \"needn't\": 'need not',\n",
    "                \"needn't've\": 'need not have',\n",
    "                \"o'clock\": 'of the clock',\n",
    "                \"oughtn't\": 'ought not',\n",
    "                \"oughtn't've\": 'ought not have',\n",
    "                \"sha'n't\": 'shall not',\n",
    "                \"shan't\": 'shall not',\n",
    "                \"shan't've\": 'shall not have',\n",
    "                \"she'd\": 'she would',\n",
    "                \"she'd've\": 'she would have',\n",
    "                \"she'll\": 'she will',\n",
    "                \"she'll've\": 'she will have',\n",
    "                \"she's\": 'she is',\n",
    "                \"should've\": 'should have',\n",
    "                \"shouldn't\": 'should not',\n",
    "                \"shouldn't've\": 'should not have',\n",
    "                \"so's\": 'so as',\n",
    "                \"so've\": 'so have',\n",
    "                \"that'd\": 'that would',\n",
    "                \"that'd've\": 'that would have',\n",
    "                \"that's\": 'that is',\n",
    "                \"there'd\": 'there would',\n",
    "                \"there'd've\": 'there would have',\n",
    "                \"there's\": 'there is',\n",
    "                \"they'd\": 'they would',\n",
    "                \"they'd've\": 'they would have',\n",
    "                \"they'll\": 'they will',\n",
    "                \"they'll've\": 'they will have',\n",
    "                \"they're\": 'they are',\n",
    "                \"they've\": 'they have',\n",
    "                \"this's\": 'this is',\n",
    "                \"to've\": 'to have',\n",
    "                \"wasn't\": 'was not',\n",
    "                \"we'd\": 'we would',\n",
    "                \"we'd've\": 'we would have',\n",
    "                \"we'll\": 'we will',\n",
    "                \"we'll've\": 'we will have',\n",
    "                \"we're\": 'we are',\n",
    "                \"we've\": 'we have',\n",
    "                \"weren't\": 'were not',\n",
    "                \"what'll\": 'what will',\n",
    "                \"what'll've\": 'what will have',\n",
    "                \"what're\": 'what are',\n",
    "                \"what's\": 'what is',\n",
    "                \"what've\": 'what have',\n",
    "                \"when's\": 'when is',\n",
    "                \"when've\": 'when have',\n",
    "                \"where'd\": 'where did',\n",
    "                \"where's\": 'where is',\n",
    "                \"where've\": 'where have',\n",
    "                \"who'll\": 'who will',\n",
    "                \"who'll've\": 'who will have',\n",
    "                \"who's\": 'who is',\n",
    "                \"who've\": 'who have',\n",
    "                \"why's\": 'why is',\n",
    "                \"why've\": 'why have',\n",
    "                \"will've\": 'will have',\n",
    "                \"won't\": 'will not',\n",
    "                \"won't've\": 'will not have',\n",
    "                \"would've\": 'would have',\n",
    "                \"wouldn't\": 'would not',\n",
    "                \"wouldn't've\": 'would not have',\n",
    "                \"y'all\": 'you all',\n",
    "                \"y'all'd\": 'you all would',\n",
    "                \"y'all'd've\": 'you all would have',\n",
    "                \"y'all're\": 'you all are',\n",
    "                \"y'all've\": 'you all have',\n",
    "                \"you'd\": 'you would',\n",
    "                \"you'd've\": 'you would have',\n",
    "                \"you'll\": 'you will',\n",
    "                \"you'll've\": 'you will have',\n",
    "                \"you're\": 'you are',\n",
    "                \"you've\": 'you have'}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:34:58.983694Z",
     "start_time": "2024-01-07T12:34:58.981601Z"
    }
   },
   "id": "80fc5f10f169e140"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "# stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "print(len(stopwords))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:34:58.989673Z",
     "start_time": "2024-01-07T12:34:58.984031Z"
    }
   },
   "id": "4ecd67cdf6195e2f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence, is_stopwords=True):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = BeautifulSoup(sentence, features='lxml').text\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열  제거 e.g.,) my husband (and myself) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) \n",
    "    sentence = ' '.join([contractions[word] if word in contractions else word for word in sentence.split()])\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence)\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    if is_stopwords:\n",
    "        tokens = ' '.join([word for word in sentence.split() if not word in stopwords if len(word) > 1])\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# test\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, 0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:34:58.990947Z",
     "start_time": "2024-01-07T12:34:58.988324Z"
    }
   },
   "id": "46291494361ffe91"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6c217c7be6b7>:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  sentence = BeautifulSoup(sentence, features='lxml').text\n",
      "<ipython-input-7-6c217c7be6b7>:3: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  sentence = BeautifulSoup(sentence, features='lxml').text\n"
     ]
    },
    {
     "data": {
      "text/plain": "                 Summary                                               Text\n0  good quality dog food  bought several vitality canned dog food produc...\n1      not as advertised  product arrived labeled jumbo salted peanuts p...\n2    delight says it all  confection around centuries light pillowy citr...\n3         cough medicine  looking secret ingredient robitussin believe f...\n4            great taffy  great taffy great price wide assortment yummy ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>good quality dog food</td>\n      <td>bought several vitality canned dog food produc...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>not as advertised</td>\n      <td>product arrived labeled jumbo salted peanuts p...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>delight says it all</td>\n      <td>confection around centuries light pillowy citr...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cough medicine</td>\n      <td>looking secret ingredient robitussin believe f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>great taffy</td>\n      <td>great taffy great price wide assortment yummy ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "for sentence in df['Text']:\n",
    "    clean_sentence = preprocess_sentence(sentence)\n",
    "    clean_text.append(clean_sentence)\n",
    "    \n",
    "df['Text'] = clean_text\n",
    "    \n",
    "clean_summary = []\n",
    "for sentence in df['Summary']:\n",
    "    clean_sentence = preprocess_sentence(sentence, 0)\n",
    "    clean_summary.append(clean_sentence)\n",
    "    \n",
    "df['Summary'] = clean_summary\n",
    "    \n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:11.005287Z",
     "start_time": "2024-01-07T12:34:58.991620Z"
    }
   },
   "id": "f0dfd008ac00a25d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary    0\n",
      "Text       0\n",
      "dtype: int64\n",
      "Summary    62801\n",
      "Text       88350\n",
      "dtype: int64\n",
      "88425\n",
      "88350\n"
     ]
    }
   ],
   "source": [
    "# check null and duplicate again\n",
    "print(df.isnull().sum())\n",
    "print(df.nunique())\n",
    "print(len(df))\n",
    "\n",
    "df = df.drop_duplicates(subset=['Text'])\n",
    "print(len(df))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:11.113415Z",
     "start_time": "2024-01-07T12:35:11.016597Z"
    }
   },
   "id": "bb57babf626e0664"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.789620826259195\n",
      "요약의 최소 길이 : 0\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.006191284663271\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "text_len = [len(s.split()) for s in df['Text']]\n",
    "summary_len = [len(s.split()) for s in df['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:11.830835Z",
     "start_time": "2024-01-07T12:35:11.163206Z"
    }
   },
   "id": "56cb2dd60f0b814c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7746576117713639\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9426372382569327\n"
     ]
    }
   ],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "\n",
    "\n",
    "below_threshold_len(text_max_len, df['Text'])\n",
    "below_threshold_len(summary_max_len, df['Summary'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:11.969488Z",
     "start_time": "2024-01-07T12:35:11.881Z"
    }
   },
   "id": "2fbe769347fb6da3"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65828\n",
      "                 Summary                                               Text\n",
      "0  good quality dog food  bought several vitality canned dog food produc...\n",
      "1      not as advertised  product arrived labeled jumbo salted peanuts p...\n",
      "2    delight says it all  confection around centuries light pillowy citr...\n",
      "3         cough medicine  looking secret ingredient robitussin believe f...\n",
      "4            great taffy  great taffy great price wide assortment yummy ...\n"
     ]
    }
   ],
   "source": [
    "df = df[df['Text'].apply(lambda row: len(row.split()) <= text_max_len)]\n",
    "df = df[df['Summary'].apply(lambda row: len(row.split()) <= summary_max_len)]\n",
    "\n",
    "print(len(df))\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:12.105316Z",
     "start_time": "2024-01-07T12:35:11.970078Z"
    }
   },
   "id": "f97d05612532c269"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### df[...]:\n",
    " - boolean indexing operation on the DataFrame df. The inner operation creates a boolean series, where each value is True if the condition is met (i.e., the text length is within the limit) and False otherwise.The df is then indexed with this boolean series, resulting in a new DataFrame that only contains rows where the condition is True."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8be175f64d138b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbf50c32352afcd"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                 Summary                                               Text  \\\n0  good quality dog food  bought several vitality canned dog food produc...   \n1      not as advertised  product arrived labeled jumbo salted peanuts p...   \n2    delight says it all  confection around centuries light pillowy citr...   \n3         cough medicine  looking secret ingredient robitussin believe f...   \n4            great taffy  great taffy great price wide assortment yummy ...   \n\n                    decoder_input                  decoder_target  \n0  sostoken good quality dog food  good quality dog food eostoken  \n1      sostoken not as advertised      not as advertised eostoken  \n2    sostoken delight says it all    delight says it all eostoken  \n3         sostoken cough medicine         cough medicine eostoken  \n4            sostoken great taffy            great taffy eostoken  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Summary</th>\n      <th>Text</th>\n      <th>decoder_input</th>\n      <th>decoder_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>good quality dog food</td>\n      <td>bought several vitality canned dog food produc...</td>\n      <td>sostoken good quality dog food</td>\n      <td>good quality dog food eostoken</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>not as advertised</td>\n      <td>product arrived labeled jumbo salted peanuts p...</td>\n      <td>sostoken not as advertised</td>\n      <td>not as advertised eostoken</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>delight says it all</td>\n      <td>confection around centuries light pillowy citr...</td>\n      <td>sostoken delight says it all</td>\n      <td>delight says it all eostoken</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cough medicine</td>\n      <td>looking secret ingredient robitussin believe f...</td>\n      <td>sostoken cough medicine</td>\n      <td>cough medicine eostoken</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>great taffy</td>\n      <td>great taffy great price wide assortment yummy ...</td>\n      <td>sostoken great taffy</td>\n      <td>great taffy eostoken</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['decoder_input'] = df['Summary'].apply(lambda s: 'sostoken '+ s)\n",
    "df['decoder_target'] = df['Summary'].apply(lambda s: s + ' eostoken')\n",
    "\n",
    "encoder_input = np.array(df['Text'])\n",
    "decoder_input = np.array(df['decoder_input'])\n",
    "decoder_target = np.array(df['decoder_target'])\n",
    "\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:12.121945Z",
     "start_time": "2024-01-07T12:35:12.118146Z"
    }
   },
   "id": "f30ecd6e120e27ff"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29466 29593 29630 ... 45891 42613 43567]\n",
      "테스트 데이터의 수 : 13165\n",
      "훈련 데이터의 개수 : 52663\n",
      "훈련 레이블의 개수 : 52663\n",
      "테스트 데이터의 개수 : 13165\n",
      "테스트 레이블의 개수 : 13165\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:12.151422Z",
     "start_time": "2024-01-07T12:35:12.123771Z"
    }
   },
   "id": "2f25618c070c4313"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11309 gap\n",
      "1155\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = Tokenizer()\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "\n",
    "print(src_tokenizer.word_index['gap'], src_tokenizer.index_word[11309]) # check index of word\n",
    "print(src_tokenizer.word_counts['home']) # check frequency of word"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:12.747099Z",
     "start_time": "2024-01-07T12:35:12.186378Z"
    }
   },
   "id": "e69e1dd498907fa7"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 32081\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23821\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8260\n",
      "단어 집합에서 희귀 단어의 비율: 74.25267292166703\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.394822959978698\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:12.757123Z",
     "start_time": "2024-01-07T12:35:12.755041Z"
    }
   },
   "id": "e4727ff2a60d5ec"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[242, 12, 1303, 1841, 5287, 19, 77, 762, 19, 2809, 818, 22, 2095, 130, 7682, 10, 1081, 101, 1860, 4170, 818, 762, 19, 3, 16, 242, 6], [41, 1, 1633, 666, 1528, 157, 626, 294, 1070, 150, 917, 1574, 1382, 324, 6, 498, 205, 967, 100, 7182, 5112, 205, 1181, 4, 58, 273, 899, 3], [4272, 1968, 175, 2648, 76, 113, 51, 920, 335, 93, 340, 36, 192, 86, 14, 243, 239, 41, 2, 1929, 407, 784, 180, 556, 14, 108, 231, 7183, 867, 166, 20, 517, 161, 51, 645, 296, 14]]\n"
     ]
    }
   ],
   "source": [
    "# remove rare words\n",
    "src_vocab = 8500\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab)\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "\n",
    "# integer encoding\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "print(encoder_input_train[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:13.886032Z",
     "start_time": "2024-01-07T12:35:12.805874Z"
    }
   },
   "id": "53d1e0cb081ca47c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337 home\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "\n",
    "print(tar_tokenizer.word_index['home'], tar_tokenizer.index_word[337])\n",
    "print(tar_tokenizer.word_counts['home'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:14.109280Z",
     "start_time": "2024-01-07T12:35:13.941567Z"
    }
   },
   "id": "5758681bd536d629"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10442\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8047\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2395\n",
      "단어 집합에서 희귀 단어의 비율: 77.06378088488796\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.843161775803704\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:14.114450Z",
     "start_time": "2024-01-07T12:35:14.112418Z"
    }
   },
   "id": "49acffb5d1a165c5"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 219, 619], [1, 80, 1153, 54], [1, 11, 32], [1, 271, 20], [1, 49, 147]]\n",
      "[[219, 619, 2], [80, 1153, 54, 2], [11, 32, 2], [271, 20, 2], [49, 147, 2]]\n"
     ]
    }
   ],
   "source": [
    "# remove rare words\n",
    "tar_vocab = 2400\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab)\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train) \n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# integer encoding\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train)\n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "print(decoder_input_train[:5])\n",
    "print(decoder_target_train[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:15.092754Z",
     "start_time": "2024-01-07T12:35:14.162016Z"
    }
   },
   "id": "ccb1c6a2686df75c"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52663 52663 52663 13165 13165 13165\n",
      "51546 51546 51546 12858 12858 12858\n"
     ]
    }
   ],
   "source": [
    "# finding empty sample indices\n",
    "print(len(encoder_input_train), len(decoder_input_train), len(decoder_target_train), len(encoder_input_test), len(decoder_input_test), len(decoder_target_test))\n",
    "\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "# padding\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')\n",
    "\n",
    "# drop\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print(len(encoder_input_train), len(decoder_input_train), len(decoder_target_train), len(encoder_input_test), len(decoder_input_test), len(decoder_target_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:15.285398Z",
     "start_time": "2024-01-07T12:35:15.099443Z"
    }
   },
   "id": "fad254e9390726dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8502b200bdb8b614"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:15.290566Z",
     "start_time": "2024-01-07T12:35:15.285793Z"
    }
   },
   "id": "165f6e1fea3566f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f811c78cf7f739c"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "embedding_dim = 128\n",
    "hidden_units = 256\n",
    "dropout_ratio = 0.4\n",
    "\n",
    "enc_input = Input(shape=(text_max_len,))\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(enc_input)\n",
    "\n",
    "# lstm\n",
    "encoder_outputs_layer_1 = LSTM(units=hidden_units, return_state=False, return_sequences=True, dropout=dropout_ratio, recurrent_dropout=dropout_ratio)\n",
    "encoder_outputs_1 = encoder_outputs_layer_1(enc_emb)\n",
    "\n",
    "encoder_outputs_layer_2 = LSTM(units=hidden_units, return_state=False, return_sequences=True, dropout=dropout_ratio, recurrent_dropout=dropout_ratio)\n",
    "encoder_outputs_2 = encoder_outputs_layer_2(encoder_outputs_1)\n",
    "\n",
    "encoder_outputs_layer_fin = LSTM(units=hidden_units, return_state=True, return_sequences=True, dropout=dropout_ratio, recurrent_dropout=dropout_ratio)\n",
    "encoder_outputs, state_h, state_c = encoder_outputs_layer_fin(encoder_outputs_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:15.494965Z",
     "start_time": "2024-01-07T12:35:15.288574Z"
    }
   },
   "id": "fa9cf65c2dda6c96"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a4e3d12940d37bb"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "dec_input = Input(shape=(None,))\n",
    "\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(dec_input)\n",
    "\n",
    "# lstm\n",
    "decoder_lstm = LSTM(units=hidden_units, return_state=True, return_sequences=True, dropout=dropout_ratio, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:45:27.624759Z",
     "start_time": "2024-01-07T12:45:27.550833Z"
    }
   },
   "id": "23f3353ac1503514"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# using attention layer instead of this part.\n",
    "# \n",
    "# # softmax\n",
    "# decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "# decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "# \n",
    "# # model\n",
    "# model = Model([enc_input, dec_input], decoder_softmax_outputs)\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:15.567562Z",
     "start_time": "2024-01-07T12:35:15.561867Z"
    }
   },
   "id": "98bda1b4278ffade"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attention "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2541b40ef561b8e"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:15.567717Z",
     "start_time": "2024-01-07T12:35:15.564269Z"
    }
   },
   "id": "abbaa98b27ca690b"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Bahdanau AttentionLayer code from outsource.\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:15.574976Z",
     "start_time": "2024-01-07T12:35:15.573606Z"
    }
   },
   "id": "88041bcd5e321ffc"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 50, 128)              1088000   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 50, 256)              394240    ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 50, 256)              525312    ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 128)            307200    ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               [(None, 50, 256),            525312    ['lstm_1[0][0]']              \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, None, 256)            394240    ['embedding_1[0][0]',         \n",
      "                                                                     'lstm_2[0][1]',              \n",
      "                                                                     'lstm_2[0][2]']              \n",
      "                                                                                                  \n",
      " attention_layer (Attention  ((None, None, 256),          131328    ['lstm_2[0][0]',              \n",
      " Layer)                       (None, None, 50))                      'lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)  (None, None, 512)            0         ['lstm_3[0][0]',              \n",
      "                                                                     'attention_layer[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 2400)           1231200   ['concat_layer[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4596832 (17.54 MB)\n",
      "Trainable params: 4596832 (17.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attention_layer = AttentionLayer(name='attention_layer')\n",
    "\n",
    "attention_out, attention_states = attention_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_out])\n",
    "\n",
    "# softmax\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# model\n",
    "model = Model([enc_input, dec_input], decoder_softmax_outputs)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:35:15.746909Z",
     "start_time": "2024-01-07T12:35:15.578438Z"
    }
   },
   "id": "2531b00fa64e7d48"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 352s 2s/step - loss: 2.7726 - val_loss: 2.4972\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train,\n",
    "                    validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "                    batch_size = 256, callbacks=[es], epochs = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:41:08.103443Z",
     "start_time": "2024-01-07T12:35:15.752197Z"
    }
   },
   "id": "4ef1714a15008f48"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inferencing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d1c271e397915c0"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "src_word_index = src_tokenizer.word_index\n",
    "src_index_word = src_tokenizer.index_word\n",
    "tar_word_index = tar_tokenizer.word_index\n",
    "tar_index_word = tar_tokenizer.index_word"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:51:46.292831Z",
     "start_time": "2024-01-07T12:51:46.275833Z"
    }
   },
   "id": "70a2b4443b4e6c9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a24eb0e3986ea6e"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 50, 128)           1088000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50, 256)           394240    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50, 256)           525312    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               [(None, 50, 256),         525312    \n",
      "                              (None, 256),                       \n",
      "                              (None, 256)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2532864 (9.66 MB)\n",
      "Trainable params: 2532864 (9.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# encoder\n",
    "# get all encoder layers from 'enc_input' to [encoder_outputs, state_h, state_c]\n",
    "enc_model_inf = Model(inputs=enc_input, outputs=[encoder_outputs, state_h, state_c])\n",
    "enc_model_inf.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:41:08.114926Z",
     "start_time": "2024-01-07T12:41:08.102747Z"
    }
   },
   "id": "836025fad9d2120e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f87709b176c5feb7"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# save previous states\n",
    "# previous states will be injected in 'decode_sequence' function\n",
    "dec_inf_input_h = Input(shape=(hidden_units,))\n",
    "dec_inf_input_c = Input(shape=(hidden_units,))\n",
    "\n",
    "dec_inf_emb = dec_emb_layer(dec_input) # dec_input = Input(shape=(None,)\n",
    "\n",
    "dec_inf_output, dec_inf_state_h, dec_inf_state_c = decoder_lstm(dec_inf_emb, initial_state=[dec_inf_input_h, dec_inf_input_c])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:45:31.764977Z",
     "start_time": "2024-01-07T12:45:31.712391Z"
    }
   },
   "id": "84b2abd7d683d6d8"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, None, 128)            307200    ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)       [(None, 256)]                0         []                            \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)       [(None, 256)]                0         []                            \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               [(None, None, 256),          394240    ['embedding_2[1][0]',         \n",
      "                              (None, 256),                           'input_10[0][0]',            \n",
      "                              (None, 256)]                           'input_11[0][0]']            \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)       [(None, 50, 256)]            0         []                            \n",
      "                                                                                                  \n",
      " attention_layer (Attention  ((None, None, 256),          131328    ['input_12[0][0]',            \n",
      " Layer)                       (None, None, 50))                      'lstm_4[1][0]']              \n",
      "                                                                                                  \n",
      " concat (Concatenate)        (None, None, 512)            0         ['lstm_4[1][0]',              \n",
      "                                                                     'attention_layer[1][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 2400)           1231200   ['concat[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2063968 (7.87 MB)\n",
      "Trainable params: 2063968 (7.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dec_inf_hidden_input = Input(shape=(text_max_len, hidden_units)) # encoder output = ('encoder_outputs')\n",
    "dec_inf_attention_out, dec_inf_attention_states = attention_layer([dec_inf_hidden_input, dec_inf_output])\n",
    "dec_inf_concat = Concatenate(axis=-1, name='concat')([dec_inf_output, dec_inf_attention_out])\n",
    "\n",
    "dec_inf_output_layer = decoder_softmax_layer(dec_inf_concat)\n",
    "\n",
    "dec_inf_model = Model(\n",
    "    inputs=[dec_input] + [dec_inf_hidden_input, dec_inf_input_h, dec_inf_input_c],\n",
    "    outputs=[dec_inf_output_layer] + [dec_inf_state_h, dec_inf_state_c]\n",
    ")\n",
    "\n",
    "dec_inf_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:45:34.283992Z",
     "start_time": "2024-01-07T12:45:34.200146Z"
    }
   },
   "id": "16f3375d1d1e0a41"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = enc_model_inf.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = dec_inf_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :]) # -1 : last time step\n",
    "        sampled_token = tar_index_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:51:05.463966Z",
     "start_time": "2024-01-07T12:51:05.458902Z"
    }
   },
   "id": "c97a98419afed9c1"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    sentence=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            sentence = sentence + src_index_word[i]+' '\n",
    "    return sentence\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    sentence=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_index['sostoken']) and i!=tar_word_index['eostoken']):\n",
    "            sentence = sentence + tar_index_word[i] + ' '\n",
    "    return sentence\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:52:01.126167Z",
     "start_time": "2024-01-07T12:52:01.089869Z"
    }
   },
   "id": "9bc5ca87dba41068"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  bought cheaper alternative le de de bad stick le product find \n",
      "실제 요약문 : not bad but \n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "예측 요약문 :  great great great great great great great\n",
      "\n",
      "\n",
      "원문 :  like product much healthy alternative greasy pork sausages bacon morning especially good grits eggs bit butter drop hot sauce try believe like \n",
      "실제 요약문 : product \n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "예측 요약문 :  my my my my my my not\n",
      "\n",
      "\n",
      "원문 :  purchased paramount oz popcorn maker figuring would easy quick mess however half kernals popped thats gave lower review flavor mark movie theater taste perfect salt butter flavor opinion wish kernals popped \n",
      "실제 요약문 : movie theater popcorn \n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "예측 요약문 :  great great my my my great great\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(500, 503):\n",
    "    print(\"원문 : \",seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약문 :\",seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약문 :\",decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T12:52:27.505276Z",
     "start_time": "2024-01-07T12:52:26.121401Z"
    }
   },
   "id": "5686749472cb681b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fbb32e2307a47c49"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
