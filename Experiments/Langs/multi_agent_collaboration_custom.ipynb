{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Annotated, Sequence, TypedDict, Literal\n",
    "import operator\n",
    "import functools\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, format_document, MessagesPlaceholder\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnableMap, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langserve.pydantic_v1 import BaseModel, Field"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:54.217466Z",
     "start_time": "2024-06-22T15:41:53.547876Z"
    }
   },
   "id": "60a9bff217b5067e",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Tools"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8ccc98a84875232"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def vector_store(path):\n",
    "    raw_documents = TextLoader(path).load()\n",
    "    embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=\"sk-proj-DFEqmV2bESTGXITqzVrHT3BlbkFJ3ndYJrjURSkNmALp5kqS\")\n",
    "    text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=0)\n",
    "    documents = text_splitter.split_documents(raw_documents)\n",
    "    store = FAISS.from_documents(documents, embeddings_model)\n",
    "\n",
    "    return store\n",
    "\n",
    "# template\n",
    "_TEMPLATE = \"\"\"Given the following conversation and a follow up question, rephrase the \n",
    "follow up question to be a standalone question, in its original language.\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_TEMPLATE)\n",
    "\n",
    "ANSWER_TEMPLATE = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(ANSWER_TEMPLATE)\n",
    "\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    \"\"\"Combine documents into a single string.\"\"\"\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "def _format_chat_history(chat_history: List[Tuple]) -> str:\n",
    "    \"\"\"Format chat history into a string.\"\"\"\n",
    "    buffer = \"\"\n",
    "    for dialogue_turn in chat_history:\n",
    "        human = \"Human: \" + dialogue_turn[0]\n",
    "        ai = \"Assistant: \" + dialogue_turn[1]\n",
    "        buffer += \"\\n\" + \"\\n\".join([human, ai])\n",
    "    return buffer\n",
    "\n",
    "class ChatHistory(BaseModel):\n",
    "    \"\"\"Chat history with the bot.\"\"\"\n",
    "    question: str\n",
    "    \n",
    "\n",
    "@tool\n",
    "def emb_finder(\n",
    "    message: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # message : [2023-08-23.txt]:::(what happen last year?)\n",
    "        # Step 1 : Separating message with date and question\n",
    "        date_str, question = message.split(\":::\")\n",
    "        # Step 2: Remove the brackets around the dates\n",
    "        date_str = date_str.strip(\"[]\")\n",
    "        # Step 3: Convert the string of dates to a list\n",
    "        date_list = date_str.split(\", \")\n",
    "        question = question.strip(\"()\")\n",
    "        \n",
    "        for date in date_list:     \n",
    "            # vector store of chat history.\n",
    "            date = date.strip(\"''\")\n",
    "            chat_db_path = f\"./embeddings/{date}\"\n",
    "            vectorstore = vector_store(chat_db_path)\n",
    "            retriever = vectorstore.as_retriever(search_type=\"mmr\")\n",
    "            \n",
    "            _inputs = RunnableMap(\n",
    "                standalone_question=RunnablePassthrough.assign()\n",
    "                | CONDENSE_QUESTION_PROMPT\n",
    "                | ChatOpenAI(temperature=0, api_key=\"sk-proj-DFEqmV2bESTGXITqzVrHT3BlbkFJ3ndYJrjURSkNmALp5kqS\")\n",
    "                | StrOutputParser(),\n",
    "                )\n",
    "            \n",
    "            _context = {\n",
    "                \"context\": itemgetter(\"standalone_question\") | retriever | _combine_documents,\n",
    "                \"question\": lambda x: x[\"standalone_question\"],\n",
    "            }\n",
    "            \n",
    "            conversational_qa_chain = (\n",
    "                _inputs | _context | ANSWER_PROMPT | ChatOpenAI(api_key=\"sk-proj-DFEqmV2bESTGXITqzVrHT3BlbkFJ3ndYJrjURSkNmALp5kqS\") | StrOutputParser()\n",
    "            )\n",
    "            \n",
    "            chain = conversational_qa_chain.with_types(input_type=ChatHistory)\n",
    "            return chain.invoke({f\"question\": {question}})\n",
    "        \n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    return (\n",
    "        message\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:54.224367Z",
     "start_time": "2024-06-22T15:41:54.218432Z"
    }
   },
   "id": "d0041f9a0782c7",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# State of Graph\n",
    "A list of messages, along with a key to track the most recent sender"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "350ee4d3b012d9d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# This defines the object that is passed between each node\n",
    "# in the graph. We will create different nodes for each agent and tool\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:54.227048Z",
     "start_time": "2024-06-22T15:41:54.225658Z"
    }
   },
   "id": "1e7bfe082fe03eef",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Nodes\n",
    "Agent Nodes, Tool Nodes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b7a1d6701232894"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Nodes\n",
    "\"\"\"\n",
    "def agent_node(state, agent, name):\n",
    "    \"\"\"Helper function to create a node for a given agent\"\"\"\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, ToolMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)    \n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", api_key=\"sk-proj-DFEqmV2bESTGXITqzVrHT3BlbkFJ3ndYJrjURSkNmALp5kqS\")\n",
    "\n",
    "# Date Agent\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d.txt\") \n",
    "file_list = os.listdir('./embeddings')\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You do not need to answer question itself.\"\n",
    "                \"You have two goals, one is to find date information from question and other is to pass the question for the next agent to answer.\"\n",
    "                \"Make '[date1.txt, date2.txt, ...]:::(question)' format to answer, when (question) is the original question from the user.\"\n",
    "                \"\\n{system_message}\"\n",
    "                ,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "prompt = prompt.partial(system_message=f\"The current date is {current_date}. If the question does not have any clue about date, use the current date. If the question has a clue about date, find all the related dates from the list {file_list}. For example, If current date is '2023-08-23' and question indicating this year, you have to answer with all the date list with 2023, like [2023-01-15.txt, 2023-02-11.txt, 2023-05-19.txt ...]\")\n",
    "data_agent =  prompt | llm\n",
    "\n",
    "date_node = functools.partial(agent_node, agent=data_agent, name=\"date_finder\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:54.245719Z",
     "start_time": "2024-06-22T15:41:54.227985Z"
    }
   },
   "id": "6fe5bdae8a8303ff",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tool Nodes\n",
    "\"\"\"\n",
    "tools = [emb_finder]\n",
    "tool_node = ToolNode(tools)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:54.247847Z",
     "start_time": "2024-06-22T15:41:54.246400Z"
    }
   },
   "id": "4280c5ea7750e595",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Embedding Node\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You have to use tools to find the embedding with the proper date,\"\n",
    "                \"Remember, you must use tool with the answer received from previous agent without any editing or deleting with the format of '[date1, date2, ...]:::(question)'.\"\n",
    "                \"Remember, don't miss or ignore single date element from received answer when you pass the state to tools.\"\n",
    "                \"You have access to the following tools: {tool_names}.\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "chart_agent =  prompt | llm.bind_tools(tools) \n",
    "\n",
    "chart_node = functools.partial(agent_node, agent=chart_agent, name=\"chart_generator\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:54.302344Z",
     "start_time": "2024-06-22T15:41:54.248413Z"
    }
   },
   "id": "9de125e77945f3",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Edge Logic\n",
    "edge logic that is needed to decide what to do based on results of the agents"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14d3926f24dbbf70"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n",
    "    \"\"\"\n",
    "        This is the router\n",
    "        Either agent can decide to end\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    if last_message.tool_calls:\n",
    "        # The previous agent is invoking a tool\n",
    "        return \"call_tool\"\n",
    "    return \"continue\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:54.304776Z",
     "start_time": "2024-06-22T15:41:54.303084Z"
    }
   },
   "id": "de5cbe9710ffb9af",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Graph"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f71958b8eafde6a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"date_finder\", date_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "workflow.add_node(\"call_tool\", tool_node)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"date_finder\",\n",
    "    router,\n",
    "    {\"continue\": \"chart_generator\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"chart_generator\",\n",
    "    router,\n",
    "    {\"continue\": END, \"call_tool\": \"call_tool\", \"__end__\": END},\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    lambda x: \"continue\",\n",
    "    {\n",
    "        \"continue\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.set_entry_point(\"date_finder\")\n",
    "graph = workflow.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:54.309372Z",
     "start_time": "2024-06-22T15:41:54.306239Z"
    }
   },
   "id": "f4e51dba9160e8ec",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict, Any, Union\n",
    "\n",
    "def extract_content_and_urls(value: Dict[str, Any]) -> List[Dict[str, Union[str, Dict[str, str]]]]:\n",
    "    result = []\n",
    "    possible_keys = ['call_tool', 'date_finder', 'chart_generator']\n",
    "\n",
    "    for key in possible_keys:\n",
    "        if key in value:\n",
    "            data = value[key]\n",
    "            if 'messages' in data:\n",
    "                messages = data['messages']\n",
    "                if isinstance(messages, list) and len(messages) > 0:\n",
    "                    message = messages[0]\n",
    "                    content = message.content\n",
    "                    # Check if the content is a JSON string\n",
    "                    try:\n",
    "                        json_content = json.loads(content)\n",
    "                        # Handle case where content is a JSON string\n",
    "                        for item in json_content:\n",
    "                            url = item.get('url')\n",
    "                            content = item.get('content')\n",
    "                            result.append({'url': url, 'content': content})\n",
    "                    except json.JSONDecodeError:\n",
    "                        # Handle case where content is a regular string\n",
    "                        result.append({'content': content})\n",
    "            break  # Stop after finding the first valid key\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:41:54.312533Z",
     "start_time": "2024-06-22T15:41:54.310156Z"
    }
   },
   "id": "3cbcbdc0fd3dbc7",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'The school started a new coding club and Alex joined it.'}]\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"User: \") # what topic did we talk last year?\n",
    "if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "    print(\"Goodbye!\")\n",
    "else:\n",
    "    events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=user_input\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 5},\n",
    "    )\n",
    "    \n",
    "    last_event = None\n",
    "    for event in events:\n",
    "        last_event = event\n",
    "    print(extract_content_and_urls(last_event))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:44:54.580665Z",
     "start_time": "2024-06-22T15:44:46.151486Z"
    }
   },
   "id": "41f8195423f0d7b8",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T15:42:00.167925Z",
     "start_time": "2024-06-22T15:42:00.166186Z"
    }
   },
   "id": "9ff80b3dc4689902",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
