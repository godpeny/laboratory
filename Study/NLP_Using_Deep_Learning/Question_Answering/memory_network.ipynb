{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from keras.utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:28:54.099446Z",
     "start_time": "2024-01-14T11:28:43.665850Z"
    }
   },
   "id": "701c63fd478a4b51"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_path = \"../data/\"\n",
    "\n",
    "TRAIN_FILE = data_path + \"qa1_single-supporting-fact_train.txt\"\n",
    "TEST_FILE = data_path + \"qa1_single-supporting-fact_test.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:44:01.438844Z",
     "start_time": "2024-01-14T11:44:01.432386Z"
    }
   },
   "id": "ef976ec05cf7af5c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def read_data(dir):\n",
    "    story_temp = []\n",
    "    questions, answers, stories = [], [], []\n",
    "    lines = open(dir, 'rb')\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        \n",
    "        idx, text = line.split(' ', 1)\n",
    "        \n",
    "        if(int(idx)) == 1: # when new story comes\n",
    "            story_temp = []\n",
    "            \n",
    "        if '\\t' in text: # when 'Q\\tA' comes\n",
    "            question, answer, _ = text.split('\\t')\n",
    "            stories.append([x for x in story_temp if x])\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "            \n",
    "        else: # when story comes\n",
    "            story_temp.append(text)\n",
    "            \n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T11:45:48.757521Z",
     "start_time": "2024-01-14T11:45:48.750977Z"
    }
   },
   "id": "85e1cf7c7bc66dd5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000 10000\n",
      "1000 1000 1000\n",
      "['John travelled to the garden.', 'John journeyed to the office.', 'Daniel travelled to the kitchen.', 'Daniel moved to the bathroom.'] Where is Daniel?  bathroom\n"
     ]
    }
   ],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)\n",
    "\n",
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)\n",
    "\n",
    "print(len(train_stories), len(train_questions), len(train_answers))\n",
    "print(len(test_stories), len(test_questions), len(test_answers))\n",
    "\n",
    "print(train_stories[3456], train_questions[3456], train_answers[3456])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T12:03:25.260649Z",
     "start_time": "2024-01-14T12:03:25.217821Z"
    }
   },
   "id": "b9117458d42035b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5beb5d99dce518fb"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [x.strip() for x in re.split('(\\W+)', sent) if x.strip()] \n",
    "\n",
    "def preprocess(train, test):\n",
    "    counter = FreqDist() # frequency distribution\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data) # concatenate sentences\n",
    "    \n",
    "    story_len, question_len = [], []\n",
    "    \n",
    "    for stories, questions, answers in [train, test]:\n",
    "        for story in stories:\n",
    "            stories_tokenized = tokenize(flatten(story))\n",
    "            story_len.append(len(stories_tokenized))\n",
    "            for word in stories_tokenized:\n",
    "                counter[word.lower()] += 1\n",
    "        for question in questions:\n",
    "            question_tokenized = tokenize(question)\n",
    "            question_len.append(len(question_tokenized))\n",
    "            for word in question_tokenized:\n",
    "                counter[word.lower()] += 1\n",
    "        for answer in answers:\n",
    "            answer_tokenized = tokenize(answer)\n",
    "            for word in answer_tokenized:\n",
    "                counter[word.lower()] += 1\n",
    "\n",
    "    # 단어 집합 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T12:02:46.635045Z",
     "start_time": "2024-01-14T12:02:46.616138Z"
    }
   },
   "id": "63be8eeb09b4e471"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': 1, 'the': 2, '.': 3, 'went': 4, 'sandra': 5, 'john': 6, 'daniel': 7, 'mary': 8, 'travelled': 9, 'journeyed': 10, 'back': 11, 'bathroom': 12, 'garden': 13, 'hallway': 14, 'moved': 15, 'office': 16, 'kitchen': 17, 'bedroom': 18, 'where': 19, 'is': 20, '?': 21}\n",
      "68 4\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess(train_data, test_data)\n",
    "vocab_size = len(word2idx) + 1\n",
    "\n",
    "print(word2idx)\n",
    "print(story_max_len, question_max_len)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T12:04:53.401812Z",
     "start_time": "2024-01-14T12:04:53.228435Z"
    }
   },
   "id": "56d039aacfe7b4f9"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    \n",
    "    stories, questions, answers = data\n",
    "    \n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w.lower()] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w.lower()] for w in tokenize(question)]\n",
    "        \n",
    "        y = np.zeros(len(word2idx) + 1)\n",
    "        y[word2idx[answer]] = 1\n",
    "        \n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return pad_sequences(Xs, maxlen=story_maxlen), pad_sequences(Xq, maxlen=question_maxlen), np.array(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T12:06:59.067002Z",
     "start_time": "2024-01-14T12:06:59.057391Z"
    }
   },
   "id": "97aef1b2ccd15ab9"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 68) (10000, 4) (10000, 22)\n",
      "(1000, 68) (1000, 4) (1000, 22)\n"
     ]
    }
   ],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)\n",
    "\n",
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape)\n",
    "print(Xstest.shape, Xqtest.shape, Ytest.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T12:07:14.743049Z",
     "start_time": "2024-01-14T12:07:14.610905Z"
    }
   },
   "id": "f02724c24234d334"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dd4b1393c65a2f4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
