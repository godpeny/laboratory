{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-19T11:52:05.492385Z",
     "start_time": "2024-01-19T11:52:03.046489Z"
    }
   },
   "outputs": [],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "from keras.utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_path = \"../data/\"\n",
    "TRAIN_FILE = os.path.join(data_path + \"qa1_single-supporting-fact_train_kor.txt\")\n",
    "TEST_FILE = os.path.join(data_path + \"qa1_single-supporting-fact_test_kor.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T11:52:05.495588Z",
     "start_time": "2024-01-19T11:52:05.493346Z"
    }
   },
   "id": "8a1b672d3300f520"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 스토리의 개수 : 10000\n",
      "훈련용 질문의 개수 : 10000\n",
      "훈련용 답변의 개수 : 10000\n",
      "테스트용 스토리의 개수 : 1000\n",
      "테스트용 질문의 개수 : 1000\n",
      "테스트용 답변의 개수 : 1000\n"
     ]
    }
   ],
   "source": [
    "def read_data(dir):\n",
    "    story_temp = []\n",
    "    questions, answers, stories = [], [], []\n",
    "    lines = open(dir, 'rb')\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "\n",
    "        idx, text = line.split(' ', 1)\n",
    "\n",
    "        if(int(idx)) == 1: # when new story comes\n",
    "            story_temp = []\n",
    "\n",
    "        if '\\t' in text: # when 'Q\\tA' comes\n",
    "            question, answer, _ = text.split('\\t')\n",
    "            stories.append([x for x in story_temp if x])\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # when story comes\n",
    "            story_temp.append(text)\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers\n",
    "\n",
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)\n",
    "\n",
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)\n",
    "\n",
    "print('훈련용 스토리의 개수 :', len(train_stories))\n",
    "print('훈련용 질문의 개수 :',len(train_questions))\n",
    "print('훈련용 답변의 개수 :',len(train_answers))\n",
    "print('테스트용 스토리의 개수 :',len(test_stories))\n",
    "print('테스트용 질문의 개수 :',len(test_questions))\n",
    "print('테스트용 답변의 개수 :',len(test_answers))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T11:52:05.534157Z",
     "start_time": "2024-01-19T11:52:05.498150Z"
    }
   },
   "id": "ccd766a456efe3aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7204b546c6b26ae"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [x.strip() for x in re.split('(\\W+)', sent) if x.strip()]\n",
    "\n",
    "def preprocess(train, test):\n",
    "    counter = FreqDist() # frequency distribution\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data) # concatenate sentences\n",
    "\n",
    "    story_len, question_len = [], []\n",
    "\n",
    "    for stories, questions, answers in [train, test]:\n",
    "        for story in stories:\n",
    "            stories_tokenized = tokenize(flatten(story))\n",
    "            story_len.append(len(stories_tokenized))\n",
    "            for word in stories_tokenized:\n",
    "                counter[word.lower()] += 1\n",
    "        for question in questions:\n",
    "            question_tokenized = tokenize(question)\n",
    "            question_len.append(len(question_tokenized))\n",
    "            for word in question_tokenized:\n",
    "                counter[word.lower()] += 1\n",
    "        for answer in answers:\n",
    "            answer_tokenized = tokenize(answer)\n",
    "            for word in answer_tokenized:\n",
    "                counter[word.lower()] += 1\n",
    "\n",
    "    # 단어 집합 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T11:52:05.536731Z",
     "start_time": "2024-01-19T11:52:05.535461Z"
    }
   },
   "id": "9db3986cf76c812"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 1, '경임이는': 2, '은경이는': 3, '수종이는': 4, '필웅이는': 5, '이동했습니다': 6, '가버렸습니다': 7, '뛰어갔습니다': 8, '복귀했습니다': 9, '갔습니다': 10, '화장실로': 11, '정원으로': 12, '복도로': 13, '어디야': 14, '?': 15, '부엌으로': 16, '사무실로': 17, '침실로': 18, '화장실': 19, '정원': 20, '사무실': 21, '침실': 22, '복도': 23, '부엌': 24}\n",
      "40 3\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess(train_data, test_data)\n",
    "vocab_size = len(word2idx) + 1\n",
    "\n",
    "\n",
    "print(word2idx)\n",
    "print(story_max_len, question_max_len)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T11:52:05.688454Z",
     "start_time": "2024-01-19T11:52:05.579667Z"
    }
   },
   "id": "8b0dd19bbd4d3f8e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/godpeny/Code/venv/laboratory/lib/python3.11/site-packages/konlpy/tag/_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['은경', '이', '는', '화장실', '로', '이동', '했습니다', '.']\n",
      "['경', '임', '이', '는', '정원', '으로', '가버렸습니다', '.']\n",
      "['수', '종이', '는', '복도', '로', '뛰어갔습니다', '.']\n",
      "['필웅이', '는', '부엌', '으로', '복귀', '했습니다', '.']\n",
      "['수', '종이', '는', '사무실', '로', '갔습니다', '.']\n",
      "['은경', '이', '는', '침실', '로', '갔습니다', '.']\n",
      "['은경', '이', '는', '화장실', '로', '이동', '했습니다', '.']\n",
      "['경', '임', '이', '는', '정원', '으로', '가버렸습니다', '.']\n",
      "['수', '종이', '는', '복도', '로', '뛰어갔습니다', '.']\n",
      "['필웅이', '는', '부엌', '으로', '복귀', '했습니다', '.']\n",
      "['수', '종이', '는', '사무실', '로', '갔습니다', '.']\n",
      "['은경', '이', '는', '침실', '로', '갔습니다', '.']\n"
     ]
    }
   ],
   "source": [
    "twitter = Twitter()\n",
    "\n",
    "print(twitter.morphs('은경이는 화장실로 이동했습니다.'))\n",
    "print(twitter.morphs('경임이는 정원으로 가버렸습니다.'))\n",
    "print(twitter.morphs('수종이는 복도로 뛰어갔습니다.'))\n",
    "print(twitter.morphs('필웅이는 부엌으로 복귀했습니다.'))\n",
    "print(twitter.morphs('수종이는 사무실로 갔습니다.'))\n",
    "print(twitter.morphs('은경이는 침실로 갔습니다.'))\n",
    "\n",
    "# add korean name entity recognition\n",
    "twitter.add_dictionary('은경이', 'Name')\n",
    "twitter.add_dictionary('은경이', 'Noun')\n",
    "twitter.add_dictionary('경임이', 'Name')\n",
    "twitter.add_dictionary('경임이', 'Noun')\n",
    "twitter.add_dictionary('수종이', 'Name')\n",
    "twitter.add_dictionary('수종이', 'Noun')\n",
    "twitter.add_dictionary('필웅이', 'Name')\n",
    "twitter.add_dictionary('필웅이', 'Noun')\n",
    "\n",
    "# test (not working currently)\n",
    "print(twitter.morphs('은경이는 화장실로 이동했습니다.'))\n",
    "print(twitter.morphs('경임이는 정원으로 가버렸습니다.'))\n",
    "print(twitter.morphs('수종이는 복도로 뛰어갔습니다.'))\n",
    "print(twitter.morphs('필웅이는 부엌으로 복귀했습니다.'))\n",
    "print(twitter.morphs('수종이는 사무실로 갔습니다.'))\n",
    "print(twitter.morphs('은경이는 침실로 갔습니다.'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T11:52:07.816721Z",
     "start_time": "2024-01-19T11:52:05.688563Z"
    }
   },
   "id": "8c4444f7023f1659"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return twitter.morphs(sent)\n",
    "\n",
    "word2idx, idx2word, story_max_len, question_max_len = preprocess(train_data, test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T11:53:04.625426Z",
     "start_time": "2024-01-19T11:52:07.815855Z"
    }
   },
   "id": "846482b3a836447e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w.lower()] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w.lower()] for w in tokenize(question)]\n",
    "\n",
    "        y = np.zeros(len(word2idx) + 1)\n",
    "        y[word2idx[answer]] = 1\n",
    "\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen), pad_sequences(Xq, maxlen=question_maxlen), np.array(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T11:53:04.628432Z",
     "start_time": "2024-01-19T11:53:04.626939Z"
    }
   },
   "id": "6b6ff441e284a342"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 83) (10000, 7) (10000, 27)\n",
      "(1000, 83) (1000, 7) (1000, 27)\n"
     ]
    }
   ],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)\n",
    "\n",
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape)\n",
    "print(Xstest.shape, Xqtest.shape, Ytest.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T11:54:01.255451Z",
     "start_time": "2024-01-19T11:53:04.630928Z"
    }
   },
   "id": "cbc8ada98504ff5e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
