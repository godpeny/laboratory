{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "\n",
    "import gensim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:07:22.569717Z",
     "start_time": "2023-10-29T02:07:21.415949Z"
    }
   },
   "id": "4107e130aea2db6c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Basics of Embedding Layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd69bf3faf4f9c1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec7bd7cce4eebb95"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# data sets\n",
    "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
    "y_train = [1, 0, 0, 1, 1, 0, 1] # 1 - good, 0 - bad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T01:32:55.860841Z",
     "start_time": "2023-10-29T01:32:55.858938Z"
    }
   },
   "id": "e7e44b7512e83863"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# tokenizing\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "vocab_size = len(tokenizer.word_index) + 1 # \n",
    "print(vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T01:41:07.254040Z",
     "start_time": "2023-10-29T01:41:07.249922Z"
    }
   },
   "id": "a2d22b07c258f014"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
     ]
    }
   ],
   "source": [
    "# encoding sentences using tokenizer\n",
    "X_encoded = tokenizer.texts_to_sequences(sentences)\n",
    "print(X_encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T01:41:07.671696Z",
     "start_time": "2023-10-29T01:41:07.668635Z"
    }
   },
   "id": "6b3e68968f97839"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(7, 4)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "# padding\n",
    "max_len = max(len(l) for l in X_encoded)\n",
    "print(max_len)\n",
    "\n",
    "X_train = pad_sequences(sequences=X_encoded, maxlen=max_len, padding='post')\n",
    "y_train = np.array(y_train) # \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T01:41:08.041938Z",
     "start_time": "2023-10-29T01:41:08.037834Z"
    }
   },
   "id": "90953767f9a6cbef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "158e3bae8a0d7cbd"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 4, 4)              64        \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81 (324.00 Byte)\n",
      "Trainable params: 81 (324.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 0.6992 - acc: 0.4286 - 141ms/epoch - 141ms/step\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.6976 - acc: 0.4286 - 2ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.6960 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.6944 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.6928 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.6912 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.6896 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.6880 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.6865 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.6849 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.6833 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.6817 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.6801 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.6785 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.6770 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.6754 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.6738 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.6722 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.6706 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.6690 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 0.6674 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 0.6658 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 0.6642 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 0.6626 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 0.6609 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 0.6593 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 0.6577 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 0.6560 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 0.6544 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 0.6527 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 0.6510 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 0.6494 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 0.6477 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 0.6460 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 0.6443 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 0.6426 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 0.6409 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 0.6391 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 0.6374 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 0.6357 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 0.6339 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 0.6321 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 0.6304 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 0.6286 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 0.6268 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 0.6250 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 0.6232 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 0.6214 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 0.6196 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.6177 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.6159 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.6140 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.6122 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.6103 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.6084 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.6065 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.6046 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.6027 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.6008 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.5989 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.5969 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.5950 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.5930 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.5911 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.5891 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.5871 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.5851 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.5832 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.5811 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.5791 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.5771 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.5751 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.5731 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.5710 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.5690 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.5669 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.5649 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.5628 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.5607 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.5587 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.5566 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.5545 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.5524 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.5503 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.5482 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.5460 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.5439 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.5418 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.5397 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.5375 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.5354 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.5332 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.5311 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.5289 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.5267 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.5246 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.5224 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.5202 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.5181 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.5159 - acc: 1.0000 - 2ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 4 # dimension of embedding vectors\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(Flatten()) # flatten embedded vectors to make it 1D for Dense layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "hist = model.fit(X_train, y_train, epochs=100, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T01:44:03.034983Z",
     "start_time": "2023-10-29T01:44:02.605453Z"
    }
   },
   "id": "a0fee7e647f63110"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[[0.49260873]]\n"
     ]
    }
   ],
   "source": [
    "print(hist.history['acc'][-1])\n",
    "print(model.predict([[1,0,0,0]]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T01:46:39.640358Z",
     "start_time": "2023-10-29T01:46:39.589956Z"
    }
   },
   "id": "56f190dc0c61ae5a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using Pretrained GloVe Embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d7bb6dff4f14c08"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60b980c01dd59089"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained word vectors and create embedding dict\n",
    "model_path = \"../model/\"\n",
    "model_name = \"glove.6B.100d.txt\"\n",
    "\n",
    "embedding_dict = dict()\n",
    "\n",
    "f = open(model_path + model_name, encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split() # e.g., ['the', '0.418', '0.24968', '-0.41242', '0.1217', ...]\n",
    "    word = values[0] # word\n",
    "    \n",
    "    vectors = np.asarray(values[1:], 'float32') # vector representations of words\n",
    "    embedding_dict[word] = vectors\n",
    "f.close()\n",
    "\n",
    "print(len(embedding_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:11:08.562105Z",
     "start_time": "2023-10-29T02:11:04.668738Z"
    }
   },
   "id": "5d7f5df325a70ae6"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "(16, 100)\n"
     ]
    }
   ],
   "source": [
    "# making embedding matrix using embedding dict\n",
    "embedding_dims = len(embedding_dict['the']) # \n",
    "print(embedding_dims)\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dims))\n",
    "print(embedding_matrix.shape)\n",
    "\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embedding_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:18:12.926916Z",
     "start_time": "2023-10-29T02:18:12.922041Z"
    }
   },
   "id": "c9dfff1298fe62b2"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.013786   0.38216    0.53236    0.15261   -0.29694   -0.20558\n",
      " -0.41846   -0.58437   -0.77355   -0.87866   -0.37858   -0.18516\n",
      " -0.128     -0.20584   -0.22925   -0.42599    0.3725     0.26077\n",
      " -1.0702     0.62916   -0.091469   0.70348   -0.4973    -0.77691\n",
      "  0.66045    0.09465   -0.44893    0.018917   0.33146   -0.35022\n",
      " -0.35789    0.030313   0.22253   -0.23236   -0.19719   -0.0053125\n",
      " -0.25848    0.58081   -0.10705   -0.17845   -0.16206    0.087086\n",
      "  0.63029   -0.76649    0.51619    0.14073    1.019     -0.43136\n",
      "  0.46138   -0.43585   -0.47568    0.19226    0.36065    0.78987\n",
      "  0.088945  -2.7814    -0.15366    0.01015    1.1798     0.15168\n",
      " -0.050112   1.2626    -0.77527    0.36031    0.95761   -0.11385\n",
      "  0.28035   -0.02591    0.31246   -0.15424    0.3778    -0.13599\n",
      "  0.2946    -0.31579    0.42943    0.086969   0.019169  -0.27242\n",
      " -0.31696    0.37327    0.61997    0.13889    0.17188    0.30363\n",
      " -1.2776     0.044423  -0.52736   -0.88536   -0.19428   -0.61947\n",
      " -0.10146   -0.26301   -0.061707   0.36627   -0.95223   -0.39346\n",
      " -0.69183   -1.0426     0.28855    0.63056  ]\n",
      "2\n",
      "[-0.013786    0.38216001  0.53236002  0.15261    -0.29694    -0.20558\n",
      " -0.41846001 -0.58437002 -0.77354997 -0.87866002 -0.37858    -0.18516\n",
      " -0.12800001 -0.20584001 -0.22925    -0.42598999  0.3725      0.26076999\n",
      " -1.07019997  0.62915999 -0.091469    0.70348001 -0.4973     -0.77691001\n",
      "  0.66044998  0.09465    -0.44893     0.018917    0.33146    -0.35021999\n",
      " -0.35789001  0.030313    0.22253001 -0.23236001 -0.19719    -0.0053125\n",
      " -0.25848001  0.58081001 -0.10705    -0.17845    -0.16205999  0.087086\n",
      "  0.63028997 -0.76648998  0.51618999  0.14072999  1.01900005 -0.43136001\n",
      "  0.46138    -0.43584999 -0.47567999  0.19226     0.36065     0.78987002\n",
      "  0.088945   -2.78139997 -0.15366     0.01015     1.17980003  0.15167999\n",
      " -0.050112    1.26259995 -0.77526999  0.36030999  0.95761001 -0.11385\n",
      "  0.28035    -0.02591     0.31246001 -0.15424     0.37779999 -0.13598999\n",
      "  0.29460001 -0.31579     0.42943001  0.086969    0.019169   -0.27241999\n",
      " -0.31696001  0.37327     0.61997002  0.13889     0.17188001  0.30362999\n",
      " -1.27760005  0.044423   -0.52736002 -0.88536    -0.19428    -0.61947\n",
      " -0.10146    -0.26301    -0.061707    0.36627001 -0.95222998 -0.39346001\n",
      " -0.69182998 -1.04260004  0.28854999  0.63055998]\n"
     ]
    }
   ],
   "source": [
    "# check embedding matrix\n",
    "print(embedding_dict['great']) # show vector representation of 'great'\n",
    "print(tokenizer.word_index['great']) # show index of 'great' -> 2\n",
    "print(embedding_matrix[2]) # show vector representation of 'great' in embedding matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:19:23.492545Z",
     "start_time": "2023-10-29T02:19:23.475147Z"
    }
   },
   "id": "d6b7c29d867c4a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21f95c3e0f59eb77"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 4, 100)            1600      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 401       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2001 (7.82 KB)\n",
      "Trainable params: 401 (1.57 KB)\n",
      "Non-trainable params: 1600 (6.25 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 0.7263 - acc: 0.4286 - 124ms/epoch - 124ms/step\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.7029 - acc: 0.4286 - 2ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.6804 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.6588 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.6381 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.6183 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.5993 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.5812 - acc: 0.7143 - 1ms/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.5638 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.5473 - acc: 0.7143 - 2ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.5315 - acc: 0.7143 - 1ms/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.5164 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.5021 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.4883 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.4751 - acc: 0.8571 - 1ms/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.4626 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.4505 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.4389 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.4278 - acc: 0.8571 - 2ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.4171 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 0.4068 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 0.3969 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 0.3873 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 0.3781 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 0.3692 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 0.3605 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 0.3522 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 0.3441 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 0.3362 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 0.3286 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 0.3213 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 0.3141 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 0.3072 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 0.3004 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 0.2939 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 0.2875 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 0.2813 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 0.2753 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 0.2695 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 0.2638 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 0.2583 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 0.2530 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 0.2478 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 0.2427 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 0.2378 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 0.2331 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 0.2284 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 0.2239 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 0.2196 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.2153 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.2112 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.2072 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.2033 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.1995 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.1958 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.1922 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.1887 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.1853 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.1820 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.1788 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.1757 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.1726 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.1697 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.1668 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.1640 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.1612 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.1586 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.1560 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.1535 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.1510 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.1486 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.1462 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.1440 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.1417 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.1395 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.1374 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.1354 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.1333 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.1314 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.1294 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.1275 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.1257 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.1239 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.1221 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.1204 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.1187 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.1171 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.1155 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.1139 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.1124 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.1109 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.1094 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.1080 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.1066 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.1052 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.1038 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.1025 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.1012 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.1000 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.0987 - acc: 1.0000 - 2ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "embedding_dims = 100\n",
    "\n",
    "model = Sequential()\n",
    "# using embedding_matrix as weights and not trainable to use pre-trained word vectors\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dims, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "hist = model.fit(X_train, y_train, epochs=100, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:26:16.420097Z",
     "start_time": "2023-10-29T02:26:16.006752Z"
    }
   },
   "id": "d479ccf0eb4193cd"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[0.3936007]]\n"
     ]
    }
   ],
   "source": [
    "print(hist.history['acc'][-1])\n",
    "print(model.predict([[1,0,0,0]]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:26:34.704280Z",
     "start_time": "2023-10-29T02:26:34.651575Z"
    }
   },
   "id": "77e2e0f2f78ecb75"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using Pretrained Word2Vec Embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52c600b23f41dbc4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70de1825c2146009"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000000, 300)\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained word vectors and create embedding dict\n",
    "model_name = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "word_2_vec = gensim.models.KeyedVectors.load_word2vec_format(model_path + model_name, binary=True)\n",
    "print(word_2_vec.vectors.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:29:09.835622Z",
     "start_time": "2023-10-29T02:28:54.216729Z"
    }
   },
   "id": "9cba180b4caa47c9"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 300)\n"
     ]
    }
   ],
   "source": [
    "# making embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "print(embedding_matrix.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:33:04.861281Z",
     "start_time": "2023-10-29T02:33:04.840897Z"
    }
   },
   "id": "ee7d2cd9bcb5009c"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def get_word(word):\n",
    "    if word in word_2_vec:\n",
    "        return word_2_vec[word]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "for word, index in tokenizer.word_index.items():\n",
    "    vector = get_word(word)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[index] = vector"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:34:02.167272Z",
     "start_time": "2023-10-29T02:34:02.142539Z"
    }
   },
   "id": "288df6c85bcf6248"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.17773438e-02  2.08007812e-01 -2.84423828e-02  1.78710938e-01\n",
      "  1.32812500e-01 -9.96093750e-02  9.61914062e-02 -1.16699219e-01\n",
      " -8.54492188e-03  1.48437500e-01 -3.34472656e-02 -1.85546875e-01\n",
      "  4.10156250e-02 -8.98437500e-02  2.17285156e-02  6.93359375e-02\n",
      "  1.80664062e-01  2.22656250e-01 -1.00585938e-01 -6.93359375e-02\n",
      "  1.04427338e-04  1.60156250e-01  4.07714844e-02  7.37304688e-02\n",
      "  1.53320312e-01  6.78710938e-02 -1.03027344e-01  4.17480469e-02\n",
      "  4.27246094e-02 -1.10351562e-01 -6.68945312e-02  4.19921875e-02\n",
      "  2.50000000e-01  2.12890625e-01  1.59179688e-01  1.44653320e-02\n",
      " -4.88281250e-02  1.39770508e-02  3.55529785e-03  2.09960938e-01\n",
      "  1.52343750e-01 -7.32421875e-02  2.16796875e-01 -5.76171875e-02\n",
      " -2.84423828e-02 -3.60107422e-03  1.52343750e-01 -2.63671875e-02\n",
      "  2.13623047e-02 -1.51367188e-01  1.04003906e-01  3.18359375e-01\n",
      " -1.85546875e-01  3.68652344e-02 -1.10839844e-01 -3.17382812e-02\n",
      " -1.01562500e-01 -1.21093750e-01  3.22265625e-01 -7.32421875e-02\n",
      " -1.52343750e-01  2.67578125e-01 -1.50390625e-01 -1.23046875e-01\n",
      "  1.07910156e-01  6.68945312e-02 -2.13623047e-02 -1.00585938e-01\n",
      " -2.05078125e-01  1.17675781e-01  6.15234375e-02  6.78710938e-02\n",
      "  1.06933594e-01 -7.71484375e-02 -1.52343750e-01 -4.24194336e-03\n",
      " -1.45507812e-01  2.53906250e-01  4.80957031e-02  9.71679688e-02\n",
      " -8.36181641e-03  1.12792969e-01  5.34667969e-02  1.79443359e-02\n",
      " -5.63964844e-02 -3.30078125e-01 -9.76562500e-02  1.42578125e-01\n",
      " -1.37695312e-01  2.20947266e-02  1.00097656e-01 -5.71289062e-02\n",
      " -1.56250000e-01 -6.37817383e-03 -9.37500000e-02 -4.68750000e-02\n",
      "  8.59375000e-02  3.06640625e-01 -1.11328125e-01 -1.94335938e-01\n",
      " -2.08007812e-01  8.10546875e-02 -4.19921875e-02 -8.30078125e-02\n",
      " -1.04003906e-01  2.92968750e-01  2.39257812e-02 -3.85742188e-02\n",
      "  3.56445312e-02 -1.04980469e-01 -6.54296875e-02  2.79296875e-01\n",
      " -1.16210938e-01 -1.45874023e-02  3.84765625e-01 -7.81250000e-02\n",
      " -2.92968750e-02 -1.35742188e-01 -5.39550781e-02 -5.49316406e-02\n",
      " -8.10546875e-02 -2.88085938e-02  8.34960938e-02  2.73437500e-01\n",
      " -6.20117188e-02 -4.78515625e-02 -1.09252930e-02 -1.13769531e-01\n",
      " -1.09863281e-01  2.02148438e-01 -1.28906250e-01 -6.68945312e-02\n",
      " -2.67578125e-01  9.61914062e-02  1.04003906e-01 -1.69921875e-01\n",
      "  5.56640625e-02  1.54296875e-01  8.05664062e-02  2.19726562e-01\n",
      " -2.27539062e-01  1.10351562e-01 -8.11767578e-03 -5.63964844e-02\n",
      " -9.03320312e-02 -7.76367188e-02 -3.61328125e-02  3.61328125e-02\n",
      "  1.58203125e-01 -1.56250000e-01  2.26562500e-01  2.85156250e-01\n",
      " -5.51757812e-02  3.53515625e-01 -1.20605469e-01  1.05957031e-01\n",
      "  3.11279297e-02 -1.91406250e-01 -2.31445312e-01 -1.11816406e-01\n",
      "  2.38037109e-03  7.51953125e-02 -1.28784180e-02  1.00585938e-01\n",
      "  4.45312500e-01 -2.77343750e-01  6.68945312e-02 -8.10546875e-02\n",
      "  6.39648438e-02  1.85546875e-02 -1.11328125e-01  9.76562500e-02\n",
      "  2.06054688e-01 -1.30859375e-01  2.39257812e-02  1.10839844e-01\n",
      "  8.05664062e-02 -1.52343750e-01  4.85229492e-03  1.84326172e-02\n",
      " -9.17968750e-02 -2.41210938e-01  8.39843750e-02 -1.00585938e-01\n",
      " -1.54296875e-01  2.75878906e-02 -1.64062500e-01 -1.01562500e-01\n",
      " -6.07299805e-03  1.33514404e-03 -2.53906250e-01  3.14453125e-01\n",
      "  1.31835938e-01 -1.31835938e-01  2.17285156e-02 -1.56250000e-01\n",
      " -1.46484375e-01 -5.12695312e-02 -1.20605469e-01 -2.15820312e-01\n",
      "  3.10058594e-02  1.30859375e-01  9.71679688e-02  5.67626953e-03\n",
      "  2.20947266e-02  1.26953125e-01 -1.24511719e-02  6.15234375e-02\n",
      " -2.23388672e-02  2.50000000e-01 -7.17773438e-02  1.58203125e-01\n",
      " -7.27539062e-02  1.97753906e-02  8.85009766e-03 -9.08203125e-02\n",
      "  3.63281250e-01 -9.03320312e-02  2.41699219e-02 -1.39770508e-02\n",
      " -5.10253906e-02  2.40478516e-02  5.88989258e-03 -1.02050781e-01\n",
      " -8.85009766e-03  3.05175781e-02 -7.81250000e-02 -1.27929688e-01\n",
      "  3.85742188e-02  2.86865234e-02 -2.28515625e-01 -1.25122070e-02\n",
      "  1.54296875e-01  9.13085938e-02  1.05468750e-01 -6.44531250e-02\n",
      " -1.28906250e-01 -1.02050781e-01 -2.16064453e-02 -3.29589844e-02\n",
      "  7.47070312e-02  3.78417969e-02  7.42187500e-02 -1.23901367e-02\n",
      " -4.68750000e-02  4.88281250e-03  1.03515625e-01 -8.69140625e-02\n",
      " -2.26562500e-01 -2.53906250e-01  3.58886719e-02  4.45312500e-01\n",
      "  5.56640625e-02  1.59179688e-01  2.71484375e-01 -1.08398438e-01\n",
      "  6.25000000e-02 -5.59082031e-02 -2.50000000e-01 -1.55273438e-01\n",
      " -6.83593750e-02 -1.39648438e-01 -1.59179688e-01 -1.79443359e-02\n",
      "  2.12402344e-02  7.37304688e-02  1.30859375e-01 -8.05664062e-02\n",
      "  2.99072266e-02  1.55639648e-02 -1.66015625e-01  1.50390625e-01\n",
      " -6.77490234e-03  1.01318359e-02  1.14746094e-01 -1.48437500e-01\n",
      " -4.58984375e-02 -1.39648438e-01 -1.73828125e-01 -4.27246094e-02\n",
      " -5.81054688e-02  5.22460938e-02 -1.11328125e-01  8.44726562e-02\n",
      " -2.55126953e-02  1.40625000e-01 -1.81640625e-01  1.72119141e-02\n",
      " -1.37695312e-01 -1.47705078e-02 -1.14746094e-02  6.44531250e-02\n",
      " -2.89062500e-01 -4.80957031e-02 -1.99218750e-01 -7.12890625e-02\n",
      "  6.44531250e-02 -1.67968750e-01 -2.08740234e-02 -1.42578125e-01]\n",
      "2\n",
      "[ 7.17773438e-02  2.08007812e-01 -2.84423828e-02  1.78710938e-01\n",
      "  1.32812500e-01 -9.96093750e-02  9.61914062e-02 -1.16699219e-01\n",
      " -8.54492188e-03  1.48437500e-01 -3.34472656e-02 -1.85546875e-01\n",
      "  4.10156250e-02 -8.98437500e-02  2.17285156e-02  6.93359375e-02\n",
      "  1.80664062e-01  2.22656250e-01 -1.00585938e-01 -6.93359375e-02\n",
      "  1.04427338e-04  1.60156250e-01  4.07714844e-02  7.37304688e-02\n",
      "  1.53320312e-01  6.78710938e-02 -1.03027344e-01  4.17480469e-02\n",
      "  4.27246094e-02 -1.10351562e-01 -6.68945312e-02  4.19921875e-02\n",
      "  2.50000000e-01  2.12890625e-01  1.59179688e-01  1.44653320e-02\n",
      " -4.88281250e-02  1.39770508e-02  3.55529785e-03  2.09960938e-01\n",
      "  1.52343750e-01 -7.32421875e-02  2.16796875e-01 -5.76171875e-02\n",
      " -2.84423828e-02 -3.60107422e-03  1.52343750e-01 -2.63671875e-02\n",
      "  2.13623047e-02 -1.51367188e-01  1.04003906e-01  3.18359375e-01\n",
      " -1.85546875e-01  3.68652344e-02 -1.10839844e-01 -3.17382812e-02\n",
      " -1.01562500e-01 -1.21093750e-01  3.22265625e-01 -7.32421875e-02\n",
      " -1.52343750e-01  2.67578125e-01 -1.50390625e-01 -1.23046875e-01\n",
      "  1.07910156e-01  6.68945312e-02 -2.13623047e-02 -1.00585938e-01\n",
      " -2.05078125e-01  1.17675781e-01  6.15234375e-02  6.78710938e-02\n",
      "  1.06933594e-01 -7.71484375e-02 -1.52343750e-01 -4.24194336e-03\n",
      " -1.45507812e-01  2.53906250e-01  4.80957031e-02  9.71679688e-02\n",
      " -8.36181641e-03  1.12792969e-01  5.34667969e-02  1.79443359e-02\n",
      " -5.63964844e-02 -3.30078125e-01 -9.76562500e-02  1.42578125e-01\n",
      " -1.37695312e-01  2.20947266e-02  1.00097656e-01 -5.71289062e-02\n",
      " -1.56250000e-01 -6.37817383e-03 -9.37500000e-02 -4.68750000e-02\n",
      "  8.59375000e-02  3.06640625e-01 -1.11328125e-01 -1.94335938e-01\n",
      " -2.08007812e-01  8.10546875e-02 -4.19921875e-02 -8.30078125e-02\n",
      " -1.04003906e-01  2.92968750e-01  2.39257812e-02 -3.85742188e-02\n",
      "  3.56445312e-02 -1.04980469e-01 -6.54296875e-02  2.79296875e-01\n",
      " -1.16210938e-01 -1.45874023e-02  3.84765625e-01 -7.81250000e-02\n",
      " -2.92968750e-02 -1.35742188e-01 -5.39550781e-02 -5.49316406e-02\n",
      " -8.10546875e-02 -2.88085938e-02  8.34960938e-02  2.73437500e-01\n",
      " -6.20117188e-02 -4.78515625e-02 -1.09252930e-02 -1.13769531e-01\n",
      " -1.09863281e-01  2.02148438e-01 -1.28906250e-01 -6.68945312e-02\n",
      " -2.67578125e-01  9.61914062e-02  1.04003906e-01 -1.69921875e-01\n",
      "  5.56640625e-02  1.54296875e-01  8.05664062e-02  2.19726562e-01\n",
      " -2.27539062e-01  1.10351562e-01 -8.11767578e-03 -5.63964844e-02\n",
      " -9.03320312e-02 -7.76367188e-02 -3.61328125e-02  3.61328125e-02\n",
      "  1.58203125e-01 -1.56250000e-01  2.26562500e-01  2.85156250e-01\n",
      " -5.51757812e-02  3.53515625e-01 -1.20605469e-01  1.05957031e-01\n",
      "  3.11279297e-02 -1.91406250e-01 -2.31445312e-01 -1.11816406e-01\n",
      "  2.38037109e-03  7.51953125e-02 -1.28784180e-02  1.00585938e-01\n",
      "  4.45312500e-01 -2.77343750e-01  6.68945312e-02 -8.10546875e-02\n",
      "  6.39648438e-02  1.85546875e-02 -1.11328125e-01  9.76562500e-02\n",
      "  2.06054688e-01 -1.30859375e-01  2.39257812e-02  1.10839844e-01\n",
      "  8.05664062e-02 -1.52343750e-01  4.85229492e-03  1.84326172e-02\n",
      " -9.17968750e-02 -2.41210938e-01  8.39843750e-02 -1.00585938e-01\n",
      " -1.54296875e-01  2.75878906e-02 -1.64062500e-01 -1.01562500e-01\n",
      " -6.07299805e-03  1.33514404e-03 -2.53906250e-01  3.14453125e-01\n",
      "  1.31835938e-01 -1.31835938e-01  2.17285156e-02 -1.56250000e-01\n",
      " -1.46484375e-01 -5.12695312e-02 -1.20605469e-01 -2.15820312e-01\n",
      "  3.10058594e-02  1.30859375e-01  9.71679688e-02  5.67626953e-03\n",
      "  2.20947266e-02  1.26953125e-01 -1.24511719e-02  6.15234375e-02\n",
      " -2.23388672e-02  2.50000000e-01 -7.17773438e-02  1.58203125e-01\n",
      " -7.27539062e-02  1.97753906e-02  8.85009766e-03 -9.08203125e-02\n",
      "  3.63281250e-01 -9.03320312e-02  2.41699219e-02 -1.39770508e-02\n",
      " -5.10253906e-02  2.40478516e-02  5.88989258e-03 -1.02050781e-01\n",
      " -8.85009766e-03  3.05175781e-02 -7.81250000e-02 -1.27929688e-01\n",
      "  3.85742188e-02  2.86865234e-02 -2.28515625e-01 -1.25122070e-02\n",
      "  1.54296875e-01  9.13085938e-02  1.05468750e-01 -6.44531250e-02\n",
      " -1.28906250e-01 -1.02050781e-01 -2.16064453e-02 -3.29589844e-02\n",
      "  7.47070312e-02  3.78417969e-02  7.42187500e-02 -1.23901367e-02\n",
      " -4.68750000e-02  4.88281250e-03  1.03515625e-01 -8.69140625e-02\n",
      " -2.26562500e-01 -2.53906250e-01  3.58886719e-02  4.45312500e-01\n",
      "  5.56640625e-02  1.59179688e-01  2.71484375e-01 -1.08398438e-01\n",
      "  6.25000000e-02 -5.59082031e-02 -2.50000000e-01 -1.55273438e-01\n",
      " -6.83593750e-02 -1.39648438e-01 -1.59179688e-01 -1.79443359e-02\n",
      "  2.12402344e-02  7.37304688e-02  1.30859375e-01 -8.05664062e-02\n",
      "  2.99072266e-02  1.55639648e-02 -1.66015625e-01  1.50390625e-01\n",
      " -6.77490234e-03  1.01318359e-02  1.14746094e-01 -1.48437500e-01\n",
      " -4.58984375e-02 -1.39648438e-01 -1.73828125e-01 -4.27246094e-02\n",
      " -5.81054688e-02  5.22460938e-02 -1.11328125e-01  8.44726562e-02\n",
      " -2.55126953e-02  1.40625000e-01 -1.81640625e-01  1.72119141e-02\n",
      " -1.37695312e-01 -1.47705078e-02 -1.14746094e-02  6.44531250e-02\n",
      " -2.89062500e-01 -4.80957031e-02 -1.99218750e-01 -7.12890625e-02\n",
      "  6.44531250e-02 -1.67968750e-01 -2.08740234e-02 -1.42578125e-01]\n"
     ]
    }
   ],
   "source": [
    "# check embedding matrix\n",
    "print(word_2_vec['great'])\n",
    "print(tokenizer.word_index['great'])\n",
    "print(embedding_matrix[2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:35:19.411082Z",
     "start_time": "2023-10-29T02:35:19.402643Z"
    }
   },
   "id": "6dd25fe3420159a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c02f27c049aced"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 4, 300)            4800      \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1200)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 1201      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6001 (23.44 KB)\n",
      "Trainable params: 1201 (4.69 KB)\n",
      "Non-trainable params: 4800 (18.75 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1/1 - 0s - loss: 0.6996 - acc: 0.2857 - 119ms/epoch - 119ms/step\n",
      "Epoch 2/100\n",
      "1/1 - 0s - loss: 0.6805 - acc: 0.5714 - 2ms/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "1/1 - 0s - loss: 0.6619 - acc: 0.8571 - 1ms/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "1/1 - 0s - loss: 0.6440 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "1/1 - 0s - loss: 0.6265 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "1/1 - 0s - loss: 0.6097 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "1/1 - 0s - loss: 0.5934 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "1/1 - 0s - loss: 0.5776 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "1/1 - 0s - loss: 0.5624 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "1/1 - 0s - loss: 0.5478 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "1/1 - 0s - loss: 0.5336 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "1/1 - 0s - loss: 0.5199 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "1/1 - 0s - loss: 0.5068 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "1/1 - 0s - loss: 0.4940 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "1/1 - 0s - loss: 0.4818 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "1/1 - 0s - loss: 0.4700 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "1/1 - 0s - loss: 0.4585 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "1/1 - 0s - loss: 0.4475 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "1/1 - 0s - loss: 0.4369 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "1/1 - 0s - loss: 0.4266 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "1/1 - 0s - loss: 0.4166 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "1/1 - 0s - loss: 0.4070 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "1/1 - 0s - loss: 0.3977 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "1/1 - 0s - loss: 0.3887 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "1/1 - 0s - loss: 0.3800 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "1/1 - 0s - loss: 0.3716 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "1/1 - 0s - loss: 0.3634 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "1/1 - 0s - loss: 0.3555 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "1/1 - 0s - loss: 0.3478 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "1/1 - 0s - loss: 0.3404 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "1/1 - 0s - loss: 0.3332 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "1/1 - 0s - loss: 0.3262 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "1/1 - 0s - loss: 0.3194 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "1/1 - 0s - loss: 0.3128 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "1/1 - 0s - loss: 0.3065 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "1/1 - 0s - loss: 0.3003 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "1/1 - 0s - loss: 0.2943 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "1/1 - 0s - loss: 0.2884 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "1/1 - 0s - loss: 0.2827 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "1/1 - 0s - loss: 0.2772 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "1/1 - 0s - loss: 0.2719 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "1/1 - 0s - loss: 0.2667 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "1/1 - 0s - loss: 0.2616 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "1/1 - 0s - loss: 0.2567 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "1/1 - 0s - loss: 0.2519 - acc: 1.0000 - 3ms/epoch - 3ms/step\n",
      "Epoch 46/100\n",
      "1/1 - 0s - loss: 0.2472 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "1/1 - 0s - loss: 0.2427 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "1/1 - 0s - loss: 0.2383 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "1/1 - 0s - loss: 0.2340 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "1/1 - 0s - loss: 0.2299 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "1/1 - 0s - loss: 0.2258 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "1/1 - 0s - loss: 0.2219 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "1/1 - 0s - loss: 0.2180 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "1/1 - 0s - loss: 0.2143 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "1/1 - 0s - loss: 0.2106 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "1/1 - 0s - loss: 0.2071 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "1/1 - 0s - loss: 0.2036 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "1/1 - 0s - loss: 0.2002 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "1/1 - 0s - loss: 0.1969 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "1/1 - 0s - loss: 0.1937 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "1/1 - 0s - loss: 0.1906 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "1/1 - 0s - loss: 0.1875 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "1/1 - 0s - loss: 0.1845 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "1/1 - 0s - loss: 0.1816 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "1/1 - 0s - loss: 0.1788 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "1/1 - 0s - loss: 0.1760 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "1/1 - 0s - loss: 0.1733 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "1/1 - 0s - loss: 0.1707 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "1/1 - 0s - loss: 0.1681 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "1/1 - 0s - loss: 0.1656 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "1/1 - 0s - loss: 0.1631 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "1/1 - 0s - loss: 0.1607 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "1/1 - 0s - loss: 0.1584 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "1/1 - 0s - loss: 0.1561 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "1/1 - 0s - loss: 0.1539 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "1/1 - 0s - loss: 0.1517 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "1/1 - 0s - loss: 0.1495 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "1/1 - 0s - loss: 0.1474 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "1/1 - 0s - loss: 0.1454 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "1/1 - 0s - loss: 0.1434 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "1/1 - 0s - loss: 0.1414 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "1/1 - 0s - loss: 0.1395 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "1/1 - 0s - loss: 0.1376 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "1/1 - 0s - loss: 0.1357 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "1/1 - 0s - loss: 0.1339 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "1/1 - 0s - loss: 0.1322 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "1/1 - 0s - loss: 0.1304 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "1/1 - 0s - loss: 0.1287 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "1/1 - 0s - loss: 0.1271 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "1/1 - 0s - loss: 0.1255 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "1/1 - 0s - loss: 0.1239 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "1/1 - 0s - loss: 0.1223 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "1/1 - 0s - loss: 0.1208 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "1/1 - 0s - loss: 0.1193 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "1/1 - 0s - loss: 0.1178 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "1/1 - 0s - loss: 0.1164 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "1/1 - 0s - loss: 0.1149 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "1/1 - 0s - loss: 0.1136 - acc: 1.0000 - 2ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "1/1 - 0s - loss: 0.1122 - acc: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "1/1 - 0s - loss: 0.1109 - acc: 1.0000 - 1ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "embedding_dims = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dims, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "hist = model.fit(X_train, y_train, epochs=100, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:37:21.238757Z",
     "start_time": "2023-10-29T02:37:20.859253Z"
    }
   },
   "id": "ebcbe09b1011f8df"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[0.54948443]]\n"
     ]
    }
   ],
   "source": [
    "print(hist.history['acc'][-1])\n",
    "print(model.predict([[1,0,0,0]]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T02:37:42.453743Z",
     "start_time": "2023-10-29T02:37:42.405214Z"
    }
   },
   "id": "aa3112383b772fe8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2449503cc2f95c6f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
