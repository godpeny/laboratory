{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-02T08:30:01.055786Z",
     "start_time": "2023-12-02T08:29:58.369625Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                              review  sentiment\n0  My family and I normally do not watch local mo...          1\n1  Believe it or not, this was at one time the wo...          0\n2  After some internet surfing, I found the \"Home...          0\n3  One of the most unheralded great works of anim...          1\n4  It was the Sixties, and anyone with long hair ...          0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My family and I normally do not watch local mo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Believe it or not, this was at one time the wo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>After some internet surfing, I found the \"Home...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>One of the most unheralded great works of anim...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>It was the Sixties, and anyone with long hair ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/\"\n",
    "df = pd.read_csv(data_path+\"IMDB_Reviews.csv\")\n",
    "\n",
    "print(len(df))\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T08:34:13.183508Z",
     "start_time": "2023-12-02T08:34:12.727707Z"
    }
   },
   "id": "8400c0381ef40185"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing with Tensorflow Subword Tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "813ce9dfa07bf74a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the_', ', ', '. ', 'a_', 'and_', 'of_', 'to_', 's_', 'is_', 'br', 'in_', 'I_', 'that_', 'this_', 'it_', ' /><', ' />', 'was_', 'The_', 't_']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    df['review'], target_vocab_size=2**13\n",
    ")\n",
    "\n",
    "print(tokenizer.subwords[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T08:45:33.656047Z",
     "start_time": "2023-12-02T08:43:44.191663Z"
    }
   },
   "id": "a49758d819ea0b55"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty bad PRC cheapie which I rarely bother to watch over again, and it's no wonder -- it's slow and creaky and dull as a butter knife. Mad doctor George Zucco is at it again, turning a dimwitted farmhand in overalls (Glenn Strange) into a wolf-man. Unfortunately, the makeup is virtually non-existent, consisting only of a beard and dimestore fangs for the most part. If it were not for Zucco and Strange's presence, along with the cute Anne Nagel, this would be completely unwatchable. Strange, who would go on to play Frankenstein's monster for Unuiversal in two years, does a Lenny impression from \"Of Mice and Men\", it seems.<br /><br />*1/2 (of Four)\n",
      "[1590, 4162, 132, 7107, 1892, 2983, 578, 76, 12, 4632, 3422, 7, 160, 175, 372, 2, 5, 39, 8051, 8, 84, 2652, 497, 39, 8051, 8, 1374, 5, 3461, 2012, 48, 5, 2263, 21, 4, 2992, 127, 4729, 711, 3, 1391, 8044, 3557, 1277, 8102, 2154, 5681, 9, 42, 15, 372, 2, 3773, 4, 3502, 2308, 467, 4890, 1503, 11, 3347, 1419, 8127, 29, 5539, 98, 6099, 58, 94, 4, 1388, 4230, 8057, 213, 3, 1966, 2, 1, 6700, 8044, 9, 7069, 716, 8057, 6600, 2, 4102, 36, 78, 6, 4, 1865, 40, 5, 3502, 1043, 1645, 8044, 1000, 1813, 23, 1, 105, 1128, 3, 156, 15, 85, 33, 23, 8102, 2154, 5681, 5, 6099, 8051, 8, 7271, 1055, 2, 534, 22, 1, 3046, 5214, 810, 634, 8120, 2, 14, 71, 34, 436, 3311, 5447, 783, 3, 6099, 2, 46, 71, 193, 25, 7, 428, 2274, 2260, 6487, 8051, 8, 2149, 23, 1138, 4117, 6023, 163, 11, 148, 735, 2, 164, 4, 5277, 921, 3395, 1262, 37, 639, 1349, 349, 5, 2460, 328, 15, 5349, 8127, 24, 10, 16, 10, 17, 8054, 8061, 8059, 8062, 29, 6, 6607, 8126, 8053]\n"
     ]
    }
   ],
   "source": [
    "print(df['review'][20])\n",
    "print(tokenizer.encode(df['review'][20]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T08:47:13.912471Z",
     "start_time": "2023-12-02T08:47:13.906698Z"
    }
   },
   "id": "e789f6b5d2bb76f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5009 ----> Ten\n",
      "2369 ----> sor\n",
      "3734 ----> Fl\n",
      "1960 ----> ow\n",
      "2 ----> , \n",
      "47 ----> from \n",
      "4224 ----> basi\n",
      "6250 ----> cs \n",
      "7 ----> to \n",
      "2503 ----> master\n",
      "8133 ----> y\n"
     ]
    }
   ],
   "source": [
    "# test with a sample string\n",
    "sample_string = 'TensorFlow, from basics to mastery'\n",
    "sample_strings_encoded = tokenizer.encode(sample_string)\n",
    "\n",
    "for string in sample_strings_encoded:\n",
    "    print('{} ----> {}'.format(string, tokenizer.decode([string])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T08:50:45.085347Z",
     "start_time": "2023-12-02T08:50:45.078213Z"
    }
   },
   "id": "c90cb24d9d6f4892"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5009 ----> Ten\n",
      "2369 ----> sor\n",
      "3734 ----> Fl\n",
      "1960 ----> ow\n",
      "2 ----> , \n",
      "1262 ----> from\n",
      "8132 ----> x\n",
      "8132 ----> x\n",
      "48 ----> y \n",
      "4224 ----> basi\n",
      "6250 ----> cs \n",
      "7 ----> to \n",
      "2503 ----> master\n",
      "8133 ----> y\n"
     ]
    }
   ],
   "source": [
    "# test with a sample string with additional words\n",
    "sample_string_dirty = 'TensorFlow, fromxxy basics to mastery'\n",
    "sample_strings_encoded_dirty = tokenizer.encode(sample_string_dirty)\n",
    "\n",
    "for string in sample_strings_encoded_dirty:\n",
    "    print('{} ----> {}'.format(string, tokenizer.decode([string])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T08:52:36.572780Z",
     "start_time": "2023-12-02T08:52:36.568781Z"
    }
   },
   "id": "ffb4f0be610b2a28"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
