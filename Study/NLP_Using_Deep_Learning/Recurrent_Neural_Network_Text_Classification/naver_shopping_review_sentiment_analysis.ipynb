{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:55:39.132376Z",
     "start_time": "2023-11-13T13:55:36.729263Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import urllib.request\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "('../data/shopping_ratings_total.txt',\n <http.client.HTTPMessage at 0x294e310d0>)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/\"\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", \n",
    "    filename=data_path + \"shopping_ratings_total.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T13:55:41.691256Z",
     "start_time": "2023-11-13T13:55:40.991256Z"
    }
   },
   "id": "c515f9827cfa6edf"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "   ratings                                            reviews\n",
      "0        5                                            배공빠르고 굿\n",
      "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
      "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
      "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
      "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table(data_path + \"shopping_ratings_total.txt\", names=['ratings', 'reviews']) # set column names\n",
    "print(len(df))\n",
    "print(df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:00:07.850064Z",
     "start_time": "2023-11-13T14:00:07.492414Z"
    }
   },
   "id": "77f1bca95b92df54"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5574403fc927eee1"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   ratings                                            reviews  label\n0        5                                            배공빠르고 굿      1\n1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고      0\n2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...      1\n3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...      0\n4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ratings</th>\n      <th>reviews</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>배공빠르고 굿</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new columns\n",
    "df['label'] = df['ratings'].apply(lambda x: 1 if x>3 else 0) # 1: positive, 0: negative\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:00:08.940501Z",
     "start_time": "2023-11-13T14:00:08.904337Z"
    }
   },
   "id": "eda5d46604846070"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 199391 2\n",
      "199391 False\n",
      "199391 199391\n"
     ]
    }
   ],
   "source": [
    "# remove non-Korean characters\n",
    "df['reviews'].replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", regex=True, inplace=True) # convert non-Korean characters to blank\n",
    "df['reviews'].replace(\"\", np.nan, inplace=True) # convert blank to null\n",
    "\n",
    "# remove null and duplicate values\n",
    "print(df['ratings'].nunique(), df['reviews'].nunique(), df['label'].nunique()) # check unique values\n",
    "df.drop_duplicates(subset=['reviews'], inplace=True) # drop duplicates\n",
    "df.dropna(how='any', inplace=True) # drop null values\n",
    "print(len(df), df.isnull().values.any()) # check null values\n",
    "print(df['reviews'].nunique(), len(df)) # check unique values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:04:24.549605Z",
     "start_time": "2023-11-13T14:04:24.333743Z"
    }
   },
   "id": "c06cf78a81325bff"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199391\n",
      "149543 49848 None\n"
     ]
    }
   ],
   "source": [
    "# split total into train and test data\n",
    "train_data, test_data = train_test_split(df, test_size=0.25, random_state=42) # random_state: seed\n",
    "print(len(train_data), len(test_data), print(len(df)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:02:57.917168Z",
     "start_time": "2023-11-13T14:02:57.901342Z"
    }
   },
   "id": "bff0891574f02ddf"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: xlabel='label'>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # check if evenly distributed\n",
    "train_data['label'].value_counts().plot(kind='bar')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:03:01.268636Z",
     "start_time": "2023-11-13T14:03:01.213215Z"
    }
   },
   "id": "27a5c674515ea9c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7011e231ac3a6697"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오다', '이렇다', '것', '도', '상품', '이라고', '차라리', '내', '가', '만들다', '게', '나다', '뻔']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']\n",
    "\n",
    "print(okt.morphs('와 이런 것도 상품이라고 차라리 내가 만드는 게 나을 뻔', stem=True)) # test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:04:37.593486Z",
     "start_time": "2023-11-13T14:04:35.474014Z"
    }
   },
   "id": "6d44e674f0d67d01"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "train_data['tokenized'] = train_data['reviews'].apply(lambda x: okt.morphs(x)) # tokenize train data\n",
    "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [word for word in x if not word in stopwords]) # remove stopwords\n",
    "\n",
    "test_data['tokenized'] = test_data['reviews'].apply(lambda x: okt.morphs(x)) # tokenize test data\n",
    "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [word for word in x if not word in stopwords]) # remove stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:10:45.005085Z",
     "start_time": "2023-11-13T14:04:38.567012Z"
    }
   },
   "id": "ee6c28af84871206"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13249                          [우엉, 진짜, 흔적, 찾아볼수가, 옶, 어, 요]\n",
      "40329                              [소재, 좋아요, 바느질, 상태, 안좋네요]\n",
      "182405            [짧아요, 게다가, 벨, 크로, 접착, 력, 그리, 좋은, 편, 아니에요]\n",
      "188396    [시원한, 재질, 이고, 보송해서, 편해요, 바닥, 미끄럼, 방지, 잘, 되어있고,...\n",
      "135778         [안, 뜯어, 봐서, 모르겠고, 일, 제, 상품, 인지, 모르고, 구매, ㅉㅉ]\n",
      "Name: tokenized, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data['tokenized'].head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:14:52.474297Z",
     "start_time": "2023-11-13T14:14:52.466359Z"
    }
   },
   "id": "52e755905dd12a96"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('너무', 13169), ('요', 11773), ('안', 11688), ('배송', 9229), ('그냥', 8608), ('잘', 7825), ('로', 5779), ('했는데', 5664), ('별로', 5580), ('못', 5152), ('제품', 5092), ('으로', 5010), ('생각', 4963), ('좀', 4912), ('ㅠㅠ', 4759), ('하고', 4743), ('사용', 4737), ('보다', 4622), ('구매', 4532), ('만', 4018)]\n",
      "[('잘', 15383), ('좋아요', 14503), ('배송', 12169), ('너무', 9131), ('재구매', 8629), ('구매', 7136), ('요', 6591), ('사용', 5434), ('가격', 5071), ('같아요', 4446), ('로', 4439), ('으로', 4406), ('좋네요', 4168), ('보다', 3987), ('제품', 3974), ('빠르고', 3943), ('주문', 3845), ('입니다', 3744), ('생각', 3496), ('했어요', 3344)]\n"
     ]
    }
   ],
   "source": [
    "negative_words = np.hstack(train_data[train_data.label == 0]['tokenized'].values)\n",
    "positive_words = np.hstack(train_data[train_data.label == 1]['tokenized'].values)\n",
    "\n",
    "negative_count = Counter(negative_words)\n",
    "positive_count = Counter(positive_words)\n",
    "\n",
    "print(negative_count.most_common(20))\n",
    "print(positive_count.most_common(20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:13:44.384451Z",
     "start_time": "2023-11-13T14:13:43.376108Z"
    }
   },
   "id": "5c38ebfd1d6248f1"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.810190759022928\n",
      "14.152656139271818\n"
     ]
    }
   ],
   "source": [
    "positive_word_avg_len = np.mean([len(word) for word in train_data[train_data.label == 1]['tokenized']])\n",
    "negative_word_avg_len = np.mean([len(word) for word in train_data[train_data.label == 0]['tokenized']])\n",
    "print(positive_word_avg_len)\n",
    "print(negative_word_avg_len)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:17:58.860755Z",
     "start_time": "2023-11-13T14:17:58.827106Z"
    }
   },
   "id": "b441235ae237133c"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "X_train = train_data['tokenized'].values\n",
    "X_test = test_data['tokenized'].values\n",
    "y_train = train_data['label'].values\n",
    "y_test = test_data['label'].values\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:28:38.704063Z",
     "start_time": "2023-11-13T14:28:37.992772Z"
    }
   },
   "id": "2a33b7306f96172d"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of words:  94486\n",
      "number of rare words:  52424\n",
      "frequency of rare words:  2.808577024785596\n",
      "ratio of rare words:  55.48335203098872\n"
     ]
    }
   ],
   "source": [
    "threshold = 2\n",
    "total_cnt = len(tokenizer.word_index) # total number of words\n",
    "total_freq = 0 # total frequency of words\n",
    "rare_cnt = 0 # number of rare words\n",
    "rare_freq = 0 # frequency of rare words\n",
    "\n",
    "for word, value in tokenizer.word_counts.items():\n",
    "    total_freq += value\n",
    "    \n",
    "    if value < threshold:\n",
    "        rare_cnt += 1\n",
    "        rare_freq += value\n",
    "        \n",
    "                \n",
    "print('total number of words: ', total_cnt)\n",
    "print('number of rare words: ', rare_cnt)\n",
    "print('frequency of rare words: ', (rare_freq/total_freq) * 100)\n",
    "print('ratio of rare words: ', (rare_cnt/total_cnt) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:31:22.792933Z",
     "start_time": "2023-11-13T14:31:22.788755Z"
    }
   },
   "id": "df62a27932595d99"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 42064\n"
     ]
    }
   ],
   "source": [
    "vocab_size = total_cnt - rare_cnt + 2 # total number of words - number of rare words + <OOV>, <PAD>\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:32:43.712870Z",
     "start_time": "2023-11-13T14:32:43.694953Z"
    }
   },
   "id": "8cc635229e88e2fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OOV token is for word that is not in the vocabulary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d5fb3bc249bade1"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# re-tokenize with vocab_size and add 'out-of-vocabulary' token\n",
    "tokenizer = Tokenizer(vocab_size, oov_token='OOV')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:35:54.344382Z",
     "start_time": "2023-11-13T14:35:52.568585Z"
    }
   },
   "id": "b805800b55785b91"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4999, 62, 3376, 30062, 1, 124, 5], [503, 6, 1154, 96, 1404], [1207, 3127, 3128, 3377, 418, 200, 1662, 65, 733, 1341]]\n",
      "[[94, 16162, 188, 188, 88, 318, 4373, 395, 5, 150, 1, 649, 1433, 52, 164, 98, 22452, 701, 125, 47, 31, 524, 125], [8, 329, 9, 132, 1709, 135], [101, 4, 4916, 1088, 9381]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_seq[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:36:03.927904Z",
     "start_time": "2023-11-13T14:36:03.913187Z"
    }
   },
   "id": "90a24b0ccea96cfe"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of words:  61\n",
      "average length of words:  12.481814595133173\n"
     ]
    }
   ],
   "source": [
    "word_max = max(len(word) for word in X_train_seq)\n",
    "word_avg = sum(map(len, X_train_seq))/len(X_train_seq)\n",
    "\n",
    "print('maximum length of words: ', word_max)\n",
    "print('average length of words: ', word_avg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:38:15.501468Z",
     "start_time": "2023-11-13T14:38:15.480912Z"
    }
   },
   "id": "d7cca6a97f03e98b"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "    count = 0\n",
    "    for sentence in nested_list:\n",
    "        if len(sentence) <= max_len:\n",
    "            count = count + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:39:32.216965Z",
     "start_time": "2023-11-13T14:39:32.198638Z"
    }
   },
   "id": "be92f571313f2a9d"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 80 이하인 샘플의 비율: 100.0\n"
     ]
    }
   ],
   "source": [
    "max_len = 80\n",
    "below_threshold_len(max_len, X_train)\n",
    "\n",
    "X_train_seq_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_seq_pad = pad_sequences(X_test_seq, maxlen=max_len)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:41:14.252917Z",
     "start_time": "2023-11-13T14:41:14.044618Z"
    }
   },
   "id": "9791e3b2a1140b71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32b2846594185921"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dense, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:41:52.528824Z",
     "start_time": "2023-11-13T14:41:52.505875Z"
    }
   },
   "id": "92c7a5aca060c582"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         4206400   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               88320     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4294849 (16.38 MB)\n",
      "Trainable params: 4294849 (16.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(GRU(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:43:37.364974Z",
     "start_time": "2023-11-13T14:43:37.071282Z"
    }
   },
   "id": "8230e71965d49b3"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1994/1994 [==============================] - ETA: 0s - loss: 0.2743 - acc: 0.8955\n",
      "Epoch 1: val_acc improved from -inf to 0.91103, saving model to ../model/shopping_best_model.h5\n",
      "1994/1994 [==============================] - 148s 74ms/step - loss: 0.2743 - acc: 0.8955 - val_loss: 0.2439 - val_acc: 0.9110\n",
      "Epoch 2/15\n",
      "   2/1994 [..............................] - ETA: 2:17 - loss: 0.1609 - acc: 0.9250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/godpeny/Code/venv/laboratory/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994/1994 [==============================] - ETA: 0s - loss: 0.2184 - acc: 0.9211\n",
      "Epoch 2: val_acc improved from 0.91103 to 0.91518, saving model to ../model/shopping_best_model.h5\n",
      "1994/1994 [==============================] - 151s 76ms/step - loss: 0.2184 - acc: 0.9211 - val_loss: 0.2350 - val_acc: 0.9152\n",
      "Epoch 3/15\n",
      "  52/1994 [..............................] - ETA: 2:20 - loss: 0.1913 - acc: 0.9343"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[63], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m mc \u001B[38;5;241m=\u001B[39m ModelCheckpoint(model_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mshopping_best_model.h5\u001B[39m\u001B[38;5;124m'\u001B[39m, monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_acc\u001B[39m\u001B[38;5;124m'\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m'\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrmsprop\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124macc\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m----> 5\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_seq_pad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmc\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1266\u001B[0m     args,\n\u001B[1;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1268\u001B[0m     executing_eagerly)\n\u001B[1;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    262\u001B[0m     )\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1494\u001B[0m   )\n",
      "File \u001B[0;32m~/Code/venv/laboratory/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[1;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[1;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[1;32m     59\u001B[0m   ]\n\u001B[0;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model_path = '../model/'\n",
    "s = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint(model_path + 'shopping_best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train_seq_pad, y_train, epochs=15, callbacks=[s, mc], batch_size=60, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:49:54.489977Z",
     "start_time": "2023-11-13T14:44:51.173128Z"
    }
   },
   "id": "aa16cf2ae7fc4269"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558/1558 [==============================] - 26s 17ms/step - loss: 0.2316 - acc: 0.9160\n",
      "\n",
      " 테스트 정확도: 0.9160\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(model_path + 'shopping_best_model.h5')\n",
    "\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test_seq_pad, y_test)[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:54:03.640823Z",
     "start_time": "2023-11-13T14:53:37.285543Z"
    }
   },
   "id": "c479968b0d124ffd"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "    new_sentence = okt.morphs(new_sentence)\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords]\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence])\n",
    "    pad_new = pad_sequences(encoded, maxlen = max_len)\n",
    "\n",
    "    score = float(loaded_model.predict(pad_new))\n",
    "    if(score > 0.5):\n",
    "        print(\"{:.2f}% 확률로 긍정 리뷰입니다.\".format(score * 100))\n",
    "    else:\n",
    "        print(\"{:.2f}% 확률로 부정 리뷰입니다.\".format((1 - score) * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:54:27.533912Z",
     "start_time": "2023-11-13T14:54:27.509239Z"
    }
   },
   "id": "5b66164fcdd718b3"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 147ms/step\n",
      "95.84% 확률로 긍정 리뷰입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/76/r353dd3n1cb9npy26cwjvyz00000gn/T/ipykernel_1479/2864717832.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  score = float(loaded_model.predict(pad_new))\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('이 상품 진짜 좋아요... 저는 강추합니다. 대박')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:54:37.867848Z",
     "start_time": "2023-11-13T14:54:37.697573Z"
    }
   },
   "id": "29c5da1df55af76d"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "99.55% 확률로 부정 리뷰입니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/76/r353dd3n1cb9npy26cwjvyz00000gn/T/ipykernel_1479/2864717832.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  score = float(loaded_model.predict(pad_new))\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('진짜 배송도 늦고 개짜증나네요. 뭐 이런 걸 상품이라고 만듬?')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T14:54:52.437225Z",
     "start_time": "2023-11-13T14:54:52.397994Z"
    }
   },
   "id": "40912e65217c5d6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fc06249a619a21c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
