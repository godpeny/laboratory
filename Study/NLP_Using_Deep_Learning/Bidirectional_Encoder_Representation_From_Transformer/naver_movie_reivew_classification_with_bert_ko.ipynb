{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLdVJjaKb4kwfFfwRIEJIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9cf3bd94ceb43ce87a7223d67ca5f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_687a82ed3e14465da47e6fd4b4a5789b",
              "IPY_MODEL_213d75ad83b04ade9d45c85cc0889d7c",
              "IPY_MODEL_0784da664add47faad69e48a076d7b23"
            ],
            "layout": "IPY_MODEL_074b75800fdf470c99ac60cdad3ffeef"
          }
        },
        "687a82ed3e14465da47e6fd4b4a5789b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6635eabe1aa4b7c82a26a5b46ae262c",
            "placeholder": "​",
            "style": "IPY_MODEL_e6e70b3e00e64d209eb5719faec0e90f",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "213d75ad83b04ade9d45c85cc0889d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e5dbcda1cd42048aaba71a3d1af63a",
            "max": 445025130,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da227a5ce9324f158ed84f3142267737",
            "value": 445025130
          }
        },
        "0784da664add47faad69e48a076d7b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1645ef319f24417bf2d3325c368dd1b",
            "placeholder": "​",
            "style": "IPY_MODEL_09fef665217a46f2bd39d6c3896badd4",
            "value": " 445M/445M [00:06&lt;00:00, 82.6MB/s]"
          }
        },
        "074b75800fdf470c99ac60cdad3ffeef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6635eabe1aa4b7c82a26a5b46ae262c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e70b3e00e64d209eb5719faec0e90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91e5dbcda1cd42048aaba71a3d1af63a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da227a5ce9324f158ed84f3142267737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1645ef319f24417bf2d3325c368dd1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09fef665217a46f2bd39d6c3896badd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/godpeny/laboratory/blob/master/Study/NLP_Using_Deep_Learning/Bidirectional_Encoder_Representation_From_Transformer/naver_movie_reivew_classification_with_bert_ko.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Default Setting For Using TPU in Google Colab"
      ],
      "metadata": {
        "id": "9Pxy_Jn5-oLF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BSFddG_-Iz4",
        "outputId": "ed13ee32-c6f3-484f-fb15-8d5247b68c3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.tpu.topology.Topology at 0x7aa4baef8bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "1LSoGN9g-mz7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "import transformers"
      ],
      "metadata": {
        "id": "vsXA0mTw_DjU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n",
        "\n",
        "train_data = pd.read_table('ratings_train.txt')\n",
        "test_data = pd.read_table('ratings_test.txt')\n",
        "\n",
        "print(train_data.tail(10))\n",
        "print(test_data.tail(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyPsGuvH_N70",
        "outputId": "bfe51d45-c33a-4282-b0e0-8298f3707f5c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              id                                           document  label\n",
            "149990   6373651                                       이걸 영화라고 찎었냐?      0\n",
            "149991   9492905  http://blog.naver.com/oroblast/220215679580 나쁜...      1\n",
            "149992   9335962  공포나 재난영화가 아니라 아예 대놓고 비급 크리쳐개그물임ㅋㅋ 음악 완전 흥겹다ㅋ 5...      0\n",
            "149993  10020916                 For Carl.칼 세이건으로 시작해서 칼 세이건으로 끝난다.      1\n",
            "149994   9458520               디케이드 다음에 더블 다음에 오즈인데 더블은 조금밖에 안나오네요.      1\n",
            "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
            "149996   8549745                                      평점이 너무 낮아서...      1\n",
            "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
            "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
            "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
            "            id                                        document  label\n",
            "49990  9757200                           제발 국뽕김치영화좀 그만 만들어라...      0\n",
            "49991  9653062                                  재밌는데....?평점이왜?      1\n",
            "49992  1077821              내일 토요일밤 MBC에서 영화 해준다.... 봐야지... 기대      1\n",
            "49993  5494272          액션영화로 기대하지말고 스릴러영화라 생각하고 보면 괜찮은 영화인듯^^      1\n",
            "49994  5567676                                     정말 너무 재밌음 ㅋ      1\n",
            "49995  4608761       오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n",
            "49996  5308387    의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO      0\n",
            "49997  9072549              그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다      0\n",
            "49998  5802125  절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네      0\n",
            "49999  6070594                                      마무리는 또 왜이래      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "itwrostS_wwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check len\n",
        "print(len(train_data), len(test_data))\n",
        "\n",
        "# check null and drop\n",
        "print(train_data.isnull().values.any(), test_data.isnull().values.any())\n",
        "train_data.dropna(inplace=True)\n",
        "test_data.dropna(inplace=True)\n",
        "print(train_data.isnull().values.any(), test_data.isnull().values.any())\n",
        "\n",
        "# check duplicated and drop\n",
        "print(train_data.nunique(), test_data.nunique())\n",
        "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "test_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "print(train_data.nunique(), test_data.nunique())\n",
        "\n",
        "print(len(train_data), len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_w5f2uj_x0V",
        "outputId": "c694f958-65dd-435b-a24e-8492d9157507"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150000 50000\n",
            "True True\n",
            "False False\n",
            "id          149995\n",
            "document    146182\n",
            "label            2\n",
            "dtype: int64 id          49997\n",
            "document    49157\n",
            "label           2\n",
            "dtype: int64\n",
            "id          146182\n",
            "document    146182\n",
            "label            2\n",
            "dtype: int64 id          49157\n",
            "document    49157\n",
            "label           2\n",
            "dtype: int64\n",
            "146182 49157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizing"
      ],
      "metadata": {
        "id": "JkkkMy61_-FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentences, labels, max_seq_len, tokenizer):\n",
        "    tokenized_sentences, token_type_ids, attention_masks, output_labels = [], [], [], []\n",
        "\n",
        "    for sentence, label in zip(sentences, labels):\n",
        "        # sentence tokenizing\n",
        "        tokenized_sentence = tokenizer.encode(sentence, max_length=max_seq_len, pad_to_max_length=True)\n",
        "        # attention masking\n",
        "        padding_count = tokenized_sentence.count(tokenizer.pad_token_id)\n",
        "        attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count # 1 for token, 0 for padding\n",
        "        # segment encoding\n",
        "        token_type_id = [0] * max_seq_len # 0 for sentence 1, 1 for sentence 2. in this case, all 0\n",
        "\n",
        "        # validation\n",
        "        assert len(tokenized_sentence) == max_seq_len, \"tokenized sentence length is not equal to max_seq_len\"\n",
        "        assert len(attention_mask) == max_seq_len, \"attention mask length is not equal to max_seq_len\"\n",
        "        assert len(token_type_id) == max_seq_len, \"token type id length is not equal to max_seq_len\"\n",
        "\n",
        "        tokenized_sentences.append(tokenized_sentence)\n",
        "        token_type_ids.append(token_type_id)\n",
        "        attention_masks.append(attention_mask)\n",
        "        output_labels.append(label)\n",
        "\n",
        "    # make numpy array\n",
        "    tokenized_sentences = np.array(tokenized_sentences, dtype=int)\n",
        "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
        "    attention_masks = np.array(attention_masks, dtype=int)\n",
        "    output_labels = np.asarray(output_labels, dtype=np.int32)\n",
        "\n",
        "    return (tokenized_sentences, token_type_ids, attention_masks), output_labels"
      ],
      "metadata": {
        "id": "RLajhBV5_1kA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 128\n",
        "tokenizer= transformers.BertTokenizer.from_pretrained('klue/bert-base')\n",
        "\n",
        "X_train, y_train = tokenize(sentences=train_data['document'], labels=train_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)\n",
        "X_test, y_test = tokenize(sentences=test_data['document'], labels=test_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZmtYNVqADRn",
        "outputId": "8d3ce5fd-1776-46ca-b87a-10dc4aae6122"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check sample\n",
        "sample_tokenized_sentences = X_train[0][0]\n",
        "sample_token_type_ids = X_train[0][1]\n",
        "sample_attention_masks = X_train[0][2]\n",
        "sample_output_labels = y_train[0]\n",
        "\n",
        "print(sample_tokenized_sentences)\n",
        "print(sample_token_type_ids)\n",
        "print(sample_attention_masks)\n",
        "print(tokenizer.decode(sample_tokenized_sentences))\n",
        "print(sample_output_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NDex_AdAz9E",
        "outputId": "11d6372d-5086-4581-f477-4ace54ea7711"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   2 1376  831 2604   18   18 4229 9801 2075 2203 2182 4243    3    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "[    2  1963    18    18    18 11811  2178  2088 28883 16516  2776    18\n",
            "    18    18    18 10737  2156  2015  2446  2232  6758  2118  1380  6074\n",
            "     3     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[2 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Many-To-One Modeling With BERT"
      ],
      "metadata": {
        "id": "ipoZ6lgQA3hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TFBertForSequenceClassification(keras.Model):\n",
        "    def __init__(self, model_name):\n",
        "        super(TFBertForSequenceClassification, self).__init__()\n",
        "        self.bert = transformers.TFBertModel.from_pretrained(model_name, from_pt=True) # Load the model weights from a PyTorch state_dict save file (see docstring of `pretrained_model_name_or_path` argument).\n",
        "        self.classifier = tf.keras.layers.Dense(\n",
        "            units=1,\n",
        "            activation='sigmoid',\n",
        "            kernel_initializer=keras.initializers.TruncatedNormal(mean=0.02),\n",
        "            name='classifier')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        tokenized_sentences, token_type_ids, attention_masks = inputs\n",
        "        outputs = self.bert(\n",
        "            tokenized_sentences,\n",
        "            token_type_ids=token_type_ids,\n",
        "            attention_mask=attention_masks)\n",
        "        cls_token = outputs[1] # [CLS]\n",
        "        predictions = self.classifier(cls_token)\n",
        "\n",
        "        return predictions\n"
      ],
      "metadata": {
        "id": "OUJd4nEEA1fD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output of Bert Model\n",
        " - 1st element : last_hidden_state - sequence of hidden-states at the output of the last layer of the model. (batch_size, sequence_length, hidden_size) -> used for Many-To-Many modeling.\n",
        " - 2nd element: pooler_output - last layer hidden-state of the first token of the sequence (classification token == [CLS]) further processed by a Linear layer and a Tanh activation function. (batch_size, hidden_size) -> used for Many-To-One modeling.\n",
        "\n",
        "### Truncated Normal Distribution\n",
        " -  truncated normal distribution is the probability distribution derived from that of a normally distributed random variable by bounding the random variable from either below or above (or both).\n",
        " - 정규 분포(Normal Distribution) 에서 최솟값( )보다 작거나 최댓값( )보다 큰 값을 제거한 확률 분포 형태"
      ],
      "metadata": {
        "id": "7AqMbtN0BAiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model = TFBertForSequenceClassification(model_name='klue/bert-base')\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=5e-5)\n",
        "  loss = keras.losses.BinaryCrossentropy()\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "c9cf3bd94ceb43ce87a7223d67ca5f83",
            "687a82ed3e14465da47e6fd4b4a5789b",
            "213d75ad83b04ade9d45c85cc0889d7c",
            "0784da664add47faad69e48a076d7b23",
            "074b75800fdf470c99ac60cdad3ffeef",
            "d6635eabe1aa4b7c82a26a5b46ae262c",
            "e6e70b3e00e64d209eb5719faec0e90f",
            "91e5dbcda1cd42048aaba71a3d1af63a",
            "da227a5ce9324f158ed84f3142267737",
            "b1645ef319f24417bf2d3325c368dd1b",
            "09fef665217a46f2bd39d6c3896badd4"
          ]
        },
        "id": "PFHWCTuMBC-5",
        "outputId": "59761fb2-4cca-4d61-979f-41076680aae7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9cf3bd94ceb43ce87a7223d67ca5f83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'bert.embeddings.position_ids', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=2, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs2revIEBQoa",
        "outputId": "4a98c373-2d26-4bcf-c2ff-012010e8d4bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1828/1828 [==============================] - 349s 137ms/step - loss: 0.2833 - accuracy: 0.8805 - val_loss: 0.2379 - val_accuracy: 0.9028\n",
            "Epoch 2/2\n",
            "1828/1828 [==============================] - 196s 107ms/step - loss: 0.1876 - accuracy: 0.9261 - val_loss: 0.2538 - val_accuracy: 0.9002\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7aa3dbfa2410>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, y_test, batch_size=1024)\n",
        "print(\"test loss, test acc: \", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjcQYzhnDnOf",
        "outputId": "ee17b298-b855-4dc1-a90d-30ff670f394b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49/49 [==============================] - 26s 307ms/step - loss: 0.2582 - accuracy: 0.8975\n",
            "test loss, test acc:  [0.25816503167152405, 0.8974510431289673]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "RJa6PKC8DhWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  input_id = tokenizer.encode(new_sentence, max_length=max_seq_len,pad_to_max_length=True)\n",
        "  padding_count = input_id.count(tokenizer.pad_token_id)\n",
        "  attention_mask = [1] * (max_seq_len - padding_count) + [0] * padding_count\n",
        "  token_type_id = [0] * max_seq_len\n",
        "\n",
        "  input_ids = np.array([input_id])\n",
        "  attention_masks = np.array([attention_mask])\n",
        "  token_type_ids = np.array([token_type_id])\n",
        "  encoded_input = [input_ids, token_type_ids, attention_masks]\n",
        "\n",
        "  score = model.predict(encoded_input)\n",
        "  print(score)\n",
        "  score = score[0][0]\n",
        "  print(score)\n",
        "\n",
        "  if(score > 0.5):\n",
        "    print(\"{:.2f}% 확 률 로 긍 정 리 뷰 입 니 다 .\\n\".format(score * 100))\n",
        "  else:\n",
        "    print(\"{:.2f}% 확 률 로 부 정 리 뷰 입 니 다 .\\n\".format((1 - score) * 100))"
      ],
      "metadata": {
        "id": "9HwcXpu7EDX5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict(\"이 영 화 존 잼 입 니 다 대 박 \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqXJW6GcETRF",
        "outputId": "2836d282-59ea-4a1b-e4ac-299145db5db9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 960ms/step\n",
            "[[0.81394494]]\n",
            "0.81394494\n",
            "81.39% 확 률 로 긍 정 리 뷰 입 니 다 .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_predict('이 영화 핵노잼 ㅠㅠ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "583eLHFgEpjV",
        "outputId": "311ba929-8fc9-491e-81ca-de07644961ba"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 738ms/step\n",
            "[[0.00708029]]\n",
            "0.0070802867\n",
            "99.29% 확 률 로 부 정 리 뷰 입 니 다 .\n",
            "\n"
          ]
        }
      ]
    }
  ]
}