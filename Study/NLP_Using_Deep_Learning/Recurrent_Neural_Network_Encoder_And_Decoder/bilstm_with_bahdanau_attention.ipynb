{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:06:22.742847Z",
     "start_time": "2023-12-13T14:06:18.669805Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2494\n",
      "238.71364\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "max_len = 500\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "print(max(map(len, X_train)))\n",
    "print(sum(map(len, X_train))/len(X_train))\n",
    "\n",
    "X_train_padded = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test_padded = pad_sequences(X_test, maxlen=max_len)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:06:25.647457Z",
     "start_time": "2023-12-13T14:06:23.942343Z"
    }
   },
   "id": "f2abb22edccb7a1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bahdanau Attention"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e16de44da7d6f7f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "from keras.layers import Dense"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:29:49.953545Z",
     "start_time": "2023-12-13T14:29:49.942813Z"
    }
   },
   "id": "493fb5422257d94b"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class BahdanauAttention(Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = Dense(units) # units : output dimensionality\n",
    "        self.W2 = Dense(units)\n",
    "        self.V = Dense(1)\n",
    "        \n",
    "    def call(self, values, query):\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        # attention_weights : (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        return context_vector, attention_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T15:29:32.756924Z",
     "start_time": "2023-12-13T15:29:32.747375Z"
    }
   },
   "id": "2695e65434c040c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### super(BahdanauAttention, self).__init__()\n",
    " - super() 라는 함수는 super class 즉, 부모 클래스의 임시적인 객체를 반환하여 부모클래스의 메소드를 사용할 수 있게 하는 것.\n",
    " - ``super(BahdanauAttention, self)`` : returns a temporary object of the superclass, which in this case is ``tf.keras.Model``, as ``BahdanauAttention`` is a subclass of tf.keras.Model.\n",
    " - ``super(BahdanauAttention, self).__init__()`` :  calls the constructor of the superclass ``(tf.keras.Model)``. This is necessary to ensure that the initialization code in the base class ``(tf.keras.Model)`` is executed.\n",
    " - In summary, the line ``super(BahdanauAttention, self).__init__()`` in the ``BahdanauAttention`` class ensures that the class inherits and initializes all necessary properties and methods from its parent class ``tf.keras.Model``.\n",
    "\n",
    "### call\n",
    " - ``call`` method is called in the ``BahdanauAttention`` class when you call the instance of the ``BahdanauAttention`` class.\n",
    " - By subclassing the `Model` class: in that case, you should define your\n",
    "    layers in `__init__()` and you should implement the model's forward pass\n",
    "    in `call()`. (https://www.tensorflow.org/api_docs/python/tf/keras/Model)\n",
    "\n",
    "### tf.layers.Dense\n",
    " - Dense implements the operation: ``output = activation(dot(input, kernel) + bias)`` , Belows are all attributes of Dense.\n",
    "  - ``activation`` is the element-wise activation function passed as the activation argument.\n",
    "  - ``kernel`` is a weights matrix created by the layer.\n",
    "  - ``bias`` is a bias vector created by the layer (only applicable if use_bias is True). \n",
    " - If the input to the layer has a rank greater than 2, then Dense computes the dot product between the inputs and the kernel along the last axis of the inputs and axis 0 of the kernel (using tf.tensordot). For example, if input has dimensions (batch_size, d0, d1), then we create a kernel with shape (d1, units), and the kernel operates along axis 2 of the input, on every sub-tensor of shape (1, 1, d1) (there are batch_size * d0 such sub-tensors). The output in this case will have shape (batch_size, d0, units). (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense?hl=en)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c684a63d3b359c0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TensorDot (Example)\n",
    "## https://www.tensorflow.org/api_docs/python/tf/tensordot\n",
    "## https://numpy.org/doc/stable/reference/generated/numpy.tensordot.html\n",
    "\n",
    "### tensordot.axes : int or (2,) array_like\n",
    " - integer_like If an int N, sum over the last N axes of a and the first N axes of b in order. The sizes of the corresponding axes must match.\n",
    " - (2,) array_like Or, a list of axes to be summed over, first sequence applying to a, second to b. Both elements array_like must be of the same length.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cba41add36bd5816"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "[[ 4. 12. 20.]\n",
      " [ 5. 17. 29.]\n",
      " [ 6. 22. 38.]\n",
      " [ 7. 27. 47.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(8.).reshape(1,2,4)\n",
    "b = np.arange(6.).reshape(1,3,2)\n",
    "c = np.tensordot(a,b, axes=([0,1],[0,2]))\n",
    "\n",
    "print(c.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:37:07.612989Z",
     "start_time": "2023-12-13T14:37:07.606436Z"
    }
   },
   "id": "8b71c7c2c3e9f407"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 2. 3.]\n",
      "  [4. 5. 6. 7.]]]\n",
      "[[[0. 1.]\n",
      "  [2. 3.]\n",
      "  [4. 5.]]]\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:37:21.866040Z",
     "start_time": "2023-12-13T14:37:21.854381Z"
    }
   },
   "id": "452d70641868006e"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4. 12. 20.]\n",
      " [ 5. 17. 29.]\n",
      " [ 6. 22. 38.]\n",
      " [ 7. 27. 47.]]\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:37:25.767761Z",
     "start_time": "2023-12-13T14:37:25.751398Z"
    }
   },
   "id": "9485bde7024f840a"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4. 12. 20.]\n",
      " [ 5. 17. 29.]\n",
      " [ 6. 22. 38.]\n",
      " [ 7. 27. 47.]]\n"
     ]
    }
   ],
   "source": [
    "_c = np.zeros((4,3))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range (4):\n",
    "        for k in range(2):\n",
    "            for l in range(1):\n",
    "                _c[j,i] += a[l,k,j] * b[l,i,k]\n",
    "print(_c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T14:53:12.210162Z",
     "start_time": "2023-12-13T14:53:12.203667Z"
    }
   },
   "id": "aff8c427dd6766c0"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n",
      "[[[ 42.  48.  54.]\n",
      "  [114. 136. 158.]]]\n",
      "[[[ 42.  48.  54.]\n",
      "  [114. 136. 158.]]]\n",
      "(1, 2, 3)\n",
      "tf.Tensor(\n",
      "[[[ 42.  48.  54.]\n",
      "  [114. 136. 158.]]], shape=(1, 2, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(8.).reshape(1,2,4)\n",
    "b = np.arange(12.).reshape(4,3)\n",
    "c = np.tensordot(a,b, axes=([2],[0]))\n",
    "\n",
    "print(c.shape)\n",
    "\n",
    "__c = np.zeros((1,2,3))\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range (2):\n",
    "        for k in range(3):\n",
    "            for l in range(4):\n",
    "                __c[i,j,k] += a[i,j,l] * b[l,k]\n",
    "\n",
    "print(c)\n",
    "print(__c)\n",
    "\n",
    "# numpy.tensordot == tf.tensordot\n",
    "tc = tf.tensordot(a,b, axes=([2],[0]))\n",
    "print(tc.shape)\n",
    "print(tc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T15:09:22.657663Z",
     "start_time": "2023-12-13T15:09:22.653334Z"
    }
   },
   "id": "680ec2d940dfda03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d74e8ee5d36e67d9"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
    "from keras import Input, Model\n",
    "from keras import optimizers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T15:19:05.140388Z",
     "start_time": "2023-12-13T15:19:05.119937Z"
    }
   },
   "id": "f0407c3359c4f59f"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n",
      "(None, 128) (None, 128)\n",
      "<keras.src.layers.core.dense.Dense object at 0x2c48ef2d0>\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 500)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)     (None, 500, 128)             1280000   ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional_8 (Bidirecti  (None, 500, 128)             98816     ['embedding_4[0][0]']         \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " bidirectional_9 (Bidirecti  [(None, 500, 128),           98816     ['bidirectional_8[0][0]']     \n",
      " onal)                        (None, 64),                                                         \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64),                                                         \n",
      "                              (None, 64)]                                                         \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 128)                  0         ['bidirectional_9[0][1]',     \n",
      " )                                                                   'bidirectional_9[0][3]']     \n",
      "                                                                                                  \n",
      " bahdanau_attention_2 (Bahd  ((None, 128),                16577     ['bidirectional_9[0][0]',     \n",
      " anauAttention)               (None, 500, 1))                        'concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 1)                    129       ['bahdanau_attention_2[0][0]']\n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1)                    0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 1)                    2         ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1494340 (5.70 MB)\n",
      "Trainable params: 1494340 (5.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "embedding_dim = 128\n",
    "hidden_units = 64\n",
    "dropout_ratio = 0.5\n",
    "\n",
    "# input-embedding\n",
    "input = Input(shape=(max_len,), dtype='int32')\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len, mask_zero=True)(input)\n",
    "# bi-LSTM\n",
    "lstm = Bidirectional(LSTM(hidden_units, dropout=dropout_ratio, return_sequences=True))(embedding)\n",
    "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(hidden_units, dropout=dropout_ratio, return_sequences=True, return_state=True))(lstm)\n",
    "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h]) # hidden state\n",
    "state_c = Concatenate()([forward_c, backward_c]) # cell state\n",
    "print(state_h.shape, state_c.shape)\n",
    "\n",
    "# Attention\n",
    "# use hidden state to compute attention score\n",
    "attention = BahdanauAttention(64) \n",
    "context_vector, attention_weights = attention(lstm, state_h)\n",
    "\n",
    "# output\n",
    "output = Dense(1, activation='relu')(context_vector)\n",
    "output = Dropout(dropout_ratio)(output)\n",
    "output = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "# model\n",
    "model = Model(inputs=input, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T15:42:01.216657Z",
     "start_time": "2023-12-13T15:41:59.262065Z"
    }
   },
   "id": "e973175bb7600bb"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "98/98 [==============================] - 318s 3s/step - loss: 0.6359 - accuracy: 0.6246 - val_loss: 0.5454 - val_accuracy: 0.8375\n",
      "Epoch 2/3\n",
      "98/98 [==============================] - 320s 3s/step - loss: 0.5822 - accuracy: 0.6850 - val_loss: 0.5007 - val_accuracy: 0.8566\n",
      "Epoch 3/3\n",
      "98/98 [==============================] - 308s 3s/step - loss: 0.5584 - accuracy: 0.7020 - val_loss: 0.4783 - val_accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_padded, y_train, epochs=3, batch_size=256, validation_data=(X_test_padded, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T15:58:30.182595Z",
     "start_time": "2023-12-13T15:42:44.436220Z"
    }
   },
   "id": "25a087eee480df0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cefe9e17dcb8bee"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 117s 150ms/step - loss: 0.4783 - accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.47830942273139954, 0.8667200207710266]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_padded, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T16:01:12.412934Z",
     "start_time": "2023-12-13T15:59:15.058289Z"
    }
   },
   "id": "b95fffab08845430"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1559b1401e729bb5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
